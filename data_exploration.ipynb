{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.max_columns', 200)\n",
    "from src.data.data_fetcher import get_all_features, get_raw_data\n",
    "from src.features.feature_engineering import create_time_features_from_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0.5: Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_A, targets_B, targets_C, X_train_estimated_a, X_train_estimated_b, X_train_estimated_c, X_train_observed_a, X_train_observed_b, X_train_observed_c, X_test_estimated_a, X_test_estimated_b, X_test_estimated_c = get_raw_data()\n",
    "all_features = get_raw_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute statistics for each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics for each location\n",
    "stats_A = targets_A['pv_measurement'].describe()\n",
    "stats_B = targets_B['pv_measurement'].describe()\n",
    "stats_C = targets_C['pv_measurement'].describe()\n",
    "print(\"Statistics for Location A:\\n\", stats_A)\n",
    "print(\"\\nStatistics for Location B:\\n\", stats_B)\n",
    "print(\"\\nStatistics for Location C:\\n\", stats_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trend Analysis\n",
    "This code will plot the actual pv_measurement values along with their rolling mean trend (computed over a 7-day window) for Location A. The shaded region represents the confidence intervals for the moving average. You can repeat similar plots for Locations B and C by calling the plot_moving_average function with their respective datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src.visualization.plotting import plot_moving_average\n",
    "# Load the datasets\n",
    "\n",
    "# For Location A, B and C\n",
    "# Compute moving averages for trend analysis\n",
    "plot_moving_average(targets_A['pv_measurement'], window=24*7, plot_intervals=True, title=\"Moving Average Trend for Location A\")\n",
    "plot_moving_average(targets_B['pv_measurement'], window=24*7, plot_intervals=True, title=\"Moving Average Trend for Location B\")\n",
    "plot_moving_average(targets_C['pv_measurement'], window=24*7, plot_intervals=True, title=\"Moving Average Trend for Location C\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonality analysis\n",
    "Identifying recurring patterns or cycles in the data. For hourly data, you might find daily or monthly seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# Load the dataset for Location A\n",
    "targets_A = pd.read_csv('path_to_A_train_targets.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# Decomposition\n",
    "result = seasonal_decompose(targets_A['pv_measurement'], model='additive')\n",
    "result.plot()\n",
    "plt.show()\n",
    "\n",
    "# Seasonal plot for daily patterns\n",
    "daily_seasonal = result.seasonal['2022-01-01':'2022-01-02']  # Adjust dates to pick a representative 2-day period\n",
    "daily_seasonal.plot(figsize=(15,6))\n",
    "plt.title('Daily Seasonal Pattern')\n",
    "plt.show()\n",
    "\n",
    "# Autocorrelation plot to identify seasonality\n",
    "plot_acf(targets_A['pv_measurement'], lags=168)  # 168 hours for a weekly pattern\n",
    "plt.title('Autocorrelation Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyclicity: \n",
    "Unlike seasonality, which happens at fixed known periods, cycles are fluctuations that are not of a fixed frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Load the dataset for Location A\n",
    "targets_A = pd.read_csv('path_to_A_train_targets.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# Visual Inspection\n",
    "plt.figure(figsize=(15,6))\n",
    "targets_A['pv_measurement'].plot()\n",
    "plt.title('Time Series Plot for Visual Inspection of Cyclicity')\n",
    "plt.show()\n",
    "\n",
    "# Autocorrelation plot\n",
    "plot_acf(targets_A['pv_measurement'], lags=500)  # Adjust lags as needed to inspect longer periods\n",
    "plt.title('Autocorrelation Plot')\n",
    "plt.show()\n",
    "\n",
    "# Partial autocorrelation plot\n",
    "plot_pacf(targets_A['pv_measurement'], lags=500)  # Adjust lags as needed\n",
    "plt.title('Partial Autocorrelation Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autocorrelation: \n",
    "It measures the relationship between a variable's current value and its past values. A lag plot or an autocorrelation function (ACF) plot can help in understanding this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# Load the dataset for Location A\n",
    "targets_A = pd.read_csv('path_to_A_train_targets.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# Plot the Autocorrelation Function\n",
    "plt.figure(figsize=(15,6))\n",
    "plot_acf(targets_A['pv_measurement'], lags=168)  # 168 hours to check for weekly patterns\n",
    "plt.title('Autocorrelation Function (ACF) Plot for Location A')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection: \n",
    "Identifying unusual data points that might be errors or rare events. This can be done visually or with statistical methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "detect_outliers() got an unexpected keyword argument 'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Bruker\\OneDrive\\NTNU semester 05\\TDT4173 Maskinl√¶ring\\ml_power_predictor\\data_exploration.ipynb Cell 18\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/data_exploration.ipynb#X56sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvisualization\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mplotting\u001b[39;00m \u001b[39mimport\u001b[39;00m detect_outliers\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/data_exploration.ipynb#X56sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Load the dataset for Location A\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/data_exploration.ipynb#X56sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# targets_A = pd.read_csv('path_to_A_train_targets.csv', parse_dates=['date'], index_col='date')\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/data_exploration.ipynb#X56sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/data_exploration.ipynb#X56sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Detect outliers\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/data_exploration.ipynb#X56sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m outliers_a \u001b[39m=\u001b[39m detect_outliers(targets_A[\u001b[39m'\u001b[39;49m\u001b[39mpv_measurement\u001b[39;49m\u001b[39m'\u001b[39;49m], title \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mOutliers for Location A\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/data_exploration.ipynb#X56sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m outliers_b \u001b[39m=\u001b[39m detect_outliers(targets_B[\u001b[39m'\u001b[39m\u001b[39mpv_measurement\u001b[39m\u001b[39m'\u001b[39m], title \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOutliers for Location B\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/data_exploration.ipynb#X56sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m outliers_c \u001b[39m=\u001b[39m detect_outliers(targets_C[\u001b[39m'\u001b[39m\u001b[39mpv_measurement\u001b[39m\u001b[39m'\u001b[39m], title \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOutliers for Location C\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: detect_outliers() got an unexpected keyword argument 'title'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src.visualization.plotting import detect_outliers\n",
    "# Load the dataset for Location A\n",
    "# targets_A = pd.read_csv('path_to_A_train_targets.csv', parse_dates=['date'], index_col='date')\n",
    "\n",
    "# Detect outliers\n",
    "outliers_a = detect_outliers(targets_A['pv_measurement'], \"Outliers for Location A\")\n",
    "outliers_b = detect_outliers(targets_B['pv_measurement'], \"Outliers for Location B\")\n",
    "outliers_c = detect_outliers(targets_C['pv_measurement'], \"Outliers for Location C\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Analysis: \n",
    "Understanding the distribution of data can provide insights into its nature (e.g., normal vs. skewed, presence of heavy tails)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance: \n",
    "If using machine learning models, understanding which features (in this case, weather parameters) are most influential in predicting solar energy production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Analysis: \n",
    "After fitting a model, analyzing the residuals (difference between predictions and actual values) can give insights into the model's accuracy and potential areas of improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation with External Factors: \n",
    "Understanding how external factors, such as weather parameters, correlate with solar production. A heatmap or correlation matrix can be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain-Specific Insights: \n",
    "Since this data deals with solar energy production, domain knowledge about factors affecting solar panel efficiency, degradation over time, and other domain-specific considerations can be invaluable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data Analysis: \n",
    "Understanding if there are any missing data points, the reason for their absence, and deciding on strategies to handle them (e.g., interpolation, imputation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_train_observed_a\n",
    "\n",
    "dtest = train_a\n",
    "dtest.shape\n",
    "dtest.head(20)\n",
    "\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "df[\"date_forecast\"].dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Data preperation\n",
    "- Dropping irrelevant columns and rows\n",
    "- Identifying duplicated columns\n",
    "- Renaming Columns\n",
    "- Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\n",
    "    'date_forecast', 'absolute_humidity_2m:gm3', 'air_density_2m:kgm3',\n",
    "       'ceiling_height_agl:m', 'clear_sky_energy_1h:J', 'clear_sky_rad:W',\n",
    "       'cloud_base_agl:m', 'dew_or_rime:idx', 'dew_point_2m:K',\n",
    "       'diffuse_rad:W', 'diffuse_rad_1h:J', 'direct_rad:W', 'direct_rad_1h:J',\n",
    "       'effective_cloud_cover:p', 'elevation:m', 'fresh_snow_12h:cm',\n",
    "       'fresh_snow_1h:cm', 'fresh_snow_24h:cm', 'fresh_snow_3h:cm',\n",
    "       'fresh_snow_6h:cm', 'is_day:idx', 'is_in_shadow:idx',\n",
    "       'msl_pressure:hPa', 'precip_5min:mm', 'precip_type_5min:idx',\n",
    "       'pressure_100m:hPa', 'pressure_50m:hPa', 'prob_rime:p',\n",
    "       'rain_water:kgm2', 'relative_humidity_1000hPa:p', 'sfc_pressure:hPa',\n",
    "       'snow_density:kgm3', 'snow_depth:cm', 'snow_drift:idx',\n",
    "       'snow_melt_10min:mm', 'snow_water:kgm2', 'sun_azimuth:d',\n",
    "       'sun_elevation:d', 'super_cooled_liquid_water:kgm2', 't_1000hPa:K',\n",
    "       'total_cloud_cover:p', 'visibility:m', 'wind_speed_10m:ms',\n",
    "       'wind_speed_u_10m:ms', 'wind_speed_v_10m:ms',\n",
    "       'wind_speed_w_1000hPa:ms'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.duplicated(subset=[\"date_forecast\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding month column to dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_time_features_from_date(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding season column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data types, ranges, missing values and outliers\n",
    "There is much we do not know about the data. We need to find out more about it. We need to know the data types, ranges, missing values and outliers. We will use the describe function to get a summary of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a, train_b, train_c, X_train_estimated_a, X_train_estimated_b, X_train_estimated_c, X_train_observed_a, X_train_observed_b, X_train_observed_c, X_test_estimated_a, X_test_estimated_b, X_test_estimated_c = get_raw_data()\n",
    "all_features = get_raw_data()\n",
    "\n",
    "missing_a = X_train_estimated_a.isna().sum()\n",
    "missing_b = X_train_estimated_b.isna().sum()\n",
    "missing_c = X_train_estimated_c.isna().sum()\n",
    "missing_a, missing_b, missing_c\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
