{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import KFold\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import accuracy_score as acs_score\n",
    "\n",
    "from src.data.data_fetcher import get_raw_data\n",
    "from src.features.preprocess_data import get_preprocessed_test_data, fetch_preprocessed_data\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_obs_combined, X_val_obs_combined, y_train_obs_combined, y_val_obs_combined, X_train_est_combined, X_val_est_combined, y_train_est_combined, y_val_est_combined = fetch_preprocessed_data()\n",
    "x_test_whole = get_preprocessed_test_data()\n",
    "\n",
    "x_whole = pd.concat([X_train_obs_combined, X_val_obs_combined, X_train_est_combined, X_val_est_combined])\n",
    "y_whole = pd.concat([y_train_obs_combined, y_val_obs_combined, y_train_est_combined, y_val_est_combined])\n",
    "x_whole.reset_index(drop=True, inplace=True)\n",
    "y_whole.reset_index(drop=True, inplace=True)\n",
    "\n",
    "x_whole.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_whole.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "total_mae = 0\n",
    "reg_models = []\n",
    "\n",
    "def compute_sample_weight(data):\n",
    "    # Assign weight of 2 for estimated data and 1 for observed data\n",
    "    return np.where(data['time_since_prediction'] > 0, 2, 1)\n",
    "\n",
    "for train_index, test_index in kf.split(x_whole):\n",
    "    reg = CatBoostRegressor(\n",
    "        iterations=10000000,\n",
    "        depth=8,\n",
    "        learning_rate=0.001,\n",
    "        loss_function='MAE',\n",
    "        verbose=200\n",
    "    )\n",
    "    \n",
    "    X_train, X_test = x_whole.iloc[train_index], x_whole.iloc[test_index]\n",
    "    y_train, y_test = y_whole.iloc[train_index], y_whole.iloc[test_index]\n",
    "    \n",
    "    # Compute sample weights for training and testing data\n",
    "    train_weight = compute_sample_weight(X_train)\n",
    "    test_weight = compute_sample_weight(X_test)\n",
    "\n",
    "    # Create Pool for training and testing\n",
    "    train_pool = Pool(data=X_train, label=y_train, weight=train_weight)\n",
    "    test_pool = Pool(data=X_test, label=y_test, weight=test_weight)\n",
    "\n",
    "    # Fit the model using the sample weights\n",
    "    reg.fit(train_pool, eval_set=test_pool, early_stopping_rounds=100)\n",
    "\n",
    "    reg_models.append(reg)\n",
    "    predictions = reg.predict(test_pool)\n",
    "    \n",
    "    # Compute weighted MAE manually\n",
    "    weighted_mae = np.sum(test_weight * np.abs(y_test - predictions)) / np.sum(test_weight)\n",
    "    total_mae += weighted_mae\n",
    "    \n",
    "    print(f\"Fold {len(reg_models)}, Weighted Mean Absolute Error: {weighted_mae}\")\n",
    "\n",
    "average_mae = total_mae / num_folds\n",
    "print(f\"Average Weighted Mean Absolute Error: {average_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_predict(x_values :pd.DataFrame, models) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function for predicting on multiple models and averaging the results\n",
    "    \"\"\"\n",
    "    results = models[0].predict(x_values)\n",
    "    for model in models[1:]:\n",
    "        prediction = model.predict(x_values)\n",
    "        results += prediction\n",
    "    \n",
    "    results = results / len(models)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val_obs_combined = multi_predict(x_whole_obs, reg_models)\n",
    "y_pred_val_est_combined = multi_predict(x_whole_est, reg_models)\n",
    "\n",
    "# Evaluate the model's performance using Mean Absolute Error (MAE) on the combined validation observed data\n",
    "mae_obs_combined = mean_absolute_error(y_whole_obs, y_pred_val_obs_combined)\n",
    "mae_est_combined = mean_absolute_error(y_whole_est, y_pred_val_est_combined)\n",
    "print('MAE on validation observed data: ', mae_obs_combined)\n",
    "print('MAE on validation estimated data: ', mae_est_combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_prediction = multi_predict(x_whole, reg_models)\n",
    "\n",
    "test_prediction = multi_predict(X_val_est_combined, reg_models)\n",
    "# Observed Data\n",
    "# Set up the plotting area\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Line plot of Actual values\n",
    "plt.plot(y_whole.reset_index(drop=True), label='Actual', linestyle='-', marker='o', markersize=5, alpha=0.7, color='blue')\n",
    "# Line plot of Predicted values\n",
    "plt.plot(train_prediction, label='Predicted', linestyle='--', marker='x', markersize=5, alpha=0.7, color='orange')\n",
    "# Titles and labels\n",
    "plt.title('Actual vs Predicted - Observed Data', fontsize=16)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualise the monthly predictions\n",
    "# Observed Data\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Line plot of Actual values\n",
    "plt.plot(y_whole.reset_index(drop=True)[:24*7*4], label='Actual', linestyle='-', marker='o', markersize=5, alpha=0.7, color='blue')\n",
    "# Line plot of Predicted values\n",
    "plt.plot(train_prediction[:24*7*4], label='Predicted', linestyle='--', marker='x', markersize=5, alpha=0.7, color='orange')\n",
    "# Titles and labels\n",
    "plt.title('Actual vs Predicted - Observed Data', fontsize=16)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estimated Data\n",
    "# Set up the plotting area\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Line plot of Actual values\n",
    "plt.plot(y_val_est_combined.reset_index(drop=True), label='Actual', linestyle='-', marker='o', markersize=5, alpha=0.7, color='blue')\n",
    "# Line plot of Predicted values\n",
    "plt.plot(test_prediction, label='Predicted', linestyle='--', marker='x', markersize=5, alpha=0.7, color='orange')\n",
    "# Titles and labels\n",
    "plt.title('Actual vs Predicted - Estimated Data', fontsize=16)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Visualise the monthly predictions\n",
    "# Estimated Data\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Line plot of Actual values\n",
    "plt.plot(y_val_est_combined.reset_index(drop=True)[:24*7*4], label='Actual', linestyle='-', marker='o', markersize=5, alpha=0.7, color='blue')\n",
    "# Line plot of Predicted values\n",
    "plt.plot(test_prediction[:24*7*4], label='Predicted', linestyle='--', marker='x', markersize=5, alpha=0.7, color='orange')\n",
    "plt.title('Actual vs Predicted - Estimated Data', fontsize=16)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"catboost_models.pkl\", \"wb\") as file:\n",
    "    pickle.dump(reg_models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"catboost_models.pkl\", \"rb\") as file:\n",
    "    loaded_reg_models = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = multi_predict(x_test_whole, reg_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "from src.models.saving import save_predictions\n",
    "\n",
    "save_predictions(y_pred, 'catboost')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
