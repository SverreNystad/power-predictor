{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in /opt/conda/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from catboost) (3.7.3)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from catboost) (1.25.2)\n",
      "Requirement already satisfied: pandas>=0.24 in /opt/conda/lib/python3.10/site-packages (from catboost) (2.0.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from catboost) (1.11.3)\n",
      "Requirement already satisfied: plotly in /opt/conda/lib/python3.10/site-packages (from catboost) (5.18.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (4.44.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->catboost) (3.1.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly->catboost) (8.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "%pip install catboost\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import KFold\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import accuracy_score as acs_score\n",
    "\n",
    "from src.data.data_fetcher import get_raw_data\n",
    "from src.features.preprocess_data import get_preprocessed_test_data, fetch_preprocessed_data\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>cloud_base_agl:m</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad:W</th>\n",
       "      <th>direct_rad_1h:J</th>\n",
       "      <th>effective_cloud_cover:p</th>\n",
       "      <th>is_day:idx</th>\n",
       "      <th>is_in_shadow:idx</th>\n",
       "      <th>precip_5min:mm</th>\n",
       "      <th>precip_type_5min:idx</th>\n",
       "      <th>pressure_50m:hPa</th>\n",
       "      <th>prob_rime:p</th>\n",
       "      <th>rain_water:kgm2</th>\n",
       "      <th>relative_humidity_1000hPa:p</th>\n",
       "      <th>sun_azimuth:d</th>\n",
       "      <th>super_cooled_liquid_water:kgm2</th>\n",
       "      <th>t_1000hPa:K</th>\n",
       "      <th>total_cloud_cover:p</th>\n",
       "      <th>visibility:m</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>wind_speed_u_10m:ms</th>\n",
       "      <th>wind_speed_v_10m:ms</th>\n",
       "      <th>wind_speed_w_1000hPa:ms</th>\n",
       "      <th>location_a</th>\n",
       "      <th>location_b</th>\n",
       "      <th>location_c</th>\n",
       "      <th>sin_day_of_year</th>\n",
       "      <th>cos_day_of_year</th>\n",
       "      <th>sin_hour</th>\n",
       "      <th>cos_hour</th>\n",
       "      <th>sun_product</th>\n",
       "      <th>modified_solar_elevation</th>\n",
       "      <th>effective_radiation</th>\n",
       "      <th>time_since_prediction</th>\n",
       "      <th>cloud_ratio</th>\n",
       "      <th>cloud_cover_over_30%</th>\n",
       "      <th>sun_addition</th>\n",
       "      <th>is_freezing</th>\n",
       "      <th>is_snow</th>\n",
       "      <th>is_rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.450</td>\n",
       "      <td>1.25900</td>\n",
       "      <td>902436.125</td>\n",
       "      <td>194.449997</td>\n",
       "      <td>2426.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.625000</td>\n",
       "      <td>88.175003</td>\n",
       "      <td>348536.406250</td>\n",
       "      <td>70.375000</td>\n",
       "      <td>271995.531250</td>\n",
       "      <td>62.900002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1018.400024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.174999</td>\n",
       "      <td>242.404755</td>\n",
       "      <td>0.000</td>\n",
       "      <td>281.774994</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>43816.324219</td>\n",
       "      <td>0.725</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.984306</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>6205.315918</td>\n",
       "      <td>0.242142</td>\n",
       "      <td>0.301401</td>\n",
       "      <td>0</td>\n",
       "      <td>0.629000</td>\n",
       "      <td>1</td>\n",
       "      <td>158.550003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.925</td>\n",
       "      <td>1.27550</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>971.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>273.600006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.425003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1010.150024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.949997</td>\n",
       "      <td>309.972748</td>\n",
       "      <td>0.100</td>\n",
       "      <td>276.625000</td>\n",
       "      <td>99.425003</td>\n",
       "      <td>33486.976562</td>\n",
       "      <td>2.825</td>\n",
       "      <td>1.125</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.702148</td>\n",
       "      <td>0.712031</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.975</td>\n",
       "      <td>1.20350</td>\n",
       "      <td>797556.125</td>\n",
       "      <td>175.350006</td>\n",
       "      <td>3255.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.075012</td>\n",
       "      <td>50.824997</td>\n",
       "      <td>206314.859375</td>\n",
       "      <td>120.599998</td>\n",
       "      <td>537617.250000</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>995.099976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.700001</td>\n",
       "      <td>230.077255</td>\n",
       "      <td>0.000</td>\n",
       "      <td>289.299988</td>\n",
       "      <td>6.050000</td>\n",
       "      <td>57556.351562</td>\n",
       "      <td>4.925</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>4.925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999371</td>\n",
       "      <td>0.035473</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>6129.494629</td>\n",
       "      <td>0.226685</td>\n",
       "      <td>0.674081</td>\n",
       "      <td>0</td>\n",
       "      <td>0.867769</td>\n",
       "      <td>0</td>\n",
       "      <td>171.424988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.675</td>\n",
       "      <td>1.23925</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2067.925049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.924988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.949997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>981.574951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.949997</td>\n",
       "      <td>252.160492</td>\n",
       "      <td>0.000</td>\n",
       "      <td>279.774994</td>\n",
       "      <td>98.974998</td>\n",
       "      <td>45661.750000</td>\n",
       "      <td>3.800</td>\n",
       "      <td>1.100</td>\n",
       "      <td>3.625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.638384</td>\n",
       "      <td>0.769718</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.929022</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.450</td>\n",
       "      <td>1.22500</td>\n",
       "      <td>2240127.750</td>\n",
       "      <td>591.500000</td>\n",
       "      <td>115.849998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>283.324982</td>\n",
       "      <td>138.100006</td>\n",
       "      <td>454697.093750</td>\n",
       "      <td>66.150002</td>\n",
       "      <td>185963.796875</td>\n",
       "      <td>96.349998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1001.400024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.900002</td>\n",
       "      <td>216.283997</td>\n",
       "      <td>0.275</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>98.199997</td>\n",
       "      <td>5958.750000</td>\n",
       "      <td>4.525</td>\n",
       "      <td>4.100</td>\n",
       "      <td>-1.950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.900002</td>\n",
       "      <td>216.283997</td>\n",
       "      <td>0.275</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>98.199997</td>\n",
       "      <td>5958.750000</td>\n",
       "      <td>4.525</td>\n",
       "      <td>4.100</td>\n",
       "      <td>-1.950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.739392</td>\n",
       "      <td>-0.673275</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>9135.315430</td>\n",
       "      <td>0.571108</td>\n",
       "      <td>0.083015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.981161</td>\n",
       "      <td>1</td>\n",
       "      <td>204.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolute_humidity_2m:gm3  air_density_2m:kgm3  clear_sky_energy_1h:J  \\\n",
       "0                     6.450              1.25900             902436.125   \n",
       "1                     4.925              1.27550                  0.000   \n",
       "2                     6.975              1.20350             797556.125   \n",
       "3                     4.675              1.23925                  0.000   \n",
       "4                     9.450              1.22500            2240127.750   \n",
       "\n",
       "   clear_sky_rad:W  cloud_base_agl:m  dew_or_rime:idx  dew_point_2m:K  \\\n",
       "0       194.449997       2426.750000              0.0      277.625000   \n",
       "1         0.000000        971.250000              0.0      273.600006   \n",
       "2       175.350006       3255.375000              0.0      279.075012   \n",
       "3         0.000000       2067.925049              0.0      272.924988   \n",
       "4       591.500000        115.849998              0.0      283.324982   \n",
       "\n",
       "   diffuse_rad:W  diffuse_rad_1h:J  direct_rad:W  direct_rad_1h:J  \\\n",
       "0      88.175003     348536.406250     70.375000    271995.531250   \n",
       "1       0.000000          0.000000      0.000000         0.000000   \n",
       "2      50.824997     206314.859375    120.599998    537617.250000   \n",
       "3       0.000000          0.000000      0.000000         0.000000   \n",
       "4     138.100006     454697.093750     66.150002    185963.796875   \n",
       "\n",
       "   effective_cloud_cover:p  is_day:idx  is_in_shadow:idx  precip_5min:mm  \\\n",
       "0                62.900002         1.0               0.0          0.0000   \n",
       "1                99.425003         0.0               1.0          0.0000   \n",
       "2                 5.250000         1.0               0.0          0.0000   \n",
       "3                91.949997         0.0               1.0          0.0000   \n",
       "4                96.349998         1.0               0.0          0.0125   \n",
       "\n",
       "   precip_type_5min:idx  pressure_50m:hPa  prob_rime:p  rain_water:kgm2  \\\n",
       "0                  0.00       1018.400024          0.0              0.0   \n",
       "1                  0.00       1010.150024          0.0              0.0   \n",
       "2                  0.00        995.099976          0.0              0.0   \n",
       "3                  0.00        981.574951          0.0              0.0   \n",
       "4                  0.25       1001.400024          0.0              0.0   \n",
       "\n",
       "   relative_humidity_1000hPa:p  sun_azimuth:d  super_cooled_liquid_water:kgm2  \\\n",
       "0                    58.174999     242.404755                           0.000   \n",
       "1                    73.949997     309.972748                           0.100   \n",
       "2                    45.700001     230.077255                           0.000   \n",
       "3                    65.949997     252.160492                           0.000   \n",
       "4                    88.900002     216.283997                           0.275   \n",
       "\n",
       "   t_1000hPa:K  total_cloud_cover:p  visibility:m  wind_speed_10m:ms  \\\n",
       "0   281.774994           100.000000  43816.324219              0.725   \n",
       "1   276.625000            99.425003  33486.976562              2.825   \n",
       "2   289.299988             6.050000  57556.351562              4.925   \n",
       "3   279.774994            98.974998  45661.750000              3.800   \n",
       "4   284.000000            98.199997   5958.750000              4.525   \n",
       "\n",
       "   wind_speed_u_10m:ms  wind_speed_v_10m:ms  wind_speed_w_1000hPa:ms  \\\n",
       "0               -0.250               -0.700                      0.0   \n",
       "1                1.125                2.600                      0.0   \n",
       "2               -0.275                4.925                      0.0   \n",
       "3                1.100                3.625                      0.0   \n",
       "4                4.100               -1.950                      0.0   \n",
       "\n",
       "   location_a  location_b  location_c  sin_day_of_year  cos_day_of_year  \\\n",
       "0           1           0           0         0.984306         0.176471   \n",
       "1           1           0           0        -0.702148         0.712031   \n",
       "2           0           1           0        -0.999371         0.035473   \n",
       "3           1           0           0        -0.638384         0.769718   \n",
       "4           0           0           1        -0.739392        -0.673275   \n",
       "\n",
       "   sin_hour  cos_hour  sun_product  modified_solar_elevation  \\\n",
       "0 -0.707107 -0.707107  6205.315918                  0.242142   \n",
       "1 -0.866025  0.500000     0.000000                  0.000000   \n",
       "2 -0.500000 -0.866025  6129.494629                  0.226685   \n",
       "3 -0.866025 -0.500000     0.000000                  0.000000   \n",
       "4 -0.258819 -0.965926  9135.315430                  0.571108   \n",
       "\n",
       "   effective_radiation  time_since_prediction  cloud_ratio  \\\n",
       "0             0.301401                      0     0.629000   \n",
       "1             0.000000                      0     1.000000   \n",
       "2             0.674081                      0     0.867769   \n",
       "3             0.000000                      0     0.929022   \n",
       "4             0.083015                      0     0.981161   \n",
       "\n",
       "   cloud_cover_over_30%  sun_addition  is_freezing  is_snow  is_rain  \n",
       "0                     1    158.550003            0        0        0  \n",
       "1                     1      0.000000            0        0        0  \n",
       "2                     0    171.424988            0        0        0  \n",
       "3                     1      0.000000            0        0        0  \n",
       "4                     1    204.250000            0        0        1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data\n",
    "train_a, train_b, train_c, X_train_estimated_a, X_train_estimated_b, X_train_estimated_c, X_train_observed_a, X_train_observed_b, X_train_observed_c, X_test_estimated_a, X_test_estimated_b, X_test_estimated_c = get_raw_data()\n",
    "\n",
    "X_train_obs_combined, X_val_obs_combined, y_train_obs_combined, y_val_obs_combined, X_train_est_combined, X_val_est_combined, y_train_est_combined, y_val_est_combined = fetch_preprocessed_data()\n",
    "x_test_whole = get_preprocessed_test_data()\n",
    "\n",
    "x_whole = pd.concat([X_train_obs_combined, X_val_obs_combined, X_train_est_combined, X_val_est_combined])\n",
    "y_whole = pd.concat([y_train_obs_combined, y_val_obs_combined, y_train_est_combined, y_val_est_combined])\n",
    "x_whole.reset_index(drop=True, inplace=True)\n",
    "y_whole.reset_index(drop=True, inplace=True)\n",
    "\n",
    "x_whole_obs = pd.concat([X_train_obs_combined, X_val_obs_combined])\n",
    "y_whole_obs = pd.concat([y_train_obs_combined, y_val_obs_combined])\n",
    "\n",
    "x_whole_est = pd.concat([X_train_est_combined, X_val_est_combined])\n",
    "y_whole_est = pd.concat([y_train_est_combined, y_val_est_combined])\n",
    "\n",
    "x_whole.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 318.9886077\ttest: 312.6121514\tbest: 312.6121514 (0)\ttotal: 170ms\tremaining: 19d 17h 5m 33s\n",
      "200:\tlearn: 280.3981892\ttest: 274.5190665\tbest: 274.5190665 (200)\ttotal: 4.59s\tremaining: 2d 15h 25m 46s\n",
      "400:\tlearn: 244.7800494\ttest: 239.5292051\tbest: 239.5292051 (400)\ttotal: 9.05s\tremaining: 2d 14h 41m 15s\n",
      "600:\tlearn: 213.4104131\ttest: 208.8713912\tbest: 208.8713912 (600)\ttotal: 13.6s\tremaining: 2d 14h 52m 54s\n",
      "800:\tlearn: 188.1612567\ttest: 184.1085503\tbest: 184.1085503 (800)\ttotal: 17.9s\tremaining: 2d 14h 1m 59s\n",
      "1000:\tlearn: 168.9008429\ttest: 165.0950869\tbest: 165.0950869 (1000)\ttotal: 22.1s\tremaining: 2d 13h 18m 41s\n",
      "1200:\tlearn: 153.7744009\ttest: 150.2344591\tbest: 150.2344591 (1200)\ttotal: 26.2s\tremaining: 2d 12h 32m 11s\n",
      "1400:\tlearn: 141.8349193\ttest: 138.4925745\tbest: 138.4925745 (1400)\ttotal: 30.3s\tremaining: 2d 11h 59m 8s\n",
      "1600:\tlearn: 132.6183590\ttest: 129.5837296\tbest: 129.5837296 (1600)\ttotal: 34.3s\tremaining: 2d 11h 32m 8s\n",
      "1800:\tlearn: 125.3101823\ttest: 122.5186445\tbest: 122.5186445 (1800)\ttotal: 38.4s\tremaining: 2d 11h 16m 13s\n",
      "2000:\tlearn: 119.3271013\ttest: 116.7719036\tbest: 116.7719036 (2000)\ttotal: 42.5s\tremaining: 2d 11h 1m 41s\n",
      "2200:\tlearn: 114.4995951\ttest: 112.1169801\tbest: 112.1169801 (2200)\ttotal: 46.7s\tremaining: 2d 10h 53m 13s\n",
      "2400:\tlearn: 110.6577843\ttest: 108.4371104\tbest: 108.4371104 (2400)\ttotal: 50.8s\tremaining: 2d 10h 47m 12s\n",
      "2600:\tlearn: 107.3211043\ttest: 105.2195392\tbest: 105.2195392 (2600)\ttotal: 55s\tremaining: 2d 10h 40m 18s\n",
      "2800:\tlearn: 104.6881462\ttest: 102.6759762\tbest: 102.6759762 (2800)\ttotal: 59s\tremaining: 2d 10h 32m 3s\n",
      "3000:\tlearn: 102.4550341\ttest: 100.5135247\tbest: 100.5135247 (3000)\ttotal: 1m 3s\tremaining: 2d 10h 25m 15s\n",
      "3200:\tlearn: 100.7494125\ttest: 98.8673386\tbest: 98.8673386 (3200)\ttotal: 1m 7s\tremaining: 2d 10h 20m 49s\n",
      "3400:\tlearn: 99.3174556\ttest: 97.4931687\tbest: 97.4931687 (3400)\ttotal: 1m 11s\tremaining: 2d 10h 12m 51s\n",
      "3600:\tlearn: 98.2165318\ttest: 96.4378423\tbest: 96.4378423 (3600)\ttotal: 1m 15s\tremaining: 2d 10h 7m 22s\n",
      "3800:\tlearn: 97.2248249\ttest: 95.4944399\tbest: 95.4944399 (3800)\ttotal: 1m 19s\tremaining: 2d 10h 1m 29s\n",
      "4000:\tlearn: 96.4527619\ttest: 94.7687501\tbest: 94.7687501 (4000)\ttotal: 1m 23s\tremaining: 2d 9h 58m 17s\n",
      "4200:\tlearn: 95.7471717\ttest: 94.0982589\tbest: 94.0982589 (4200)\ttotal: 1m 27s\tremaining: 2d 9h 52m 5s\n",
      "4400:\tlearn: 95.1924886\ttest: 93.5723442\tbest: 93.5723442 (4400)\ttotal: 1m 31s\tremaining: 2d 9h 46m 42s\n",
      "4600:\tlearn: 94.6656695\ttest: 93.0763636\tbest: 93.0763636 (4600)\ttotal: 1m 35s\tremaining: 2d 9h 42m 58s\n",
      "4800:\tlearn: 94.2298590\ttest: 92.6590817\tbest: 92.6590817 (4800)\ttotal: 1m 39s\tremaining: 2d 9h 38m 59s\n",
      "5000:\tlearn: 93.8655828\ttest: 92.3075480\tbest: 92.3075480 (5000)\ttotal: 1m 43s\tremaining: 2d 9h 37m 42s\n",
      "5200:\tlearn: 93.6114793\ttest: 92.0611230\tbest: 92.0611230 (5200)\ttotal: 1m 47s\tremaining: 2d 9h 36m 44s\n",
      "5400:\tlearn: 93.3770898\ttest: 91.8352871\tbest: 91.8352871 (5400)\ttotal: 1m 52s\tremaining: 2d 9h 38m 19s\n",
      "5600:\tlearn: 93.1565158\ttest: 91.6180280\tbest: 91.6180280 (5600)\ttotal: 1m 56s\tremaining: 2d 9h 40m 3s\n",
      "5800:\tlearn: 92.9568203\ttest: 91.4277875\tbest: 91.4277875 (5800)\ttotal: 2m\tremaining: 2d 9h 39m 29s\n",
      "6000:\tlearn: 92.7904801\ttest: 91.2727534\tbest: 91.2727534 (6000)\ttotal: 2m 4s\tremaining: 2d 9h 41m 42s\n",
      "6200:\tlearn: 92.6259070\ttest: 91.1201943\tbest: 91.1201943 (6200)\ttotal: 2m 8s\tremaining: 2d 9h 43m 29s\n",
      "6400:\tlearn: 92.4857975\ttest: 90.9893617\tbest: 90.9893617 (6400)\ttotal: 2m 13s\tremaining: 2d 9h 44m 46s\n",
      "6600:\tlearn: 92.3434626\ttest: 90.8572805\tbest: 90.8572805 (6600)\ttotal: 2m 17s\tremaining: 2d 9h 44m 32s\n",
      "6800:\tlearn: 92.2240916\ttest: 90.7484178\tbest: 90.7484178 (6800)\ttotal: 2m 21s\tremaining: 2d 9h 44m 12s\n",
      "7000:\tlearn: 92.0850450\ttest: 90.6227163\tbest: 90.6227163 (7000)\ttotal: 2m 25s\tremaining: 2d 9h 43m 36s\n",
      "7200:\tlearn: 91.9693287\ttest: 90.5185945\tbest: 90.5185945 (7200)\ttotal: 2m 29s\tremaining: 2d 9h 42m 11s\n",
      "7400:\tlearn: 91.8598627\ttest: 90.4222415\tbest: 90.4222415 (7400)\ttotal: 2m 33s\tremaining: 2d 9h 41m 36s\n",
      "7600:\tlearn: 91.7616136\ttest: 90.3344549\tbest: 90.3344549 (7600)\ttotal: 2m 37s\tremaining: 2d 9h 40m 54s\n",
      "7800:\tlearn: 91.6563665\ttest: 90.2431153\tbest: 90.2431153 (7800)\ttotal: 2m 42s\tremaining: 2d 9h 39m 15s\n",
      "8000:\tlearn: 91.5461032\ttest: 90.1487317\tbest: 90.1487317 (8000)\ttotal: 2m 46s\tremaining: 2d 9h 37m 50s\n",
      "8200:\tlearn: 91.4485618\ttest: 90.0642904\tbest: 90.0642904 (8200)\ttotal: 2m 50s\tremaining: 2d 9h 36m 39s\n",
      "8400:\tlearn: 91.3402763\ttest: 89.9766007\tbest: 89.9766007 (8400)\ttotal: 2m 54s\tremaining: 2d 9h 36m 24s\n",
      "8600:\tlearn: 91.2370257\ttest: 89.8913922\tbest: 89.8913922 (8600)\ttotal: 2m 58s\tremaining: 2d 9h 38m 41s\n",
      "8800:\tlearn: 91.1501196\ttest: 89.8171911\tbest: 89.8171911 (8800)\ttotal: 3m 2s\tremaining: 2d 9h 37m 55s\n",
      "9000:\tlearn: 91.0512921\ttest: 89.7324285\tbest: 89.7324285 (9000)\ttotal: 3m 6s\tremaining: 2d 9h 37m 21s\n",
      "9200:\tlearn: 90.9452585\ttest: 89.6485103\tbest: 89.6485103 (9200)\ttotal: 3m 11s\tremaining: 2d 9h 37m 15s\n",
      "9400:\tlearn: 90.8612077\ttest: 89.5801874\tbest: 89.5801874 (9400)\ttotal: 3m 15s\tremaining: 2d 9h 36m 26s\n",
      "9600:\tlearn: 90.7717978\ttest: 89.5065888\tbest: 89.5065888 (9600)\ttotal: 3m 19s\tremaining: 2d 9h 35m 34s\n",
      "9800:\tlearn: 90.6783583\ttest: 89.4273393\tbest: 89.4273393 (9800)\ttotal: 3m 23s\tremaining: 2d 9h 33m 59s\n",
      "10000:\tlearn: 90.5887186\ttest: 89.3534443\tbest: 89.3534443 (10000)\ttotal: 3m 27s\tremaining: 2d 9h 34m 43s\n",
      "10200:\tlearn: 90.5022136\ttest: 89.2796255\tbest: 89.2796255 (10200)\ttotal: 3m 31s\tremaining: 2d 9h 33m 51s\n",
      "10400:\tlearn: 90.4180258\ttest: 89.2116372\tbest: 89.2116372 (10400)\ttotal: 3m 35s\tremaining: 2d 9h 33m 37s\n",
      "10600:\tlearn: 90.3413163\ttest: 89.1490997\tbest: 89.1490997 (10600)\ttotal: 3m 39s\tremaining: 2d 9h 32m 52s\n",
      "10800:\tlearn: 90.2559045\ttest: 89.0809540\tbest: 89.0809540 (10800)\ttotal: 3m 43s\tremaining: 2d 9h 32m 7s\n",
      "11000:\tlearn: 90.1820585\ttest: 89.0175442\tbest: 89.0175442 (11000)\ttotal: 3m 48s\tremaining: 2d 9h 31m 44s\n",
      "11200:\tlearn: 90.1039885\ttest: 88.9571166\tbest: 88.9571166 (11200)\ttotal: 3m 52s\tremaining: 2d 9h 31m 5s\n",
      "11400:\tlearn: 90.0174240\ttest: 88.8872669\tbest: 88.8872669 (11400)\ttotal: 3m 56s\tremaining: 2d 9h 30m 12s\n",
      "11600:\tlearn: 89.9419683\ttest: 88.8266846\tbest: 88.8266846 (11600)\ttotal: 4m\tremaining: 2d 9h 29m 28s\n",
      "11800:\tlearn: 89.8639392\ttest: 88.7653560\tbest: 88.7653560 (11800)\ttotal: 4m 4s\tremaining: 2d 9h 28m 11s\n",
      "12000:\tlearn: 89.7922171\ttest: 88.7089607\tbest: 88.7089607 (12000)\ttotal: 4m 8s\tremaining: 2d 9h 28m 2s\n",
      "12200:\tlearn: 89.7149296\ttest: 88.6497700\tbest: 88.6497700 (12200)\ttotal: 4m 12s\tremaining: 2d 9h 27m 25s\n",
      "12400:\tlearn: 89.6330486\ttest: 88.5880811\tbest: 88.5880811 (12400)\ttotal: 4m 17s\tremaining: 2d 9h 30m 46s\n",
      "12600:\tlearn: 89.5511020\ttest: 88.5290162\tbest: 88.5288918 (12599)\ttotal: 4m 21s\tremaining: 2d 9h 31m 5s\n",
      "12800:\tlearn: 89.4728518\ttest: 88.4769564\tbest: 88.4769564 (12800)\ttotal: 4m 25s\tremaining: 2d 9h 30m 8s\n",
      "13000:\tlearn: 89.3984425\ttest: 88.4216275\tbest: 88.4216275 (13000)\ttotal: 4m 29s\tremaining: 2d 9h 29m 41s\n",
      "13200:\tlearn: 89.3284034\ttest: 88.3704252\tbest: 88.3704252 (13200)\ttotal: 4m 33s\tremaining: 2d 9h 32m 25s\n",
      "13400:\tlearn: 89.2456921\ttest: 88.3088601\tbest: 88.3088601 (13400)\ttotal: 4m 38s\tremaining: 2d 9h 34m 44s\n",
      "13600:\tlearn: 89.1692854\ttest: 88.2522615\tbest: 88.2522615 (13600)\ttotal: 4m 42s\tremaining: 2d 9h 34m 50s\n",
      "13800:\tlearn: 89.0721417\ttest: 88.1813253\tbest: 88.1813253 (13800)\ttotal: 4m 46s\tremaining: 2d 9h 34m\n",
      "14000:\tlearn: 88.8665724\ttest: 88.0330305\tbest: 88.0330305 (14000)\ttotal: 4m 50s\tremaining: 2d 9h 33m 24s\n",
      "14200:\tlearn: 88.6789470\ttest: 87.9090797\tbest: 87.9090797 (14200)\ttotal: 4m 54s\tremaining: 2d 9h 33m 3s\n",
      "14400:\tlearn: 88.5190727\ttest: 87.7948230\tbest: 87.7948230 (14400)\ttotal: 4m 58s\tremaining: 2d 9h 31m 53s\n",
      "14600:\tlearn: 88.3549658\ttest: 87.6885248\tbest: 87.6885248 (14600)\ttotal: 5m 2s\tremaining: 2d 9h 31m 4s\n",
      "14800:\tlearn: 88.2299214\ttest: 87.6142365\tbest: 87.6142365 (14800)\ttotal: 5m 6s\tremaining: 2d 9h 29m 42s\n",
      "15000:\tlearn: 88.1326217\ttest: 87.5539466\tbest: 87.5539466 (15000)\ttotal: 5m 10s\tremaining: 2d 9h 29m 32s\n",
      "15200:\tlearn: 88.0091570\ttest: 87.4763134\tbest: 87.4763134 (15200)\ttotal: 5m 14s\tremaining: 2d 9h 28m 21s\n",
      "15400:\tlearn: 87.8964148\ttest: 87.4068073\tbest: 87.4068073 (15400)\ttotal: 5m 19s\tremaining: 2d 9h 27m 1s\n",
      "15600:\tlearn: 87.7927531\ttest: 87.3465297\tbest: 87.3465297 (15600)\ttotal: 5m 23s\tremaining: 2d 9h 25m 24s\n",
      "15800:\tlearn: 87.6469953\ttest: 87.2479122\tbest: 87.2479122 (15800)\ttotal: 5m 27s\tremaining: 2d 9h 24m 57s\n",
      "16000:\tlearn: 87.5299558\ttest: 87.1677471\tbest: 87.1677471 (16000)\ttotal: 5m 31s\tremaining: 2d 9h 24m 11s\n",
      "16200:\tlearn: 87.4070091\ttest: 87.0814256\tbest: 87.0814256 (16200)\ttotal: 5m 35s\tremaining: 2d 9h 24m 18s\n",
      "16400:\tlearn: 87.3003213\ttest: 87.0058203\tbest: 87.0058203 (16400)\ttotal: 5m 39s\tremaining: 2d 9h 24m 16s\n",
      "16600:\tlearn: 87.2373460\ttest: 86.9670394\tbest: 86.9670394 (16600)\ttotal: 5m 43s\tremaining: 2d 9h 23m 55s\n",
      "16800:\tlearn: 87.1061774\ttest: 86.8937121\tbest: 86.8937121 (16800)\ttotal: 5m 47s\tremaining: 2d 9h 22m 52s\n",
      "17000:\tlearn: 86.9501261\ttest: 86.8144898\tbest: 86.8144898 (17000)\ttotal: 5m 51s\tremaining: 2d 9h 23m\n",
      "17200:\tlearn: 86.8251102\ttest: 86.7342334\tbest: 86.7342334 (17200)\ttotal: 5m 55s\tremaining: 2d 9h 22m 36s\n",
      "17400:\tlearn: 86.6209116\ttest: 86.6032203\tbest: 86.6032203 (17400)\ttotal: 6m\tremaining: 2d 9h 22m 36s\n",
      "17600:\tlearn: 86.4522770\ttest: 86.4901605\tbest: 86.4901605 (17600)\ttotal: 6m 4s\tremaining: 2d 9h 21m 12s\n",
      "17800:\tlearn: 86.2975436\ttest: 86.4078506\tbest: 86.4078506 (17800)\ttotal: 6m 8s\tremaining: 2d 9h 19m 43s\n",
      "18000:\tlearn: 86.1818407\ttest: 86.3369310\tbest: 86.3369310 (18000)\ttotal: 6m 12s\tremaining: 2d 9h 19m 15s\n",
      "18200:\tlearn: 86.0928496\ttest: 86.2803595\tbest: 86.2803595 (18200)\ttotal: 6m 16s\tremaining: 2d 9h 19m 41s\n",
      "18400:\tlearn: 85.9779754\ttest: 86.2045957\tbest: 86.2045957 (18400)\ttotal: 6m 20s\tremaining: 2d 9h 20m 18s\n",
      "18600:\tlearn: 85.8646921\ttest: 86.1385943\tbest: 86.1385943 (18600)\ttotal: 6m 24s\tremaining: 2d 9h 20m 4s\n",
      "18800:\tlearn: 85.7833358\ttest: 86.0855528\tbest: 86.0855528 (18800)\ttotal: 6m 28s\tremaining: 2d 9h 20m 6s\n",
      "19000:\tlearn: 85.6598018\ttest: 86.0133148\tbest: 86.0133148 (19000)\ttotal: 6m 32s\tremaining: 2d 9h 19m 45s\n",
      "19200:\tlearn: 85.5705994\ttest: 85.9636789\tbest: 85.9636789 (19200)\ttotal: 6m 37s\tremaining: 2d 9h 19m 29s\n",
      "19400:\tlearn: 85.4958110\ttest: 85.9143664\tbest: 85.9143664 (19400)\ttotal: 6m 41s\tremaining: 2d 9h 18m 53s\n",
      "19600:\tlearn: 85.4338130\ttest: 85.8751253\tbest: 85.8751253 (19600)\ttotal: 6m 45s\tremaining: 2d 9h 18m 13s\n",
      "19800:\tlearn: 85.3684283\ttest: 85.8340148\tbest: 85.8340148 (19800)\ttotal: 6m 49s\tremaining: 2d 9h 16m 58s\n",
      "20000:\tlearn: 85.3209148\ttest: 85.8052251\tbest: 85.8052251 (20000)\ttotal: 6m 53s\tremaining: 2d 9h 17m 39s\n",
      "20200:\tlearn: 85.2768923\ttest: 85.7809395\tbest: 85.7809395 (20200)\ttotal: 6m 57s\tremaining: 2d 9h 18m 34s\n",
      "20400:\tlearn: 85.2394181\ttest: 85.7589769\tbest: 85.7589769 (20400)\ttotal: 7m 1s\tremaining: 2d 9h 16m 49s\n",
      "20600:\tlearn: 85.1964038\ttest: 85.7324228\tbest: 85.7323974 (20598)\ttotal: 7m 5s\tremaining: 2d 9h 15m 58s\n",
      "20800:\tlearn: 85.1630083\ttest: 85.7097941\tbest: 85.7097941 (20800)\ttotal: 7m 9s\tremaining: 2d 9h 14m 55s\n",
      "21000:\tlearn: 85.1201434\ttest: 85.6816525\tbest: 85.6816525 (21000)\ttotal: 7m 13s\tremaining: 2d 9h 13m 47s\n",
      "21200:\tlearn: 85.0826977\ttest: 85.6567806\tbest: 85.6567806 (21200)\ttotal: 7m 17s\tremaining: 2d 9h 12m 57s\n",
      "21400:\tlearn: 85.0340915\ttest: 85.6253161\tbest: 85.6253161 (21400)\ttotal: 7m 21s\tremaining: 2d 9h 13m 22s\n",
      "21600:\tlearn: 84.9806410\ttest: 85.5907251\tbest: 85.5907251 (21600)\ttotal: 7m 25s\tremaining: 2d 9h 13m 4s\n",
      "21800:\tlearn: 84.9456658\ttest: 85.5687211\tbest: 85.5687211 (21800)\ttotal: 7m 29s\tremaining: 2d 9h 12m 9s\n",
      "22000:\tlearn: 84.9096005\ttest: 85.5475423\tbest: 85.5475423 (22000)\ttotal: 7m 33s\tremaining: 2d 9h 11m 38s\n",
      "22200:\tlearn: 84.8761381\ttest: 85.5281134\tbest: 85.5281134 (22200)\ttotal: 7m 38s\tremaining: 2d 9h 11m 21s\n",
      "22400:\tlearn: 84.8481303\ttest: 85.5124692\tbest: 85.5124692 (22400)\ttotal: 7m 42s\tremaining: 2d 9h 10m 26s\n",
      "22600:\tlearn: 84.8137019\ttest: 85.4915149\tbest: 85.4915149 (22600)\ttotal: 7m 46s\tremaining: 2d 9h 9m 43s\n",
      "22800:\tlearn: 84.7826112\ttest: 85.4717262\tbest: 85.4717262 (22800)\ttotal: 7m 50s\tremaining: 2d 9h 9m 21s\n",
      "23000:\tlearn: 84.7550250\ttest: 85.4549327\tbest: 85.4549327 (23000)\ttotal: 7m 54s\tremaining: 2d 9h 8m 31s\n",
      "23200:\tlearn: 84.7259262\ttest: 85.4378202\tbest: 85.4378202 (23200)\ttotal: 7m 58s\tremaining: 2d 9h 8m 15s\n",
      "23400:\tlearn: 84.6970828\ttest: 85.4198379\tbest: 85.4198379 (23400)\ttotal: 8m 2s\tremaining: 2d 9h 7m 25s\n",
      "23600:\tlearn: 84.6629547\ttest: 85.3990327\tbest: 85.3990327 (23600)\ttotal: 8m 6s\tremaining: 2d 9h 6m 34s\n",
      "23800:\tlearn: 84.6465478\ttest: 85.3896309\tbest: 85.3896309 (23800)\ttotal: 8m 10s\tremaining: 2d 9h 5m 47s\n",
      "24000:\tlearn: 84.6393485\ttest: 85.3849963\tbest: 85.3849963 (24000)\ttotal: 8m 14s\tremaining: 2d 9h 5m 42s\n",
      "24200:\tlearn: 84.6302616\ttest: 85.3791977\tbest: 85.3791977 (24200)\ttotal: 8m 18s\tremaining: 2d 9h 5m 4s\n",
      "24400:\tlearn: 84.6226776\ttest: 85.3746096\tbest: 85.3746096 (24400)\ttotal: 8m 22s\tremaining: 2d 9h 4m 31s\n",
      "24600:\tlearn: 84.6098264\ttest: 85.3667622\tbest: 85.3667622 (24600)\ttotal: 8m 26s\tremaining: 2d 9h 3m 59s\n",
      "24800:\tlearn: 84.5985363\ttest: 85.3593464\tbest: 85.3593464 (24800)\ttotal: 8m 30s\tremaining: 2d 9h 3m 57s\n",
      "25000:\tlearn: 84.5801641\ttest: 85.3469103\tbest: 85.3469103 (25000)\ttotal: 8m 34s\tremaining: 2d 9h 3m 25s\n",
      "25200:\tlearn: 84.5412221\ttest: 85.3214315\tbest: 85.3214315 (25200)\ttotal: 8m 38s\tremaining: 2d 9h 3m 20s\n",
      "25400:\tlearn: 84.5016569\ttest: 85.2967931\tbest: 85.2967931 (25400)\ttotal: 8m 43s\tremaining: 2d 9h 3m 14s\n",
      "25600:\tlearn: 84.4449718\ttest: 85.2588432\tbest: 85.2588432 (25600)\ttotal: 8m 47s\tremaining: 2d 9h 2m 31s\n",
      "25800:\tlearn: 84.3894783\ttest: 85.2227755\tbest: 85.2227755 (25800)\ttotal: 8m 51s\tremaining: 2d 9h 2m 7s\n",
      "26000:\tlearn: 84.3421129\ttest: 85.1935022\tbest: 85.1935022 (26000)\ttotal: 8m 55s\tremaining: 2d 9h 1m 33s\n",
      "26200:\tlearn: 84.3056594\ttest: 85.1729276\tbest: 85.1729276 (26200)\ttotal: 8m 59s\tremaining: 2d 9h 2m 33s\n",
      "26400:\tlearn: 84.2654611\ttest: 85.1481255\tbest: 85.1481255 (26400)\ttotal: 9m 3s\tremaining: 2d 9h 1m 45s\n",
      "26600:\tlearn: 84.2120056\ttest: 85.1150022\tbest: 85.1150022 (26600)\ttotal: 9m 7s\tremaining: 2d 9h 1m 16s\n",
      "26800:\tlearn: 84.1560710\ttest: 85.0792491\tbest: 85.0792491 (26800)\ttotal: 9m 11s\tremaining: 2d 9h 32s\n",
      "27000:\tlearn: 84.1076490\ttest: 85.0494126\tbest: 85.0493832 (26998)\ttotal: 9m 15s\tremaining: 2d 8h 59m 46s\n",
      "27200:\tlearn: 84.0826868\ttest: 85.0349469\tbest: 85.0349453 (27199)\ttotal: 9m 19s\tremaining: 2d 8h 58m 50s\n",
      "27400:\tlearn: 84.0438943\ttest: 85.0130587\tbest: 85.0130587 (27400)\ttotal: 9m 23s\tremaining: 2d 8h 58m 9s\n",
      "27600:\tlearn: 84.0156743\ttest: 84.9947701\tbest: 84.9947701 (27600)\ttotal: 9m 27s\tremaining: 2d 8h 57m 9s\n",
      "27800:\tlearn: 83.9527739\ttest: 84.9566260\tbest: 84.9566260 (27800)\ttotal: 9m 31s\tremaining: 2d 8h 56m 46s\n",
      "28000:\tlearn: 83.8865200\ttest: 84.9155581\tbest: 84.9155557 (27999)\ttotal: 9m 35s\tremaining: 2d 8h 55m 42s\n",
      "28200:\tlearn: 83.8465201\ttest: 84.8930560\tbest: 84.8930560 (28200)\ttotal: 9m 39s\tremaining: 2d 8h 55m 10s\n",
      "28400:\tlearn: 83.8158767\ttest: 84.8731654\tbest: 84.8731654 (28400)\ttotal: 9m 43s\tremaining: 2d 8h 55m 5s\n",
      "28600:\tlearn: 83.7781949\ttest: 84.8497070\tbest: 84.8497070 (28600)\ttotal: 9m 47s\tremaining: 2d 8h 54m 51s\n",
      "28800:\tlearn: 83.7289228\ttest: 84.8185062\tbest: 84.8185062 (28800)\ttotal: 9m 51s\tremaining: 2d 8h 54m 9s\n",
      "29000:\tlearn: 83.7005824\ttest: 84.8010275\tbest: 84.8010275 (29000)\ttotal: 9m 55s\tremaining: 2d 8h 53m 40s\n",
      "29200:\tlearn: 83.6697264\ttest: 84.7808915\tbest: 84.7808915 (29200)\ttotal: 9m 59s\tremaining: 2d 8h 53m 19s\n",
      "29400:\tlearn: 83.6368154\ttest: 84.7613979\tbest: 84.7613979 (29400)\ttotal: 10m 3s\tremaining: 2d 8h 52m 41s\n",
      "29600:\tlearn: 83.6103144\ttest: 84.7481593\tbest: 84.7481593 (29600)\ttotal: 10m 8s\tremaining: 2d 8h 54m 55s\n",
      "29800:\tlearn: 83.5791564\ttest: 84.7311550\tbest: 84.7311550 (29800)\ttotal: 10m 12s\tremaining: 2d 8h 55m 9s\n",
      "30000:\tlearn: 83.5422569\ttest: 84.7122602\tbest: 84.7122602 (30000)\ttotal: 10m 16s\tremaining: 2d 8h 55m 19s\n",
      "30200:\tlearn: 83.5091734\ttest: 84.6944268\tbest: 84.6944268 (30200)\ttotal: 10m 20s\tremaining: 2d 8h 55m 10s\n",
      "30400:\tlearn: 83.4721997\ttest: 84.6719109\tbest: 84.6719109 (30400)\ttotal: 10m 24s\tremaining: 2d 8h 54m 41s\n",
      "30600:\tlearn: 83.4308296\ttest: 84.6477738\tbest: 84.6477738 (30600)\ttotal: 10m 28s\tremaining: 2d 8h 54m 59s\n",
      "30800:\tlearn: 83.3755103\ttest: 84.6160210\tbest: 84.6160210 (30800)\ttotal: 10m 33s\tremaining: 2d 8h 54m 42s\n",
      "31000:\tlearn: 83.3262433\ttest: 84.5893695\tbest: 84.5893695 (31000)\ttotal: 10m 37s\tremaining: 2d 8h 54m 59s\n",
      "31200:\tlearn: 83.2758246\ttest: 84.5608614\tbest: 84.5608614 (31200)\ttotal: 10m 41s\tremaining: 2d 8h 54m 27s\n",
      "31400:\tlearn: 83.2161768\ttest: 84.5252346\tbest: 84.5252346 (31400)\ttotal: 10m 45s\tremaining: 2d 8h 54m 19s\n",
      "31600:\tlearn: 83.1466029\ttest: 84.4861584\tbest: 84.4861584 (31600)\ttotal: 10m 49s\tremaining: 2d 8h 54m 23s\n",
      "31800:\tlearn: 83.0675396\ttest: 84.4405509\tbest: 84.4405509 (31800)\ttotal: 10m 53s\tremaining: 2d 8h 53m 57s\n",
      "32000:\tlearn: 83.0062857\ttest: 84.4051896\tbest: 84.4051849 (31999)\ttotal: 10m 57s\tremaining: 2d 8h 53m 50s\n",
      "32200:\tlearn: 82.9446367\ttest: 84.3714743\tbest: 84.3714743 (32200)\ttotal: 11m 1s\tremaining: 2d 8h 53m 8s\n",
      "32400:\tlearn: 82.8834930\ttest: 84.3356152\tbest: 84.3356152 (32400)\ttotal: 11m 5s\tremaining: 2d 8h 52m 54s\n",
      "32600:\tlearn: 82.8204266\ttest: 84.3005664\tbest: 84.3005664 (32600)\ttotal: 11m 9s\tremaining: 2d 8h 52m 36s\n",
      "32800:\tlearn: 82.7542752\ttest: 84.2653171\tbest: 84.2653171 (32800)\ttotal: 11m 13s\tremaining: 2d 8h 51m 53s\n",
      "33000:\tlearn: 82.6892702\ttest: 84.2297049\tbest: 84.2297049 (33000)\ttotal: 11m 17s\tremaining: 2d 8h 51m 39s\n",
      "33200:\tlearn: 82.6314120\ttest: 84.1969647\tbest: 84.1969647 (33200)\ttotal: 11m 21s\tremaining: 2d 8h 51m 44s\n",
      "33400:\tlearn: 82.5548761\ttest: 84.1531041\tbest: 84.1531041 (33400)\ttotal: 11m 25s\tremaining: 2d 8h 51m 17s\n",
      "33600:\tlearn: 82.4727755\ttest: 84.1110851\tbest: 84.1110851 (33600)\ttotal: 11m 29s\tremaining: 2d 8h 50m 53s\n",
      "33800:\tlearn: 82.3948498\ttest: 84.0660800\tbest: 84.0660230 (33799)\ttotal: 11m 33s\tremaining: 2d 8h 50m 18s\n",
      "34000:\tlearn: 82.3073170\ttest: 84.0231922\tbest: 84.0231922 (34000)\ttotal: 11m 38s\tremaining: 2d 8h 50m\n",
      "34200:\tlearn: 82.2371785\ttest: 83.9848178\tbest: 83.9848178 (34200)\ttotal: 11m 42s\tremaining: 2d 8h 49m 48s\n",
      "34400:\tlearn: 82.1566527\ttest: 83.9433004\tbest: 83.9433004 (34400)\ttotal: 11m 46s\tremaining: 2d 8h 49m 27s\n",
      "34600:\tlearn: 82.0880365\ttest: 83.9069765\tbest: 83.9069765 (34600)\ttotal: 11m 50s\tremaining: 2d 8h 48m 48s\n",
      "34800:\tlearn: 82.0110784\ttest: 83.8649867\tbest: 83.8649867 (34800)\ttotal: 11m 54s\tremaining: 2d 8h 48m 30s\n",
      "35000:\tlearn: 81.9161622\ttest: 83.8134082\tbest: 83.8134082 (35000)\ttotal: 11m 58s\tremaining: 2d 8h 48m 42s\n",
      "35200:\tlearn: 81.8325795\ttest: 83.7689646\tbest: 83.7689646 (35200)\ttotal: 12m 2s\tremaining: 2d 8h 48m 36s\n",
      "35400:\tlearn: 81.7485595\ttest: 83.7258787\tbest: 83.7258787 (35400)\ttotal: 12m 6s\tremaining: 2d 8h 48m 10s\n",
      "35600:\tlearn: 81.6742050\ttest: 83.6867229\tbest: 83.6867229 (35600)\ttotal: 12m 10s\tremaining: 2d 8h 47m 24s\n",
      "35800:\tlearn: 81.6094073\ttest: 83.6530995\tbest: 83.6530995 (35800)\ttotal: 12m 14s\tremaining: 2d 8h 46m 57s\n",
      "36000:\tlearn: 81.5518528\ttest: 83.6247311\tbest: 83.6247311 (36000)\ttotal: 12m 18s\tremaining: 2d 8h 46m 18s\n",
      "36200:\tlearn: 81.4897358\ttest: 83.5925028\tbest: 83.5925028 (36200)\ttotal: 12m 22s\tremaining: 2d 8h 45m 57s\n",
      "36400:\tlearn: 81.4269898\ttest: 83.5608225\tbest: 83.5608225 (36400)\ttotal: 12m 26s\tremaining: 2d 8h 45m 17s\n",
      "36600:\tlearn: 81.3624391\ttest: 83.5270450\tbest: 83.5270330 (36599)\ttotal: 12m 30s\tremaining: 2d 8h 44m 26s\n",
      "36800:\tlearn: 81.2929378\ttest: 83.4904417\tbest: 83.4904417 (36800)\ttotal: 12m 34s\tremaining: 2d 8h 43m 42s\n",
      "37000:\tlearn: 81.2208118\ttest: 83.4517044\tbest: 83.4517044 (37000)\ttotal: 12m 38s\tremaining: 2d 8h 44m 19s\n",
      "37200:\tlearn: 81.1458405\ttest: 83.4128903\tbest: 83.4128903 (37200)\ttotal: 12m 42s\tremaining: 2d 8h 43m 43s\n",
      "37400:\tlearn: 81.0909809\ttest: 83.3822598\tbest: 83.3822598 (37400)\ttotal: 12m 46s\tremaining: 2d 8h 43m 11s\n",
      "37600:\tlearn: 81.0291227\ttest: 83.3505271\tbest: 83.3502872 (37598)\ttotal: 12m 50s\tremaining: 2d 8h 42m 35s\n",
      "37800:\tlearn: 80.9751107\ttest: 83.3210363\tbest: 83.3210363 (37800)\ttotal: 12m 54s\tremaining: 2d 8h 42m 10s\n",
      "38000:\tlearn: 80.9206176\ttest: 83.2902216\tbest: 83.2902216 (38000)\ttotal: 12m 58s\tremaining: 2d 8h 41m 35s\n",
      "38200:\tlearn: 80.8706354\ttest: 83.2642929\tbest: 83.2642929 (38200)\ttotal: 13m 2s\tremaining: 2d 8h 41m 6s\n",
      "38400:\tlearn: 80.8037173\ttest: 83.2312317\tbest: 83.2312317 (38400)\ttotal: 13m 6s\tremaining: 2d 8h 40m 34s\n",
      "38600:\tlearn: 80.7438682\ttest: 83.1999258\tbest: 83.1999258 (38600)\ttotal: 13m 10s\tremaining: 2d 8h 40m 14s\n",
      "38800:\tlearn: 80.6950453\ttest: 83.1725575\tbest: 83.1725575 (38800)\ttotal: 13m 14s\tremaining: 2d 8h 39m 56s\n",
      "39000:\tlearn: 80.6455162\ttest: 83.1472960\tbest: 83.1472960 (39000)\ttotal: 13m 18s\tremaining: 2d 8h 39m 31s\n",
      "39200:\tlearn: 80.5992145\ttest: 83.1268152\tbest: 83.1268152 (39200)\ttotal: 13m 22s\tremaining: 2d 8h 39m 15s\n",
      "39400:\tlearn: 80.5491128\ttest: 83.1007809\tbest: 83.1007809 (39400)\ttotal: 13m 26s\tremaining: 2d 8h 38m 49s\n",
      "39600:\tlearn: 80.4997578\ttest: 83.0758308\tbest: 83.0758308 (39600)\ttotal: 13m 30s\tremaining: 2d 8h 38m 11s\n",
      "39800:\tlearn: 80.4494436\ttest: 83.0511171\tbest: 83.0511171 (39800)\ttotal: 13m 34s\tremaining: 2d 8h 37m 42s\n",
      "40000:\tlearn: 80.4010030\ttest: 83.0275629\tbest: 83.0275629 (40000)\ttotal: 13m 38s\tremaining: 2d 8h 37m 9s\n",
      "40200:\tlearn: 80.3508059\ttest: 83.0010121\tbest: 83.0009457 (40199)\ttotal: 13m 42s\tremaining: 2d 8h 37m 43s\n",
      "40400:\tlearn: 80.3072487\ttest: 82.9814822\tbest: 82.9814822 (40400)\ttotal: 13m 46s\tremaining: 2d 8h 37m 32s\n",
      "40600:\tlearn: 80.2629596\ttest: 82.9604118\tbest: 82.9604118 (40600)\ttotal: 13m 50s\tremaining: 2d 8h 37m 14s\n",
      "40800:\tlearn: 80.2080381\ttest: 82.9365224\tbest: 82.9365224 (40800)\ttotal: 13m 54s\tremaining: 2d 8h 36m 43s\n",
      "41000:\tlearn: 80.1652210\ttest: 82.9166132\tbest: 82.9166132 (41000)\ttotal: 13m 58s\tremaining: 2d 8h 36m 17s\n",
      "41200:\tlearn: 80.1094585\ttest: 82.8890352\tbest: 82.8890352 (41200)\ttotal: 14m 3s\tremaining: 2d 8h 36m 14s\n",
      "41400:\tlearn: 80.0547779\ttest: 82.8653379\tbest: 82.8653379 (41400)\ttotal: 14m 7s\tremaining: 2d 8h 35m 49s\n",
      "41600:\tlearn: 79.9966011\ttest: 82.8366151\tbest: 82.8365538 (41594)\ttotal: 14m 11s\tremaining: 2d 8h 35m 11s\n",
      "41800:\tlearn: 79.9238785\ttest: 82.8056179\tbest: 82.8056179 (41800)\ttotal: 14m 15s\tremaining: 2d 8h 34m 53s\n",
      "42000:\tlearn: 79.8568762\ttest: 82.7718144\tbest: 82.7718144 (42000)\ttotal: 14m 19s\tremaining: 2d 8h 34m 32s\n",
      "42200:\tlearn: 79.7860257\ttest: 82.7370178\tbest: 82.7370178 (42200)\ttotal: 14m 23s\tremaining: 2d 8h 34m 5s\n",
      "42400:\tlearn: 79.7150278\ttest: 82.7035577\tbest: 82.7035577 (42400)\ttotal: 14m 26s\tremaining: 2d 8h 33m 21s\n",
      "42600:\tlearn: 79.6315776\ttest: 82.6621876\tbest: 82.6621876 (42600)\ttotal: 14m 30s\tremaining: 2d 8h 32m 44s\n",
      "42800:\tlearn: 79.5613123\ttest: 82.6304307\tbest: 82.6304307 (42800)\ttotal: 14m 34s\tremaining: 2d 8h 32m 31s\n",
      "43000:\tlearn: 79.5072909\ttest: 82.6031752\tbest: 82.6031752 (43000)\ttotal: 14m 38s\tremaining: 2d 8h 31m 55s\n",
      "43200:\tlearn: 79.4545857\ttest: 82.5777332\tbest: 82.5777332 (43200)\ttotal: 14m 42s\tremaining: 2d 8h 31m 8s\n",
      "43400:\tlearn: 79.4062551\ttest: 82.5541761\tbest: 82.5541761 (43400)\ttotal: 14m 46s\tremaining: 2d 8h 30m 44s\n",
      "43600:\tlearn: 79.3593354\ttest: 82.5290570\tbest: 82.5290570 (43600)\ttotal: 14m 50s\tremaining: 2d 8h 30m 35s\n",
      "43800:\tlearn: 79.3161642\ttest: 82.5061080\tbest: 82.5061080 (43800)\ttotal: 14m 54s\tremaining: 2d 8h 30m 10s\n",
      "44000:\tlearn: 79.2631533\ttest: 82.4816173\tbest: 82.4816173 (44000)\ttotal: 14m 59s\tremaining: 2d 8h 30m 20s\n",
      "44200:\tlearn: 79.2030401\ttest: 82.4529567\tbest: 82.4529567 (44200)\ttotal: 15m 3s\tremaining: 2d 8h 29m 51s\n",
      "44400:\tlearn: 79.1443122\ttest: 82.4247700\tbest: 82.4247700 (44400)\ttotal: 15m 7s\tremaining: 2d 8h 29m 40s\n",
      "44600:\tlearn: 79.1028550\ttest: 82.4070017\tbest: 82.4070017 (44600)\ttotal: 15m 10s\tremaining: 2d 8h 29m\n",
      "44800:\tlearn: 79.0501901\ttest: 82.3837917\tbest: 82.3837917 (44800)\ttotal: 15m 14s\tremaining: 2d 8h 28m 18s\n",
      "45000:\tlearn: 79.0050624\ttest: 82.3650865\tbest: 82.3650865 (45000)\ttotal: 15m 18s\tremaining: 2d 8h 27m 43s\n",
      "45200:\tlearn: 78.9535988\ttest: 82.3390282\tbest: 82.3390282 (45200)\ttotal: 15m 22s\tremaining: 2d 8h 27m 3s\n",
      "45400:\tlearn: 78.8920795\ttest: 82.3094480\tbest: 82.3094480 (45400)\ttotal: 15m 26s\tremaining: 2d 8h 26m 45s\n",
      "45600:\tlearn: 78.8337885\ttest: 82.2831984\tbest: 82.2831984 (45600)\ttotal: 15m 30s\tremaining: 2d 8h 26m 17s\n",
      "45800:\tlearn: 78.7709261\ttest: 82.2586167\tbest: 82.2586167 (45800)\ttotal: 15m 34s\tremaining: 2d 8h 25m 36s\n",
      "46000:\tlearn: 78.7070058\ttest: 82.2308709\tbest: 82.2308709 (46000)\ttotal: 15m 38s\tremaining: 2d 8h 25m 3s\n",
      "46200:\tlearn: 78.6579643\ttest: 82.2096357\tbest: 82.2096357 (46200)\ttotal: 15m 42s\tremaining: 2d 8h 24m 53s\n",
      "46400:\tlearn: 78.6074192\ttest: 82.1874811\tbest: 82.1874811 (46400)\ttotal: 15m 46s\tremaining: 2d 8h 24m 21s\n",
      "46600:\tlearn: 78.5532890\ttest: 82.1636221\tbest: 82.1636221 (46600)\ttotal: 15m 50s\tremaining: 2d 8h 23m 44s\n",
      "46800:\tlearn: 78.5036942\ttest: 82.1400616\tbest: 82.1400616 (46800)\ttotal: 15m 54s\tremaining: 2d 8h 23m 9s\n",
      "47000:\tlearn: 78.4635832\ttest: 82.1184916\tbest: 82.1184916 (47000)\ttotal: 15m 58s\tremaining: 2d 8h 22m 38s\n",
      "47200:\tlearn: 78.4189149\ttest: 82.0983967\tbest: 82.0983967 (47200)\ttotal: 16m 2s\tremaining: 2d 8h 22m 2s\n",
      "47400:\tlearn: 78.3814274\ttest: 82.0801465\tbest: 82.0801465 (47400)\ttotal: 16m 6s\tremaining: 2d 8h 21m 40s\n",
      "47600:\tlearn: 78.3391651\ttest: 82.0568543\tbest: 82.0568543 (47600)\ttotal: 16m 10s\tremaining: 2d 8h 21m 9s\n",
      "47800:\tlearn: 78.2833919\ttest: 82.0309378\tbest: 82.0309326 (47799)\ttotal: 16m 14s\tremaining: 2d 8h 21m\n",
      "48000:\tlearn: 78.2347482\ttest: 82.0095292\tbest: 82.0095292 (48000)\ttotal: 16m 18s\tremaining: 2d 8h 20m 47s\n",
      "48200:\tlearn: 78.1835736\ttest: 81.9854784\tbest: 81.9854784 (48200)\ttotal: 16m 22s\tremaining: 2d 8h 20m 30s\n",
      "48400:\tlearn: 78.1372897\ttest: 81.9626385\tbest: 81.9626385 (48400)\ttotal: 16m 26s\tremaining: 2d 8h 19m 56s\n",
      "48600:\tlearn: 78.0977529\ttest: 81.9444099\tbest: 81.9444099 (48600)\ttotal: 16m 30s\tremaining: 2d 8h 19m 25s\n",
      "48800:\tlearn: 78.0500129\ttest: 81.9233988\tbest: 81.9233988 (48800)\ttotal: 16m 34s\tremaining: 2d 8h 18m 43s\n",
      "49000:\tlearn: 77.9995322\ttest: 81.8988165\tbest: 81.8988165 (49000)\ttotal: 16m 38s\tremaining: 2d 8h 18m 13s\n",
      "49200:\tlearn: 77.9568062\ttest: 81.8786457\tbest: 81.8786434 (49199)\ttotal: 16m 42s\tremaining: 2d 8h 17m 40s\n",
      "49400:\tlearn: 77.9152284\ttest: 81.8576794\tbest: 81.8576794 (49400)\ttotal: 16m 46s\tremaining: 2d 8h 17m 15s\n",
      "49600:\tlearn: 77.8608025\ttest: 81.8315840\tbest: 81.8315840 (49600)\ttotal: 16m 49s\tremaining: 2d 8h 16m 41s\n",
      "49800:\tlearn: 77.8094513\ttest: 81.8085194\tbest: 81.8085194 (49800)\ttotal: 16m 53s\tremaining: 2d 8h 16m 6s\n",
      "50000:\tlearn: 77.7570624\ttest: 81.7856901\tbest: 81.7856901 (50000)\ttotal: 16m 57s\tremaining: 2d 8h 15m 30s\n",
      "50200:\tlearn: 77.7073258\ttest: 81.7646687\tbest: 81.7646687 (50200)\ttotal: 17m 1s\tremaining: 2d 8h 14m 49s\n",
      "50400:\tlearn: 77.6544097\ttest: 81.7392923\tbest: 81.7392923 (50400)\ttotal: 17m 5s\tremaining: 2d 8h 14m 19s\n",
      "50600:\tlearn: 77.6092107\ttest: 81.7180903\tbest: 81.7180903 (50600)\ttotal: 17m 9s\tremaining: 2d 8h 14m 9s\n",
      "50800:\tlearn: 77.5690865\ttest: 81.6990227\tbest: 81.6990227 (50800)\ttotal: 17m 13s\tremaining: 2d 8h 13m 33s\n",
      "51000:\tlearn: 77.5176963\ttest: 81.6774402\tbest: 81.6774402 (51000)\ttotal: 17m 17s\tremaining: 2d 8h 13m 6s\n",
      "51200:\tlearn: 77.4631236\ttest: 81.6519291\tbest: 81.6519291 (51200)\ttotal: 17m 21s\tremaining: 2d 8h 12m 41s\n",
      "51400:\tlearn: 77.4110052\ttest: 81.6279438\tbest: 81.6279438 (51400)\ttotal: 17m 25s\tremaining: 2d 8h 12m 16s\n",
      "51600:\tlearn: 77.3548801\ttest: 81.6011415\tbest: 81.6011415 (51600)\ttotal: 17m 29s\tremaining: 2d 8h 11m 46s\n",
      "51800:\tlearn: 77.3132047\ttest: 81.5823601\tbest: 81.5823601 (51800)\ttotal: 17m 33s\tremaining: 2d 8h 11m 7s\n",
      "52000:\tlearn: 77.2675697\ttest: 81.5627295\tbest: 81.5627295 (52000)\ttotal: 17m 37s\tremaining: 2d 8h 10m 34s\n",
      "52200:\tlearn: 77.2239067\ttest: 81.5416547\tbest: 81.5416547 (52200)\ttotal: 17m 41s\tremaining: 2d 8h 9m 54s\n",
      "52400:\tlearn: 77.1802389\ttest: 81.5221965\tbest: 81.5221965 (52400)\ttotal: 17m 44s\tremaining: 2d 8h 9m 25s\n",
      "52600:\tlearn: 77.1354224\ttest: 81.5034105\tbest: 81.5033923 (52599)\ttotal: 17m 48s\tremaining: 2d 8h 8m 49s\n",
      "52800:\tlearn: 77.0935008\ttest: 81.4852086\tbest: 81.4852086 (52800)\ttotal: 17m 52s\tremaining: 2d 8h 8m 19s\n",
      "53000:\tlearn: 77.0393503\ttest: 81.4603514\tbest: 81.4603514 (53000)\ttotal: 17m 56s\tremaining: 2d 8h 7m 49s\n",
      "53200:\tlearn: 76.9984298\ttest: 81.4404104\tbest: 81.4404104 (53200)\ttotal: 18m\tremaining: 2d 8h 8m 4s\n",
      "53400:\tlearn: 76.9463553\ttest: 81.4164525\tbest: 81.4164525 (53400)\ttotal: 18m 4s\tremaining: 2d 8h 7m 51s\n",
      "53600:\tlearn: 76.8954922\ttest: 81.3938923\tbest: 81.3938923 (53600)\ttotal: 18m 8s\tremaining: 2d 8h 7m 18s\n",
      "53800:\tlearn: 76.8435712\ttest: 81.3697725\tbest: 81.3697725 (53800)\ttotal: 18m 12s\tremaining: 2d 8h 6m 47s\n",
      "54000:\tlearn: 76.7922701\ttest: 81.3450947\tbest: 81.3450947 (54000)\ttotal: 18m 16s\tremaining: 2d 8h 6m 15s\n",
      "54200:\tlearn: 76.7458840\ttest: 81.3252424\tbest: 81.3252424 (54200)\ttotal: 18m 20s\tremaining: 2d 8h 5m 57s\n",
      "54400:\tlearn: 76.7011103\ttest: 81.3034957\tbest: 81.3034957 (54399)\ttotal: 18m 24s\tremaining: 2d 8h 5m 36s\n",
      "54600:\tlearn: 76.6544098\ttest: 81.2813566\tbest: 81.2813566 (54600)\ttotal: 18m 28s\tremaining: 2d 8h 5m 13s\n",
      "54800:\tlearn: 76.6060758\ttest: 81.2599916\tbest: 81.2599916 (54800)\ttotal: 18m 32s\tremaining: 2d 8h 4m 51s\n",
      "55000:\tlearn: 76.5541140\ttest: 81.2358624\tbest: 81.2358624 (55000)\ttotal: 18m 36s\tremaining: 2d 8h 4m 28s\n",
      "55200:\tlearn: 76.5033822\ttest: 81.2118737\tbest: 81.2118737 (55200)\ttotal: 18m 40s\tremaining: 2d 8h 3m 58s\n",
      "55400:\tlearn: 76.4497365\ttest: 81.1866329\tbest: 81.1866329 (55400)\ttotal: 18m 44s\tremaining: 2d 8h 3m 32s\n",
      "55600:\tlearn: 76.3927481\ttest: 81.1600906\tbest: 81.1600906 (55600)\ttotal: 18m 48s\tremaining: 2d 8h 3m 14s\n",
      "55800:\tlearn: 76.3369134\ttest: 81.1369329\tbest: 81.1369329 (55800)\ttotal: 18m 52s\tremaining: 2d 8h 2m 52s\n",
      "56000:\tlearn: 76.2845772\ttest: 81.1168542\tbest: 81.1168521 (55999)\ttotal: 18m 56s\tremaining: 2d 8h 2m 19s\n",
      "56200:\tlearn: 76.2336273\ttest: 81.0980727\tbest: 81.0980727 (56200)\ttotal: 19m\tremaining: 2d 8h 1m 49s\n",
      "56400:\tlearn: 76.1912899\ttest: 81.0784367\tbest: 81.0784349 (56398)\ttotal: 19m 3s\tremaining: 2d 8h 1m 24s\n",
      "56600:\tlearn: 76.1485925\ttest: 81.0589717\tbest: 81.0589717 (56600)\ttotal: 19m 7s\tremaining: 2d 8h 57s\n",
      "56800:\tlearn: 76.1077160\ttest: 81.0412179\tbest: 81.0412179 (56800)\ttotal: 19m 11s\tremaining: 2d 8h 27s\n",
      "57000:\tlearn: 76.0554673\ttest: 81.0177809\tbest: 81.0177809 (57000)\ttotal: 19m 15s\tremaining: 2d 7h 59m 59s\n",
      "57200:\tlearn: 76.0096758\ttest: 80.9998143\tbest: 80.9998143 (57200)\ttotal: 19m 19s\tremaining: 2d 7h 59m 40s\n",
      "57400:\tlearn: 75.9619114\ttest: 80.9781362\tbest: 80.9781362 (57400)\ttotal: 19m 23s\tremaining: 2d 7h 59m 21s\n",
      "57600:\tlearn: 75.9189038\ttest: 80.9586298\tbest: 80.9586298 (57600)\ttotal: 19m 27s\tremaining: 2d 7h 58m 51s\n",
      "57800:\tlearn: 75.8756082\ttest: 80.9401936\tbest: 80.9401936 (57800)\ttotal: 19m 31s\tremaining: 2d 7h 58m 36s\n",
      "58000:\tlearn: 75.8307219\ttest: 80.9221944\tbest: 80.9221944 (58000)\ttotal: 19m 35s\tremaining: 2d 7h 58m 58s\n",
      "58200:\tlearn: 75.7829468\ttest: 80.9032032\tbest: 80.9031918 (58198)\ttotal: 19m 39s\tremaining: 2d 7h 58m 57s\n",
      "58400:\tlearn: 75.7486514\ttest: 80.8883490\tbest: 80.8883490 (58400)\ttotal: 19m 43s\tremaining: 2d 7h 58m 28s\n",
      "58600:\tlearn: 75.7226811\ttest: 80.8769042\tbest: 80.8769042 (58600)\ttotal: 19m 47s\tremaining: 2d 7h 58m 26s\n",
      "58800:\tlearn: 75.6996380\ttest: 80.8664529\tbest: 80.8664529 (58800)\ttotal: 19m 51s\tremaining: 2d 7h 58m 31s\n",
      "59000:\tlearn: 75.6762784\ttest: 80.8564184\tbest: 80.8564184 (59000)\ttotal: 19m 55s\tremaining: 2d 7h 58m 13s\n",
      "59200:\tlearn: 75.6551094\ttest: 80.8478921\tbest: 80.8478921 (59200)\ttotal: 19m 59s\tremaining: 2d 7h 58m 7s\n",
      "59400:\tlearn: 75.6188200\ttest: 80.8324851\tbest: 80.8324851 (59400)\ttotal: 20m 4s\tremaining: 2d 7h 58m 8s\n",
      "59600:\tlearn: 75.5885055\ttest: 80.8212061\tbest: 80.8211457 (59599)\ttotal: 20m 8s\tremaining: 2d 7h 58m 16s\n",
      "59800:\tlearn: 75.5486832\ttest: 80.8027781\tbest: 80.8027781 (59800)\ttotal: 20m 12s\tremaining: 2d 7h 57m 56s\n",
      "60000:\tlearn: 75.5073554\ttest: 80.7846950\tbest: 80.7846950 (59999)\ttotal: 20m 16s\tremaining: 2d 7h 57m 51s\n",
      "60200:\tlearn: 75.4705748\ttest: 80.7671872\tbest: 80.7671872 (60200)\ttotal: 20m 20s\tremaining: 2d 7h 57m 28s\n",
      "60400:\tlearn: 75.4342245\ttest: 80.7535925\tbest: 80.7535925 (60400)\ttotal: 20m 24s\tremaining: 2d 7h 57m 7s\n",
      "60600:\tlearn: 75.3948089\ttest: 80.7365391\tbest: 80.7365391 (60600)\ttotal: 20m 28s\tremaining: 2d 7h 56m 56s\n",
      "60800:\tlearn: 75.3479435\ttest: 80.7172027\tbest: 80.7172027 (60800)\ttotal: 20m 31s\tremaining: 2d 7h 56m 33s\n",
      "61000:\tlearn: 75.3049263\ttest: 80.7000025\tbest: 80.7000025 (61000)\ttotal: 20m 35s\tremaining: 2d 7h 56m 15s\n",
      "61200:\tlearn: 75.2699367\ttest: 80.6841226\tbest: 80.6841226 (61200)\ttotal: 20m 39s\tremaining: 2d 7h 56m 2s\n",
      "61400:\tlearn: 75.2316344\ttest: 80.6662943\tbest: 80.6662940 (61399)\ttotal: 20m 43s\tremaining: 2d 7h 55m 46s\n",
      "61600:\tlearn: 75.2002170\ttest: 80.6529469\tbest: 80.6529469 (61600)\ttotal: 20m 47s\tremaining: 2d 7h 55m 28s\n",
      "61800:\tlearn: 75.1530447\ttest: 80.6323656\tbest: 80.6323644 (61799)\ttotal: 20m 51s\tremaining: 2d 7h 55m 22s\n",
      "62000:\tlearn: 75.1013496\ttest: 80.6082266\tbest: 80.6082266 (62000)\ttotal: 20m 55s\tremaining: 2d 7h 54m 57s\n",
      "62200:\tlearn: 75.0660243\ttest: 80.5918156\tbest: 80.5918156 (62200)\ttotal: 20m 59s\tremaining: 2d 7h 54m 53s\n",
      "62400:\tlearn: 75.0256996\ttest: 80.5721097\tbest: 80.5721097 (62400)\ttotal: 21m 3s\tremaining: 2d 7h 54m 53s\n",
      "62600:\tlearn: 74.9902769\ttest: 80.5564612\tbest: 80.5564612 (62600)\ttotal: 21m 7s\tremaining: 2d 7h 54m 32s\n",
      "62800:\tlearn: 74.9647715\ttest: 80.5456899\tbest: 80.5456899 (62800)\ttotal: 21m 11s\tremaining: 2d 7h 54m 15s\n",
      "63000:\tlearn: 74.9398627\ttest: 80.5342018\tbest: 80.5342018 (63000)\ttotal: 21m 15s\tremaining: 2d 7h 53m 47s\n",
      "63200:\tlearn: 74.9174542\ttest: 80.5248494\tbest: 80.5248494 (63200)\ttotal: 21m 19s\tremaining: 2d 7h 53m 45s\n",
      "63400:\tlearn: 74.8919616\ttest: 80.5145067\tbest: 80.5145067 (63400)\ttotal: 21m 23s\tremaining: 2d 7h 53m 17s\n",
      "63600:\tlearn: 74.8597545\ttest: 80.5020541\tbest: 80.5020541 (63600)\ttotal: 21m 27s\tremaining: 2d 7h 52m 54s\n",
      "63800:\tlearn: 74.8347466\ttest: 80.4918807\tbest: 80.4918807 (63800)\ttotal: 21m 31s\tremaining: 2d 7h 52m 30s\n",
      "64000:\tlearn: 74.8017218\ttest: 80.4785003\tbest: 80.4785003 (64000)\ttotal: 21m 35s\tremaining: 2d 7h 52m 2s\n",
      "64200:\tlearn: 74.7628482\ttest: 80.4625857\tbest: 80.4625538 (64194)\ttotal: 21m 39s\tremaining: 2d 7h 51m 36s\n",
      "64400:\tlearn: 74.7257698\ttest: 80.4476331\tbest: 80.4476331 (64400)\ttotal: 21m 43s\tremaining: 2d 7h 51m 21s\n",
      "64600:\tlearn: 74.6913868\ttest: 80.4331526\tbest: 80.4331526 (64600)\ttotal: 21m 47s\tremaining: 2d 7h 50m 58s\n",
      "64800:\tlearn: 74.6508891\ttest: 80.4177965\tbest: 80.4177965 (64800)\ttotal: 21m 51s\tremaining: 2d 7h 50m 39s\n",
      "65000:\tlearn: 74.6110814\ttest: 80.4013088\tbest: 80.4013088 (65000)\ttotal: 21m 55s\tremaining: 2d 7h 50m 24s\n",
      "65200:\tlearn: 74.5666757\ttest: 80.3801368\tbest: 80.3801368 (65200)\ttotal: 21m 59s\tremaining: 2d 7h 50m 6s\n",
      "65400:\tlearn: 74.5262416\ttest: 80.3617162\tbest: 80.3617162 (65400)\ttotal: 22m 3s\tremaining: 2d 7h 49m 44s\n",
      "65600:\tlearn: 74.4870290\ttest: 80.3452784\tbest: 80.3452784 (65600)\ttotal: 22m 7s\tremaining: 2d 7h 49m 32s\n",
      "65800:\tlearn: 74.4523399\ttest: 80.3299822\tbest: 80.3299822 (65800)\ttotal: 22m 11s\tremaining: 2d 7h 49m 30s\n",
      "66000:\tlearn: 74.4170113\ttest: 80.3148659\tbest: 80.3148604 (65998)\ttotal: 22m 15s\tremaining: 2d 7h 49m 16s\n",
      "66200:\tlearn: 74.3720537\ttest: 80.2953966\tbest: 80.2953878 (66199)\ttotal: 22m 19s\tremaining: 2d 7h 49m 13s\n",
      "66400:\tlearn: 74.3345069\ttest: 80.2809284\tbest: 80.2807262 (66398)\ttotal: 22m 23s\tremaining: 2d 7h 48m 50s\n",
      "66600:\tlearn: 74.3016844\ttest: 80.2669520\tbest: 80.2667955 (66596)\ttotal: 22m 27s\tremaining: 2d 7h 48m 54s\n",
      "66800:\tlearn: 74.2733075\ttest: 80.2556270\tbest: 80.2556270 (66800)\ttotal: 22m 31s\tremaining: 2d 7h 48m 39s\n",
      "67000:\tlearn: 74.2459100\ttest: 80.2436301\tbest: 80.2436301 (67000)\ttotal: 22m 35s\tremaining: 2d 7h 48m 31s\n",
      "67200:\tlearn: 74.2139697\ttest: 80.2309750\tbest: 80.2309750 (67200)\ttotal: 22m 39s\tremaining: 2d 7h 48m 12s\n",
      "67400:\tlearn: 74.1840785\ttest: 80.2197672\tbest: 80.2197141 (67396)\ttotal: 22m 43s\tremaining: 2d 7h 48m 1s\n",
      "67600:\tlearn: 74.1547070\ttest: 80.2073532\tbest: 80.2071915 (67598)\ttotal: 22m 47s\tremaining: 2d 7h 47m 48s\n",
      "67800:\tlearn: 74.1192291\ttest: 80.1914721\tbest: 80.1914721 (67800)\ttotal: 22m 51s\tremaining: 2d 7h 47m 31s\n",
      "68000:\tlearn: 74.0871882\ttest: 80.1778628\tbest: 80.1778628 (68000)\ttotal: 22m 54s\tremaining: 2d 7h 47m 5s\n",
      "68200:\tlearn: 74.0560659\ttest: 80.1637252\tbest: 80.1637252 (68200)\ttotal: 22m 58s\tremaining: 2d 7h 46m 51s\n",
      "68400:\tlearn: 74.0167091\ttest: 80.1476406\tbest: 80.1476327 (68399)\ttotal: 23m 3s\tremaining: 2d 7h 46m 50s\n",
      "68600:\tlearn: 73.9844411\ttest: 80.1343973\tbest: 80.1343973 (68600)\ttotal: 23m 6s\tremaining: 2d 7h 46m 28s\n",
      "68800:\tlearn: 73.9547545\ttest: 80.1211934\tbest: 80.1211934 (68800)\ttotal: 23m 10s\tremaining: 2d 7h 46m 1s\n",
      "69000:\tlearn: 73.9248349\ttest: 80.1086248\tbest: 80.1086248 (69000)\ttotal: 23m 14s\tremaining: 2d 7h 45m 36s\n",
      "69200:\tlearn: 73.8897609\ttest: 80.0935270\tbest: 80.0935270 (69200)\ttotal: 23m 18s\tremaining: 2d 7h 45m 14s\n",
      "69400:\tlearn: 73.8597662\ttest: 80.0807406\tbest: 80.0807406 (69400)\ttotal: 23m 22s\tremaining: 2d 7h 44m 52s\n",
      "69600:\tlearn: 73.8284140\ttest: 80.0672723\tbest: 80.0672719 (69599)\ttotal: 23m 26s\tremaining: 2d 7h 44m 30s\n",
      "69800:\tlearn: 73.8030016\ttest: 80.0558485\tbest: 80.0558485 (69800)\ttotal: 23m 30s\tremaining: 2d 7h 44m 9s\n",
      "70000:\tlearn: 73.7740850\ttest: 80.0420829\tbest: 80.0419933 (69997)\ttotal: 23m 34s\tremaining: 2d 7h 43m 47s\n",
      "70200:\tlearn: 73.7491847\ttest: 80.0314952\tbest: 80.0314952 (70200)\ttotal: 23m 38s\tremaining: 2d 7h 43m 30s\n",
      "70400:\tlearn: 73.7241049\ttest: 80.0197079\tbest: 80.0197062 (70399)\ttotal: 23m 42s\tremaining: 2d 7h 43m 10s\n",
      "70600:\tlearn: 73.6984976\ttest: 80.0088785\tbest: 80.0088773 (70597)\ttotal: 23m 46s\tremaining: 2d 7h 43m 13s\n",
      "70800:\tlearn: 73.6658619\ttest: 79.9950462\tbest: 79.9950462 (70800)\ttotal: 23m 50s\tremaining: 2d 7h 43m 8s\n",
      "71000:\tlearn: 73.6315901\ttest: 79.9831922\tbest: 79.9831922 (71000)\ttotal: 23m 54s\tremaining: 2d 7h 42m 54s\n",
      "71200:\tlearn: 73.5947429\ttest: 79.9670968\tbest: 79.9670782 (71199)\ttotal: 23m 58s\tremaining: 2d 7h 42m 39s\n",
      "71400:\tlearn: 73.5605582\ttest: 79.9512943\tbest: 79.9512929 (71399)\ttotal: 24m 2s\tremaining: 2d 7h 43m\n",
      "71600:\tlearn: 73.5212066\ttest: 79.9343159\tbest: 79.9343159 (71600)\ttotal: 24m 6s\tremaining: 2d 7h 42m 42s\n",
      "71800:\tlearn: 73.4845023\ttest: 79.9204320\tbest: 79.9204320 (71800)\ttotal: 24m 10s\tremaining: 2d 7h 42m 29s\n",
      "72000:\tlearn: 73.4450272\ttest: 79.9031611\tbest: 79.9031611 (72000)\ttotal: 24m 14s\tremaining: 2d 7h 42m 18s\n",
      "72200:\tlearn: 73.4117831\ttest: 79.8870260\tbest: 79.8870012 (72198)\ttotal: 24m 18s\tremaining: 2d 7h 42m 9s\n",
      "72400:\tlearn: 73.3712116\ttest: 79.8703617\tbest: 79.8703617 (72400)\ttotal: 24m 22s\tremaining: 2d 7h 41m 57s\n",
      "72600:\tlearn: 73.3379681\ttest: 79.8565399\tbest: 79.8565399 (72600)\ttotal: 24m 26s\tremaining: 2d 7h 41m 36s\n",
      "72800:\tlearn: 73.3100056\ttest: 79.8442362\tbest: 79.8442362 (72800)\ttotal: 24m 30s\tremaining: 2d 7h 41m 35s\n",
      "73000:\tlearn: 73.2782610\ttest: 79.8307614\tbest: 79.8307499 (72999)\ttotal: 24m 34s\tremaining: 2d 7h 41m 17s\n",
      "73200:\tlearn: 73.2516534\ttest: 79.8213721\tbest: 79.8213721 (73200)\ttotal: 24m 38s\tremaining: 2d 7h 40m 52s\n",
      "73400:\tlearn: 73.2310509\ttest: 79.8133551\tbest: 79.8133551 (73400)\ttotal: 24m 42s\tremaining: 2d 7h 40m 45s\n",
      "73600:\tlearn: 73.2101649\ttest: 79.8043206\tbest: 79.8043206 (73600)\ttotal: 24m 46s\tremaining: 2d 7h 40m 25s\n",
      "73800:\tlearn: 73.1831965\ttest: 79.7934180\tbest: 79.7934180 (73800)\ttotal: 24m 50s\tremaining: 2d 7h 40m 7s\n",
      "74000:\tlearn: 73.1502246\ttest: 79.7786930\tbest: 79.7786930 (74000)\ttotal: 24m 54s\tremaining: 2d 7h 39m 56s\n",
      "74200:\tlearn: 73.1203841\ttest: 79.7646231\tbest: 79.7646125 (74199)\ttotal: 24m 57s\tremaining: 2d 7h 39m 44s\n",
      "74400:\tlearn: 73.0873548\ttest: 79.7493912\tbest: 79.7493522 (74398)\ttotal: 25m 1s\tremaining: 2d 7h 39m 32s\n",
      "74600:\tlearn: 73.0489948\ttest: 79.7349122\tbest: 79.7349122 (74600)\ttotal: 25m 5s\tremaining: 2d 7h 39m 11s\n",
      "74800:\tlearn: 73.0166309\ttest: 79.7213189\tbest: 79.7213189 (74800)\ttotal: 25m 9s\tremaining: 2d 7h 39m 1s\n",
      "75000:\tlearn: 72.9846505\ttest: 79.7064657\tbest: 79.7064657 (75000)\ttotal: 25m 13s\tremaining: 2d 7h 38m 40s\n",
      "75200:\tlearn: 72.9505262\ttest: 79.6909050\tbest: 79.6909050 (75200)\ttotal: 25m 17s\tremaining: 2d 7h 38m 29s\n",
      "75400:\tlearn: 72.9189038\ttest: 79.6763483\tbest: 79.6763483 (75400)\ttotal: 25m 21s\tremaining: 2d 7h 38m 9s\n",
      "75600:\tlearn: 72.8885801\ttest: 79.6624135\tbest: 79.6623041 (75599)\ttotal: 25m 25s\tremaining: 2d 7h 37m 52s\n",
      "75800:\tlearn: 72.8613882\ttest: 79.6503174\tbest: 79.6502690 (75799)\ttotal: 25m 29s\tremaining: 2d 7h 37m 32s\n",
      "76000:\tlearn: 72.8358339\ttest: 79.6390169\tbest: 79.6390169 (76000)\ttotal: 25m 33s\tremaining: 2d 7h 37m 13s\n",
      "76200:\tlearn: 72.8088032\ttest: 79.6264952\tbest: 79.6264952 (76200)\ttotal: 25m 37s\tremaining: 2d 7h 37m 4s\n",
      "76400:\tlearn: 72.7776839\ttest: 79.6122365\tbest: 79.6122365 (76400)\ttotal: 25m 41s\tremaining: 2d 7h 36m 48s\n",
      "76600:\tlearn: 72.7493187\ttest: 79.5992803\tbest: 79.5992674 (76598)\ttotal: 25m 45s\tremaining: 2d 7h 36m 28s\n",
      "76800:\tlearn: 72.7288870\ttest: 79.5885208\tbest: 79.5885208 (76800)\ttotal: 25m 49s\tremaining: 2d 7h 36m 12s\n",
      "77000:\tlearn: 72.7050368\ttest: 79.5781476\tbest: 79.5781474 (76999)\ttotal: 25m 53s\tremaining: 2d 7h 35m 55s\n",
      "77200:\tlearn: 72.6819961\ttest: 79.5689071\tbest: 79.5688853 (77196)\ttotal: 25m 57s\tremaining: 2d 7h 35m 40s\n",
      "77400:\tlearn: 72.6600860\ttest: 79.5594248\tbest: 79.5594248 (77400)\ttotal: 26m 1s\tremaining: 2d 7h 35m 32s\n",
      "77600:\tlearn: 72.6372765\ttest: 79.5497840\tbest: 79.5497840 (77600)\ttotal: 26m 5s\tremaining: 2d 7h 35m 11s\n",
      "77800:\tlearn: 72.5965372\ttest: 79.5351649\tbest: 79.5351571 (77799)\ttotal: 26m 8s\tremaining: 2d 7h 34m 58s\n",
      "78000:\tlearn: 72.5608453\ttest: 79.5213666\tbest: 79.5213666 (78000)\ttotal: 26m 12s\tremaining: 2d 7h 34m 44s\n",
      "78200:\tlearn: 72.5252877\ttest: 79.5078498\tbest: 79.5078498 (78200)\ttotal: 26m 16s\tremaining: 2d 7h 34m 31s\n",
      "78400:\tlearn: 72.4927933\ttest: 79.4950443\tbest: 79.4950443 (78400)\ttotal: 26m 20s\tremaining: 2d 7h 34m 27s\n",
      "78600:\tlearn: 72.4560278\ttest: 79.4807046\tbest: 79.4807046 (78600)\ttotal: 26m 24s\tremaining: 2d 7h 34m 9s\n",
      "78800:\tlearn: 72.4127892\ttest: 79.4626489\tbest: 79.4626489 (78800)\ttotal: 26m 28s\tremaining: 2d 7h 33m 55s\n",
      "79000:\tlearn: 72.3737089\ttest: 79.4448066\tbest: 79.4448066 (79000)\ttotal: 26m 32s\tremaining: 2d 7h 33m 36s\n",
      "79200:\tlearn: 72.3391254\ttest: 79.4307099\tbest: 79.4307099 (79200)\ttotal: 26m 36s\tremaining: 2d 7h 33m 25s\n",
      "79400:\tlearn: 72.2975833\ttest: 79.4157461\tbest: 79.4157461 (79400)\ttotal: 26m 40s\tremaining: 2d 7h 33m 21s\n",
      "79600:\tlearn: 72.2610451\ttest: 79.4016333\tbest: 79.4016299 (79599)\ttotal: 26m 44s\tremaining: 2d 7h 33m 10s\n",
      "79800:\tlearn: 72.2196810\ttest: 79.3849107\tbest: 79.3849107 (79800)\ttotal: 26m 48s\tremaining: 2d 7h 32m 55s\n",
      "80000:\tlearn: 72.1826240\ttest: 79.3721843\tbest: 79.3721843 (80000)\ttotal: 26m 52s\tremaining: 2d 7h 32m 36s\n",
      "80200:\tlearn: 72.1570976\ttest: 79.3599111\tbest: 79.3599111 (80200)\ttotal: 26m 56s\tremaining: 2d 7h 32m 16s\n",
      "80400:\tlearn: 72.1259730\ttest: 79.3487640\tbest: 79.3487640 (80400)\ttotal: 27m\tremaining: 2d 7h 32m 28s\n",
      "80600:\tlearn: 72.0905521\ttest: 79.3328948\tbest: 79.3328948 (80600)\ttotal: 27m 4s\tremaining: 2d 7h 32m 27s\n",
      "80800:\tlearn: 72.0582954\ttest: 79.3182189\tbest: 79.3182189 (80800)\ttotal: 27m 8s\tremaining: 2d 7h 32m 16s\n",
      "81000:\tlearn: 72.0321382\ttest: 79.3083418\tbest: 79.3083418 (81000)\ttotal: 27m 12s\tremaining: 2d 7h 32m\n",
      "81200:\tlearn: 72.0080760\ttest: 79.2992484\tbest: 79.2992484 (81200)\ttotal: 27m 16s\tremaining: 2d 7h 31m 46s\n",
      "81400:\tlearn: 71.9753500\ttest: 79.2879024\tbest: 79.2879024 (81400)\ttotal: 27m 20s\tremaining: 2d 7h 31m 43s\n",
      "81600:\tlearn: 71.9498825\ttest: 79.2777543\tbest: 79.2777543 (81600)\ttotal: 27m 24s\tremaining: 2d 7h 31m 23s\n",
      "81800:\tlearn: 71.9257278\ttest: 79.2698438\tbest: 79.2698431 (81799)\ttotal: 27m 28s\tremaining: 2d 7h 31m 2s\n",
      "82000:\tlearn: 71.9001007\ttest: 79.2601631\tbest: 79.2601181 (81988)\ttotal: 27m 32s\tremaining: 2d 7h 30m 44s\n",
      "82200:\tlearn: 71.8787043\ttest: 79.2499491\tbest: 79.2499491 (82200)\ttotal: 27m 36s\tremaining: 2d 7h 30m 28s\n",
      "82400:\tlearn: 71.8534552\ttest: 79.2420032\tbest: 79.2419581 (82398)\ttotal: 27m 40s\tremaining: 2d 7h 30m 12s\n",
      "82600:\tlearn: 71.8269004\ttest: 79.2307870\tbest: 79.2307643 (82598)\ttotal: 27m 44s\tremaining: 2d 7h 29m 58s\n",
      "82800:\tlearn: 71.8004014\ttest: 79.2206557\tbest: 79.2206186 (82799)\ttotal: 27m 48s\tremaining: 2d 7h 29m 41s\n",
      "83000:\tlearn: 71.7668295\ttest: 79.2086044\tbest: 79.2086044 (83000)\ttotal: 27m 51s\tremaining: 2d 7h 29m 25s\n",
      "83200:\tlearn: 71.7382681\ttest: 79.1976569\tbest: 79.1976569 (83200)\ttotal: 27m 55s\tremaining: 2d 7h 29m 8s\n",
      "83400:\tlearn: 71.7074949\ttest: 79.1873536\tbest: 79.1873536 (83400)\ttotal: 27m 59s\tremaining: 2d 7h 28m 51s\n",
      "83600:\tlearn: 71.6740488\ttest: 79.1732860\tbest: 79.1732860 (83600)\ttotal: 28m 3s\tremaining: 2d 7h 28m 35s\n",
      "83800:\tlearn: 71.6392023\ttest: 79.1609623\tbest: 79.1609623 (83800)\ttotal: 28m 7s\tremaining: 2d 7h 28m 21s\n",
      "84000:\tlearn: 71.6072132\ttest: 79.1500582\tbest: 79.1500582 (84000)\ttotal: 28m 11s\tremaining: 2d 7h 28m 13s\n",
      "84200:\tlearn: 71.5785850\ttest: 79.1406049\tbest: 79.1406049 (84200)\ttotal: 28m 15s\tremaining: 2d 7h 27m 56s\n",
      "84400:\tlearn: 71.5432732\ttest: 79.1291240\tbest: 79.1291240 (84400)\ttotal: 28m 19s\tremaining: 2d 7h 27m 43s\n",
      "84600:\tlearn: 71.5139759\ttest: 79.1167919\tbest: 79.1167919 (84600)\ttotal: 28m 23s\tremaining: 2d 7h 27m 28s\n",
      "84800:\tlearn: 71.4844420\ttest: 79.1049481\tbest: 79.1049481 (84800)\ttotal: 28m 27s\tremaining: 2d 7h 27m 16s\n",
      "85000:\tlearn: 71.4644846\ttest: 79.0973119\tbest: 79.0972066 (84999)\ttotal: 28m 31s\tremaining: 2d 7h 26m 57s\n",
      "85200:\tlearn: 71.4408201\ttest: 79.0881734\tbest: 79.0881734 (85200)\ttotal: 28m 35s\tremaining: 2d 7h 26m 41s\n",
      "85400:\tlearn: 71.4102689\ttest: 79.0781389\tbest: 79.0781389 (85400)\ttotal: 28m 39s\tremaining: 2d 7h 26m 52s\n",
      "85600:\tlearn: 71.3796435\ttest: 79.0665822\tbest: 79.0665822 (85600)\ttotal: 28m 43s\tremaining: 2d 7h 26m 46s\n",
      "85800:\tlearn: 71.3514814\ttest: 79.0554184\tbest: 79.0554184 (85800)\ttotal: 28m 47s\tremaining: 2d 7h 26m 29s\n",
      "86000:\tlearn: 71.3194160\ttest: 79.0438134\tbest: 79.0438083 (85999)\ttotal: 28m 51s\tremaining: 2d 7h 26m 17s\n",
      "86200:\tlearn: 71.2845102\ttest: 79.0294894\tbest: 79.0294894 (86200)\ttotal: 28m 55s\tremaining: 2d 7h 26m 27s\n",
      "86400:\tlearn: 71.2529516\ttest: 79.0181474\tbest: 79.0181474 (86400)\ttotal: 28m 59s\tremaining: 2d 7h 26m 23s\n",
      "86600:\tlearn: 71.2114896\ttest: 79.0022849\tbest: 79.0022849 (86600)\ttotal: 29m 3s\tremaining: 2d 7h 26m 8s\n",
      "86800:\tlearn: 71.1763055\ttest: 78.9908054\tbest: 78.9908054 (86800)\ttotal: 29m 7s\tremaining: 2d 7h 25m 47s\n",
      "87000:\tlearn: 71.1382551\ttest: 78.9810201\tbest: 78.9807349 (86997)\ttotal: 29m 11s\tremaining: 2d 7h 25m 26s\n",
      "87200:\tlearn: 71.1020482\ttest: 78.9665277\tbest: 78.9665277 (87200)\ttotal: 29m 15s\tremaining: 2d 7h 25m 11s\n",
      "87400:\tlearn: 71.0659187\ttest: 78.9545758\tbest: 78.9545758 (87400)\ttotal: 29m 18s\tremaining: 2d 7h 24m 52s\n",
      "87600:\tlearn: 71.0319125\ttest: 78.9416565\tbest: 78.9416565 (87600)\ttotal: 29m 22s\tremaining: 2d 7h 24m 31s\n",
      "87800:\tlearn: 70.9972756\ttest: 78.9274811\tbest: 78.9274811 (87800)\ttotal: 29m 26s\tremaining: 2d 7h 24m 25s\n",
      "88000:\tlearn: 70.9613291\ttest: 78.9143940\tbest: 78.9143906 (87999)\ttotal: 29m 30s\tremaining: 2d 7h 24m 5s\n",
      "88200:\tlearn: 70.9222134\ttest: 78.9021359\tbest: 78.9021359 (88200)\ttotal: 29m 34s\tremaining: 2d 7h 23m 45s\n",
      "88400:\tlearn: 70.8793957\ttest: 78.8874032\tbest: 78.8874032 (88400)\ttotal: 29m 38s\tremaining: 2d 7h 23m 24s\n",
      "88600:\tlearn: 70.8464124\ttest: 78.8755073\tbest: 78.8755025 (88598)\ttotal: 29m 42s\tremaining: 2d 7h 23m 6s\n",
      "88800:\tlearn: 70.8114349\ttest: 78.8616077\tbest: 78.8616077 (88800)\ttotal: 29m 46s\tremaining: 2d 7h 22m 47s\n",
      "89000:\tlearn: 70.7702572\ttest: 78.8463473\tbest: 78.8463243 (88997)\ttotal: 29m 50s\tremaining: 2d 7h 22m 27s\n",
      "89200:\tlearn: 70.7335338\ttest: 78.8311983\tbest: 78.8311983 (89200)\ttotal: 29m 54s\tremaining: 2d 7h 22m 10s\n",
      "89400:\tlearn: 70.6981986\ttest: 78.8176689\tbest: 78.8176689 (89400)\ttotal: 29m 58s\tremaining: 2d 7h 22m\n",
      "89600:\tlearn: 70.6696781\ttest: 78.8076799\tbest: 78.8075580 (89599)\ttotal: 30m 2s\tremaining: 2d 7h 22m 6s\n",
      "89800:\tlearn: 70.6334137\ttest: 78.7961151\tbest: 78.7960858 (89799)\ttotal: 30m 6s\tremaining: 2d 7h 21m 52s\n",
      "90000:\tlearn: 70.5957029\ttest: 78.7815801\tbest: 78.7815801 (90000)\ttotal: 30m 9s\tremaining: 2d 7h 21m 36s\n",
      "90200:\tlearn: 70.5548260\ttest: 78.7691409\tbest: 78.7691409 (90200)\ttotal: 30m 13s\tremaining: 2d 7h 21m 18s\n",
      "90400:\tlearn: 70.5164888\ttest: 78.7556695\tbest: 78.7556672 (90399)\ttotal: 30m 17s\tremaining: 2d 7h 21m 2s\n",
      "90600:\tlearn: 70.4846564\ttest: 78.7465302\tbest: 78.7465302 (90600)\ttotal: 30m 21s\tremaining: 2d 7h 20m 50s\n",
      "90800:\tlearn: 70.4538327\ttest: 78.7370530\tbest: 78.7370530 (90800)\ttotal: 30m 25s\tremaining: 2d 7h 20m 33s\n",
      "91000:\tlearn: 70.4237264\ttest: 78.7254484\tbest: 78.7254391 (90999)\ttotal: 30m 29s\tremaining: 2d 7h 20m 13s\n",
      "91200:\tlearn: 70.3902404\ttest: 78.7132638\tbest: 78.7132638 (91200)\ttotal: 30m 33s\tremaining: 2d 7h 20m\n",
      "91400:\tlearn: 70.3576608\ttest: 78.7009630\tbest: 78.7009630 (91400)\ttotal: 30m 37s\tremaining: 2d 7h 19m 52s\n",
      "91600:\tlearn: 70.3253125\ttest: 78.6873025\tbest: 78.6872446 (91599)\ttotal: 30m 41s\tremaining: 2d 7h 19m 31s\n",
      "91800:\tlearn: 70.2987614\ttest: 78.6776073\tbest: 78.6776073 (91800)\ttotal: 30m 45s\tremaining: 2d 7h 19m 16s\n",
      "92000:\tlearn: 70.2738500\ttest: 78.6700152\tbest: 78.6700054 (91998)\ttotal: 30m 49s\tremaining: 2d 7h 18m 57s\n",
      "92200:\tlearn: 70.2364364\ttest: 78.6548663\tbest: 78.6548601 (92198)\ttotal: 30m 53s\tremaining: 2d 7h 18m 43s\n",
      "92400:\tlearn: 70.2032953\ttest: 78.6444972\tbest: 78.6444972 (92400)\ttotal: 30m 57s\tremaining: 2d 7h 18m 37s\n",
      "92600:\tlearn: 70.1724539\ttest: 78.6337667\tbest: 78.6337667 (92600)\ttotal: 31m\tremaining: 2d 7h 18m 20s\n",
      "92800:\tlearn: 70.1444810\ttest: 78.6231253\tbest: 78.6230842 (92796)\ttotal: 31m 4s\tremaining: 2d 7h 18m 5s\n",
      "93000:\tlearn: 70.1133624\ttest: 78.6116031\tbest: 78.6115988 (92999)\ttotal: 31m 8s\tremaining: 2d 7h 17m 48s\n",
      "93200:\tlearn: 70.0811955\ttest: 78.5997945\tbest: 78.5997945 (93200)\ttotal: 31m 12s\tremaining: 2d 7h 17m 29s\n",
      "93400:\tlearn: 70.0510613\ttest: 78.5896140\tbest: 78.5896140 (93400)\ttotal: 31m 16s\tremaining: 2d 7h 17m 9s\n",
      "93600:\tlearn: 70.0176366\ttest: 78.5772440\tbest: 78.5772440 (93600)\ttotal: 31m 20s\tremaining: 2d 7h 16m 53s\n",
      "93800:\tlearn: 69.9840129\ttest: 78.5638868\tbest: 78.5638868 (93800)\ttotal: 31m 24s\tremaining: 2d 7h 16m 38s\n",
      "94000:\tlearn: 69.9546569\ttest: 78.5524137\tbest: 78.5522078 (93998)\ttotal: 31m 28s\tremaining: 2d 7h 16m 18s\n",
      "94200:\tlearn: 69.9157816\ttest: 78.5390388\tbest: 78.5390388 (94200)\ttotal: 31m 32s\tremaining: 2d 7h 16m 2s\n",
      "94400:\tlearn: 69.8756355\ttest: 78.5243604\tbest: 78.5243452 (94395)\ttotal: 31m 35s\tremaining: 2d 7h 15m 44s\n",
      "94600:\tlearn: 69.8406542\ttest: 78.5119410\tbest: 78.5119181 (94599)\ttotal: 31m 39s\tremaining: 2d 7h 15m 29s\n",
      "94800:\tlearn: 69.8094483\ttest: 78.5008774\tbest: 78.5008774 (94800)\ttotal: 31m 43s\tremaining: 2d 7h 15m 12s\n",
      "95000:\tlearn: 69.7744782\ttest: 78.4891675\tbest: 78.4890724 (94999)\ttotal: 31m 47s\tremaining: 2d 7h 14m 55s\n",
      "95200:\tlearn: 69.7341417\ttest: 78.4757633\tbest: 78.4757633 (95200)\ttotal: 31m 51s\tremaining: 2d 7h 14m 46s\n",
      "95400:\tlearn: 69.7007652\ttest: 78.4649764\tbest: 78.4649764 (95400)\ttotal: 31m 55s\tremaining: 2d 7h 14m 30s\n",
      "95600:\tlearn: 69.6757042\ttest: 78.4549083\tbest: 78.4549083 (95600)\ttotal: 31m 59s\tremaining: 2d 7h 14m 17s\n",
      "95800:\tlearn: 69.6392619\ttest: 78.4424593\tbest: 78.4423922 (95799)\ttotal: 32m 3s\tremaining: 2d 7h 14m 6s\n",
      "96000:\tlearn: 69.6081408\ttest: 78.4332720\tbest: 78.4332720 (96000)\ttotal: 32m 7s\tremaining: 2d 7h 13m 45s\n",
      "96200:\tlearn: 69.5792720\ttest: 78.4251416\tbest: 78.4251416 (96200)\ttotal: 32m 11s\tremaining: 2d 7h 13m 29s\n",
      "96400:\tlearn: 69.5487169\ttest: 78.4118496\tbest: 78.4118496 (96400)\ttotal: 32m 14s\tremaining: 2d 7h 13m 8s\n",
      "96600:\tlearn: 69.5173354\ttest: 78.4021893\tbest: 78.4021833 (96599)\ttotal: 32m 18s\tremaining: 2d 7h 12m 52s\n",
      "96800:\tlearn: 69.4899943\ttest: 78.3927497\tbest: 78.3927497 (96800)\ttotal: 32m 22s\tremaining: 2d 7h 12m 39s\n",
      "97000:\tlearn: 69.4620278\ttest: 78.3824411\tbest: 78.3824411 (97000)\ttotal: 32m 26s\tremaining: 2d 7h 12m 32s\n",
      "97200:\tlearn: 69.4328513\ttest: 78.3735649\tbest: 78.3735649 (97200)\ttotal: 32m 30s\tremaining: 2d 7h 12m 21s\n",
      "97400:\tlearn: 69.3995661\ttest: 78.3623662\tbest: 78.3623662 (97400)\ttotal: 32m 34s\tremaining: 2d 7h 12m 4s\n",
      "97600:\tlearn: 69.3653590\ttest: 78.3513529\tbest: 78.3513216 (97596)\ttotal: 32m 38s\tremaining: 2d 7h 11m 47s\n",
      "97800:\tlearn: 69.3307890\ttest: 78.3401526\tbest: 78.3401526 (97800)\ttotal: 32m 42s\tremaining: 2d 7h 11m 34s\n",
      "98000:\tlearn: 69.2957159\ttest: 78.3299739\tbest: 78.3298122 (97999)\ttotal: 32m 46s\tremaining: 2d 7h 11m 19s\n",
      "98200:\tlearn: 69.2597722\ttest: 78.3165815\tbest: 78.3165799 (98199)\ttotal: 32m 50s\tremaining: 2d 7h 11m 3s\n",
      "98400:\tlearn: 69.2301610\ttest: 78.3082006\tbest: 78.3082006 (98400)\ttotal: 32m 54s\tremaining: 2d 7h 10m 49s\n",
      "98600:\tlearn: 69.1977407\ttest: 78.2962564\tbest: 78.2962564 (98600)\ttotal: 32m 58s\tremaining: 2d 7h 10m 38s\n",
      "98800:\tlearn: 69.1630830\ttest: 78.2844766\tbest: 78.2844738 (98799)\ttotal: 33m 2s\tremaining: 2d 7h 10m 33s\n",
      "99000:\tlearn: 69.1275244\ttest: 78.2695950\tbest: 78.2695947 (98999)\ttotal: 33m 6s\tremaining: 2d 7h 10m 32s\n",
      "99200:\tlearn: 69.0948952\ttest: 78.2609934\tbest: 78.2609816 (99198)\ttotal: 33m 10s\tremaining: 2d 7h 10m 14s\n",
      "99400:\tlearn: 69.0609193\ttest: 78.2498032\tbest: 78.2498032 (99400)\ttotal: 33m 13s\tremaining: 2d 7h 9m 58s\n",
      "99600:\tlearn: 69.0269739\ttest: 78.2386777\tbest: 78.2386777 (99600)\ttotal: 33m 17s\tremaining: 2d 7h 9m 44s\n",
      "99800:\tlearn: 68.9921617\ttest: 78.2271462\tbest: 78.2270280 (99797)\ttotal: 33m 21s\tremaining: 2d 7h 9m 31s\n",
      "100000:\tlearn: 68.9637463\ttest: 78.2181531\tbest: 78.2181479 (99998)\ttotal: 33m 25s\tremaining: 2d 7h 9m 16s\n",
      "100200:\tlearn: 68.9380896\ttest: 78.2100325\tbest: 78.2100325 (100200)\ttotal: 33m 29s\tremaining: 2d 7h 8m 58s\n",
      "100400:\tlearn: 68.9089557\ttest: 78.2020601\tbest: 78.2020601 (100400)\ttotal: 33m 33s\tremaining: 2d 7h 8m 40s\n",
      "100600:\tlearn: 68.8764175\ttest: 78.1924448\tbest: 78.1923939 (100595)\ttotal: 33m 37s\tremaining: 2d 7h 8m 25s\n",
      "100800:\tlearn: 68.8479772\ttest: 78.1819201\tbest: 78.1819201 (100800)\ttotal: 33m 41s\tremaining: 2d 7h 8m 17s\n",
      "101000:\tlearn: 68.8214063\ttest: 78.1730654\tbest: 78.1730654 (101000)\ttotal: 33m 45s\tremaining: 2d 7h 7m 57s\n",
      "101200:\tlearn: 68.7940944\ttest: 78.1647987\tbest: 78.1647987 (101200)\ttotal: 33m 48s\tremaining: 2d 7h 7m 40s\n",
      "101400:\tlearn: 68.7632959\ttest: 78.1555092\tbest: 78.1555092 (101400)\ttotal: 33m 52s\tremaining: 2d 7h 7m 23s\n",
      "101600:\tlearn: 68.7280842\ttest: 78.1445449\tbest: 78.1445449 (101600)\ttotal: 33m 56s\tremaining: 2d 7h 7m 7s\n",
      "101800:\tlearn: 68.6925935\ttest: 78.1337945\tbest: 78.1337945 (101800)\ttotal: 34m\tremaining: 2d 7h 6m 46s\n",
      "102000:\tlearn: 68.6527480\ttest: 78.1214625\tbest: 78.1214625 (102000)\ttotal: 34m 4s\tremaining: 2d 7h 6m 32s\n",
      "102200:\tlearn: 68.6146714\ttest: 78.1113128\tbest: 78.1113128 (102200)\ttotal: 34m 8s\tremaining: 2d 7h 6m 17s\n",
      "102400:\tlearn: 68.5789143\ttest: 78.0984606\tbest: 78.0984442 (102399)\ttotal: 34m 12s\tremaining: 2d 7h 6m 5s\n",
      "102600:\tlearn: 68.5378031\ttest: 78.0842728\tbest: 78.0842728 (102600)\ttotal: 34m 16s\tremaining: 2d 7h 5m 54s\n",
      "102800:\tlearn: 68.5002976\ttest: 78.0718637\tbest: 78.0718637 (102800)\ttotal: 34m 20s\tremaining: 2d 7h 6m 2s\n",
      "103000:\tlearn: 68.4741811\ttest: 78.0624378\tbest: 78.0624378 (103000)\ttotal: 34m 24s\tremaining: 2d 7h 6m 15s\n",
      "103200:\tlearn: 68.4396963\ttest: 78.0518651\tbest: 78.0518651 (103200)\ttotal: 34m 28s\tremaining: 2d 7h 6m 33s\n",
      "103400:\tlearn: 68.4063283\ttest: 78.0406351\tbest: 78.0406351 (103400)\ttotal: 34m 32s\tremaining: 2d 7h 6m 35s\n",
      "103600:\tlearn: 68.3737886\ttest: 78.0268895\tbest: 78.0268885 (103599)\ttotal: 34m 36s\tremaining: 2d 7h 6m 36s\n",
      "103800:\tlearn: 68.3409232\ttest: 78.0158358\tbest: 78.0158065 (103798)\ttotal: 34m 40s\tremaining: 2d 7h 6m 30s\n",
      "104000:\tlearn: 68.3154486\ttest: 78.0064488\tbest: 78.0064488 (104000)\ttotal: 34m 44s\tremaining: 2d 7h 6m 21s\n",
      "104200:\tlearn: 68.2836951\ttest: 77.9936161\tbest: 77.9934209 (104198)\ttotal: 34m 48s\tremaining: 2d 7h 6m 1s\n",
      "104400:\tlearn: 68.2498142\ttest: 77.9834053\tbest: 77.9833723 (104394)\ttotal: 34m 52s\tremaining: 2d 7h 6m 1s\n",
      "104600:\tlearn: 68.2181772\ttest: 77.9720360\tbest: 77.9720360 (104600)\ttotal: 34m 57s\tremaining: 2d 7h 6m 39s\n",
      "104800:\tlearn: 68.1877994\ttest: 77.9619625\tbest: 77.9619625 (104800)\ttotal: 35m 1s\tremaining: 2d 7h 6m 58s\n",
      "105000:\tlearn: 68.1606129\ttest: 77.9533805\tbest: 77.9533108 (104995)\ttotal: 35m 5s\tremaining: 2d 7h 7m 26s\n",
      "105200:\tlearn: 68.1255907\ttest: 77.9438711\tbest: 77.9438711 (105200)\ttotal: 35m 9s\tremaining: 2d 7h 7m 23s\n",
      "105400:\tlearn: 68.0920337\ttest: 77.9326124\tbest: 77.9326124 (105400)\ttotal: 35m 13s\tremaining: 2d 7h 7m 17s\n",
      "105600:\tlearn: 68.0559292\ttest: 77.9206544\tbest: 77.9206544 (105600)\ttotal: 35m 17s\tremaining: 2d 7h 7m 7s\n",
      "105800:\tlearn: 68.0270712\ttest: 77.9124061\tbest: 77.9120476 (105799)\ttotal: 35m 21s\tremaining: 2d 7h 6m 53s\n",
      "106000:\tlearn: 67.9966959\ttest: 77.9052362\tbest: 77.9052362 (106000)\ttotal: 35m 25s\tremaining: 2d 7h 6m 36s\n",
      "106200:\tlearn: 67.9684411\ttest: 77.8965791\tbest: 77.8965791 (106200)\ttotal: 35m 29s\tremaining: 2d 7h 6m 16s\n",
      "106400:\tlearn: 67.9417563\ttest: 77.8878251\tbest: 77.8878251 (106400)\ttotal: 35m 33s\tremaining: 2d 7h 5m 59s\n",
      "106600:\tlearn: 67.9186564\ttest: 77.8805067\tbest: 77.8804692 (106592)\ttotal: 35m 37s\tremaining: 2d 7h 5m 41s\n",
      "106800:\tlearn: 67.8892317\ttest: 77.8698407\tbest: 77.8698407 (106800)\ttotal: 35m 41s\tremaining: 2d 7h 5m 30s\n",
      "107000:\tlearn: 67.8634454\ttest: 77.8611402\tbest: 77.8611402 (107000)\ttotal: 35m 44s\tremaining: 2d 7h 5m 12s\n",
      "107200:\tlearn: 67.8361629\ttest: 77.8529749\tbest: 77.8529749 (107200)\ttotal: 35m 48s\tremaining: 2d 7h 4m 55s\n",
      "107400:\tlearn: 67.8016714\ttest: 77.8419473\tbest: 77.8417144 (107396)\ttotal: 35m 52s\tremaining: 2d 7h 4m 37s\n",
      "107600:\tlearn: 67.7726397\ttest: 77.8327788\tbest: 77.8327788 (107600)\ttotal: 35m 56s\tremaining: 2d 7h 4m 23s\n",
      "107800:\tlearn: 67.7493765\ttest: 77.8245278\tbest: 77.8245278 (107800)\ttotal: 36m\tremaining: 2d 7h 4m 9s\n",
      "108000:\tlearn: 67.7278144\ttest: 77.8176112\tbest: 77.8176112 (108000)\ttotal: 36m 4s\tremaining: 2d 7h 4m 11s\n",
      "108200:\tlearn: 67.7024026\ttest: 77.8094897\tbest: 77.8094897 (108200)\ttotal: 36m 8s\tremaining: 2d 7h 3m 53s\n",
      "108400:\tlearn: 67.6792253\ttest: 77.8018244\tbest: 77.8017875 (108396)\ttotal: 36m 12s\tremaining: 2d 7h 3m 41s\n",
      "108600:\tlearn: 67.6566908\ttest: 77.7960876\tbest: 77.7960707 (108599)\ttotal: 36m 16s\tremaining: 2d 7h 3m 28s\n",
      "108800:\tlearn: 67.6288329\ttest: 77.7878141\tbest: 77.7878141 (108800)\ttotal: 36m 20s\tremaining: 2d 7h 3m 12s\n",
      "109000:\tlearn: 67.6048173\ttest: 77.7810916\tbest: 77.7810746 (108998)\ttotal: 36m 23s\tremaining: 2d 7h 2m 52s\n",
      "109200:\tlearn: 67.5758039\ttest: 77.7716478\tbest: 77.7716478 (109200)\ttotal: 36m 27s\tremaining: 2d 7h 2m 35s\n",
      "109400:\tlearn: 67.5497378\ttest: 77.7630191\tbest: 77.7630140 (109398)\ttotal: 36m 31s\tremaining: 2d 7h 2m 15s\n",
      "109600:\tlearn: 67.5216619\ttest: 77.7539728\tbest: 77.7539637 (109599)\ttotal: 36m 35s\tremaining: 2d 7h 2m 1s\n",
      "109800:\tlearn: 67.4921472\ttest: 77.7422385\tbest: 77.7422385 (109800)\ttotal: 36m 39s\tremaining: 2d 7h 1m 44s\n",
      "110000:\tlearn: 67.4626085\ttest: 77.7348505\tbest: 77.7348505 (110000)\ttotal: 36m 43s\tremaining: 2d 7h 1m 27s\n",
      "110200:\tlearn: 67.4294801\ttest: 77.7245275\tbest: 77.7245275 (110200)\ttotal: 36m 47s\tremaining: 2d 7h 1m 11s\n",
      "110400:\tlearn: 67.3977399\ttest: 77.7136394\tbest: 77.7136394 (110400)\ttotal: 36m 50s\tremaining: 2d 7h 57s\n",
      "110600:\tlearn: 67.3777049\ttest: 77.7072942\tbest: 77.7070461 (110597)\ttotal: 36m 54s\tremaining: 2d 7h 41s\n",
      "110800:\tlearn: 67.3525625\ttest: 77.6980714\tbest: 77.6980714 (110800)\ttotal: 36m 58s\tremaining: 2d 7h 26s\n",
      "111000:\tlearn: 67.3311446\ttest: 77.6907079\tbest: 77.6906756 (110998)\ttotal: 37m 2s\tremaining: 2d 7h 9s\n",
      "111200:\tlearn: 67.3063715\ttest: 77.6841163\tbest: 77.6841163 (111200)\ttotal: 37m 6s\tremaining: 2d 6h 59m 56s\n",
      "111400:\tlearn: 67.2872330\ttest: 77.6774023\tbest: 77.6773118 (111395)\ttotal: 37m 10s\tremaining: 2d 6h 59m 38s\n",
      "111600:\tlearn: 67.2676685\ttest: 77.6722003\tbest: 77.6722003 (111600)\ttotal: 37m 14s\tremaining: 2d 6h 59m 22s\n",
      "111800:\tlearn: 67.2452477\ttest: 77.6661247\tbest: 77.6661247 (111800)\ttotal: 37m 18s\tremaining: 2d 6h 59m 7s\n",
      "112000:\tlearn: 67.2220960\ttest: 77.6586668\tbest: 77.6586532 (111999)\ttotal: 37m 21s\tremaining: 2d 6h 58m 54s\n",
      "112200:\tlearn: 67.1944821\ttest: 77.6498778\tbest: 77.6498304 (112195)\ttotal: 37m 25s\tremaining: 2d 6h 58m 36s\n",
      "112400:\tlearn: 67.1657940\ttest: 77.6408487\tbest: 77.6408487 (112400)\ttotal: 37m 29s\tremaining: 2d 6h 58m 19s\n",
      "112600:\tlearn: 67.1414607\ttest: 77.6332988\tbest: 77.6332988 (112600)\ttotal: 37m 33s\tremaining: 2d 6h 58m 2s\n",
      "112800:\tlearn: 67.1165865\ttest: 77.6265292\tbest: 77.6265292 (112800)\ttotal: 37m 37s\tremaining: 2d 6h 57m 49s\n",
      "113000:\tlearn: 67.0910785\ttest: 77.6171364\tbest: 77.6171364 (113000)\ttotal: 37m 41s\tremaining: 2d 6h 57m 37s\n",
      "113200:\tlearn: 67.0635334\ttest: 77.6083027\tbest: 77.6083027 (113200)\ttotal: 37m 45s\tremaining: 2d 6h 57m 22s\n",
      "113400:\tlearn: 67.0365410\ttest: 77.5972001\tbest: 77.5971823 (113399)\ttotal: 37m 49s\tremaining: 2d 6h 57m 4s\n",
      "113600:\tlearn: 67.0155258\ttest: 77.5902218\tbest: 77.5901797 (113598)\ttotal: 37m 53s\tremaining: 2d 6h 56m 54s\n",
      "113800:\tlearn: 66.9898949\ttest: 77.5803906\tbest: 77.5803906 (113800)\ttotal: 37m 56s\tremaining: 2d 6h 56m 36s\n",
      "114000:\tlearn: 66.9668876\ttest: 77.5734100\tbest: 77.5734100 (114000)\ttotal: 38m\tremaining: 2d 6h 56m 21s\n",
      "114200:\tlearn: 66.9438055\ttest: 77.5648145\tbest: 77.5646362 (114199)\ttotal: 38m 4s\tremaining: 2d 6h 56m 7s\n",
      "114400:\tlearn: 66.9207414\ttest: 77.5573797\tbest: 77.5573797 (114400)\ttotal: 38m 8s\tremaining: 2d 6h 55m 57s\n",
      "114600:\tlearn: 66.8914116\ttest: 77.5484883\tbest: 77.5484883 (114600)\ttotal: 38m 12s\tremaining: 2d 6h 55m 40s\n",
      "114800:\tlearn: 66.8612699\ttest: 77.5393246\tbest: 77.5393246 (114800)\ttotal: 38m 16s\tremaining: 2d 6h 55m 33s\n",
      "115000:\tlearn: 66.8410691\ttest: 77.5312886\tbest: 77.5312886 (115000)\ttotal: 38m 20s\tremaining: 2d 6h 55m 19s\n",
      "115200:\tlearn: 66.8168449\ttest: 77.5228054\tbest: 77.5228054 (115200)\ttotal: 38m 24s\tremaining: 2d 6h 55m 9s\n",
      "115400:\tlearn: 66.7809598\ttest: 77.5094998\tbest: 77.5094412 (115398)\ttotal: 38m 28s\tremaining: 2d 6h 54m 52s\n",
      "115600:\tlearn: 66.7502664\ttest: 77.5007346\tbest: 77.5006797 (115599)\ttotal: 38m 31s\tremaining: 2d 6h 54m 40s\n",
      "115800:\tlearn: 66.7162835\ttest: 77.4921960\tbest: 77.4921716 (115798)\ttotal: 38m 35s\tremaining: 2d 6h 54m 23s\n",
      "116000:\tlearn: 66.6869488\ttest: 77.4847860\tbest: 77.4847860 (116000)\ttotal: 38m 39s\tremaining: 2d 6h 54m 12s\n",
      "116200:\tlearn: 66.6464763\ttest: 77.4755377\tbest: 77.4754551 (116189)\ttotal: 38m 43s\tremaining: 2d 6h 53m 59s\n",
      "116400:\tlearn: 66.6200654\ttest: 77.4671240\tbest: 77.4669985 (116390)\ttotal: 38m 47s\tremaining: 2d 6h 53m 44s\n",
      "116600:\tlearn: 66.5902719\ttest: 77.4581971\tbest: 77.4581971 (116600)\ttotal: 38m 51s\tremaining: 2d 6h 53m 28s\n",
      "116800:\tlearn: 66.5570084\ttest: 77.4491179\tbest: 77.4488711 (116796)\ttotal: 38m 55s\tremaining: 2d 6h 53m 15s\n",
      "117000:\tlearn: 66.5183708\ttest: 77.4416832\tbest: 77.4416832 (117000)\ttotal: 38m 59s\tremaining: 2d 6h 53m 1s\n",
      "117200:\tlearn: 66.4829105\ttest: 77.4330862\tbest: 77.4330862 (117200)\ttotal: 39m 3s\tremaining: 2d 6h 52m 55s\n",
      "117400:\tlearn: 66.4416906\ttest: 77.4190853\tbest: 77.4190800 (117396)\ttotal: 39m 7s\tremaining: 2d 6h 52m 52s\n",
      "117600:\tlearn: 66.4056858\ttest: 77.4078347\tbest: 77.4078153 (117599)\ttotal: 39m 11s\tremaining: 2d 6h 52m 44s\n",
      "117800:\tlearn: 66.3744453\ttest: 77.3974522\tbest: 77.3974522 (117800)\ttotal: 39m 14s\tremaining: 2d 6h 52m 37s\n",
      "118000:\tlearn: 66.3504730\ttest: 77.3898633\tbest: 77.3898633 (118000)\ttotal: 39m 18s\tremaining: 2d 6h 52m 27s\n",
      "118200:\tlearn: 66.3264849\ttest: 77.3816291\tbest: 77.3816291 (118200)\ttotal: 39m 22s\tremaining: 2d 6h 52m 17s\n",
      "118400:\tlearn: 66.3043608\ttest: 77.3735531\tbest: 77.3735416 (118398)\ttotal: 39m 26s\tremaining: 2d 6h 52m 3s\n",
      "118600:\tlearn: 66.2796626\ttest: 77.3665375\tbest: 77.3664242 (118596)\ttotal: 39m 30s\tremaining: 2d 6h 52m 10s\n",
      "118800:\tlearn: 66.2588550\ttest: 77.3592509\tbest: 77.3592461 (118799)\ttotal: 39m 34s\tremaining: 2d 6h 52m 8s\n",
      "119000:\tlearn: 66.2325016\ttest: 77.3523340\tbest: 77.3522698 (118999)\ttotal: 39m 38s\tremaining: 2d 6h 51m 58s\n",
      "119200:\tlearn: 66.2052777\ttest: 77.3438260\tbest: 77.3438260 (119200)\ttotal: 39m 42s\tremaining: 2d 6h 51m 46s\n",
      "119400:\tlearn: 66.1809882\ttest: 77.3367852\tbest: 77.3366789 (119398)\ttotal: 39m 46s\tremaining: 2d 6h 51m 35s\n",
      "119600:\tlearn: 66.1521747\ttest: 77.3261128\tbest: 77.3261128 (119600)\ttotal: 39m 50s\tremaining: 2d 6h 51m 20s\n",
      "119800:\tlearn: 66.1309932\ttest: 77.3192060\tbest: 77.3188791 (119796)\ttotal: 39m 54s\tremaining: 2d 6h 51m 9s\n",
      "120000:\tlearn: 66.1065888\ttest: 77.3124349\tbest: 77.3124349 (120000)\ttotal: 39m 58s\tremaining: 2d 6h 50m 59s\n",
      "120200:\tlearn: 66.0822606\ttest: 77.3069868\tbest: 77.3069778 (120197)\ttotal: 40m 2s\tremaining: 2d 6h 50m 46s\n",
      "120400:\tlearn: 66.0516134\ttest: 77.2991943\tbest: 77.2991943 (120400)\ttotal: 40m 6s\tremaining: 2d 6h 50m 31s\n",
      "120600:\tlearn: 66.0264244\ttest: 77.2923056\tbest: 77.2923056 (120600)\ttotal: 40m 9s\tremaining: 2d 6h 50m 20s\n",
      "120800:\tlearn: 65.9928434\ttest: 77.2817586\tbest: 77.2817570 (120799)\ttotal: 40m 13s\tremaining: 2d 6h 50m 14s\n",
      "121000:\tlearn: 65.9641834\ttest: 77.2742618\tbest: 77.2742208 (120994)\ttotal: 40m 17s\tremaining: 2d 6h 50m 3s\n",
      "121200:\tlearn: 65.9333591\ttest: 77.2646976\tbest: 77.2646976 (121200)\ttotal: 40m 21s\tremaining: 2d 6h 49m 49s\n",
      "121400:\tlearn: 65.8962412\ttest: 77.2540123\tbest: 77.2539398 (121399)\ttotal: 40m 25s\tremaining: 2d 6h 49m 36s\n",
      "121600:\tlearn: 65.8658628\ttest: 77.2463119\tbest: 77.2463119 (121600)\ttotal: 40m 29s\tremaining: 2d 6h 49m 22s\n",
      "121800:\tlearn: 65.8359398\ttest: 77.2364953\tbest: 77.2364463 (121796)\ttotal: 40m 33s\tremaining: 2d 6h 49m 12s\n",
      "122000:\tlearn: 65.8055981\ttest: 77.2298892\tbest: 77.2295967 (121981)\ttotal: 40m 37s\tremaining: 2d 6h 48m 59s\n",
      "122200:\tlearn: 65.7744301\ttest: 77.2237249\tbest: 77.2237249 (122200)\ttotal: 40m 41s\tremaining: 2d 6h 48m 45s\n",
      "122400:\tlearn: 65.7368162\ttest: 77.2139315\tbest: 77.2138471 (122396)\ttotal: 40m 45s\tremaining: 2d 6h 48m 31s\n",
      "122600:\tlearn: 65.7047957\ttest: 77.2042458\tbest: 77.2042454 (122599)\ttotal: 40m 48s\tremaining: 2d 6h 48m 18s\n",
      "122800:\tlearn: 65.6713940\ttest: 77.1965263\tbest: 77.1963864 (122799)\ttotal: 40m 52s\tremaining: 2d 6h 48m 4s\n",
      "123000:\tlearn: 65.6334326\ttest: 77.1867148\tbest: 77.1866955 (122999)\ttotal: 40m 56s\tremaining: 2d 6h 47m 54s\n",
      "123200:\tlearn: 65.6003735\ttest: 77.1787549\tbest: 77.1787549 (123200)\ttotal: 41m\tremaining: 2d 6h 47m 58s\n",
      "123400:\tlearn: 65.5696007\ttest: 77.1690833\tbest: 77.1688690 (123387)\ttotal: 41m 5s\tremaining: 2d 6h 48m 19s\n",
      "123600:\tlearn: 65.5312031\ttest: 77.1592536\tbest: 77.1592536 (123600)\ttotal: 41m 9s\tremaining: 2d 6h 48m 31s\n",
      "123800:\tlearn: 65.4932893\ttest: 77.1479134\tbest: 77.1479134 (123800)\ttotal: 41m 13s\tremaining: 2d 6h 48m 52s\n",
      "124000:\tlearn: 65.4571383\ttest: 77.1355217\tbest: 77.1355217 (124000)\ttotal: 41m 17s\tremaining: 2d 6h 49m 7s\n",
      "124200:\tlearn: 65.4125928\ttest: 77.1239067\tbest: 77.1239067 (124200)\ttotal: 41m 22s\tremaining: 2d 6h 49m 19s\n",
      "124400:\tlearn: 65.3756713\ttest: 77.1147243\tbest: 77.1145685 (124393)\ttotal: 41m 26s\tremaining: 2d 6h 49m 22s\n",
      "124600:\tlearn: 65.3433420\ttest: 77.1057448\tbest: 77.1056310 (124595)\ttotal: 41m 30s\tremaining: 2d 6h 49m 33s\n",
      "124800:\tlearn: 65.3112031\ttest: 77.0975946\tbest: 77.0975946 (124800)\ttotal: 41m 34s\tremaining: 2d 6h 49m 52s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gunna\\Documents\\Maskinlæring\\Prosjekt\\power-predictor\\catboost.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gunna/Documents/Maskinl%C3%A6ring/Prosjekt/power-predictor/catboost.ipynb#W2sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m test_pool \u001b[39m=\u001b[39m Pool(data\u001b[39m=\u001b[39mX_test, label\u001b[39m=\u001b[39my_test, weight\u001b[39m=\u001b[39mtest_weight)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gunna/Documents/Maskinl%C3%A6ring/Prosjekt/power-predictor/catboost.ipynb#W2sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# Fit the model using the sample weights\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gunna/Documents/Maskinl%C3%A6ring/Prosjekt/power-predictor/catboost.ipynb#W2sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m reg\u001b[39m.\u001b[39;49mfit(train_pool, eval_set\u001b[39m=\u001b[39;49mtest_pool, early_stopping_rounds\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gunna/Documents/Maskinl%C3%A6ring/Prosjekt/power-predictor/catboost.ipynb#W2sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m reg_models\u001b[39m.\u001b[39mappend(reg)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gunna/Documents/Maskinl%C3%A6ring/Prosjekt/power-predictor/catboost.ipynb#W2sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m predictions \u001b[39m=\u001b[39m reg\u001b[39m.\u001b[39mpredict(test_pool)\n",
      "File \u001b[1;32mc:\\Users\\gunna\\Documents\\Maskinlæring\\Prosjekt\\power-predictor\\venv\\lib\\site-packages\\catboost\\core.py:5703\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5700\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[0;32m   5701\u001b[0m     CatBoostRegressor\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m-> 5703\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline,\n\u001b[0;32m   5704\u001b[0m                  use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description,\n\u001b[0;32m   5705\u001b[0m                  verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[0;32m   5706\u001b[0m                  save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "File \u001b[1;32mc:\\Users\\gunna\\Documents\\Maskinlæring\\Prosjekt\\power-predictor\\venv\\lib\\site-packages\\catboost\\core.py:2319\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2315\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2317\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[0;32m   2318\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2319\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[0;32m   2320\u001b[0m         train_pool,\n\u001b[0;32m   2321\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   2322\u001b[0m         params,\n\u001b[0;32m   2323\u001b[0m         allow_clear_pool,\n\u001b[0;32m   2324\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m   2325\u001b[0m     )\n\u001b[0;32m   2327\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2328\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32mc:\\Users\\gunna\\Documents\\Maskinlæring\\Prosjekt\\power-predictor\\venv\\lib\\site-packages\\catboost\\core.py:1723\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1722\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1723\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   1724\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:4645\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4694\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "total_mae = 0\n",
    "reg_models = []\n",
    "\n",
    "def compute_sample_weight(data):\n",
    "    # Assign weight of 2 for estimated data and 1 for observed data\n",
    "    return np.where(data['time_since_prediction'] > 0, 2, 1)\n",
    "\n",
    "for train_index, test_index in kf.split(x_whole):\n",
    "    reg = CatBoostRegressor(\n",
    "        iterations=10000000,\n",
    "        depth=8,\n",
    "        learning_rate=0.001,\n",
    "        loss_function='MAE',\n",
    "        verbose=200\n",
    "    )\n",
    "    \n",
    "    X_train, X_test = x_whole.iloc[train_index], x_whole.iloc[test_index]\n",
    "    y_train, y_test = y_whole.iloc[train_index], y_whole.iloc[test_index]\n",
    "    \n",
    "    # Compute sample weights for training and testing data\n",
    "    train_weight = compute_sample_weight(X_train)\n",
    "    test_weight = compute_sample_weight(X_test)\n",
    "\n",
    "    # Create Pool for training and testing\n",
    "    train_pool = Pool(data=X_train, label=y_train, weight=train_weight)\n",
    "    test_pool = Pool(data=X_test, label=y_test, weight=test_weight)\n",
    "\n",
    "    # Fit the model using the sample weights\n",
    "    reg.fit(train_pool, eval_set=test_pool, early_stopping_rounds=100)\n",
    "\n",
    "    reg_models.append(reg)\n",
    "    predictions = reg.predict(test_pool)\n",
    "    \n",
    "    # Compute weighted MAE manually\n",
    "    weighted_mae = np.sum(test_weight * np.abs(y_test - predictions)) / np.sum(test_weight)\n",
    "    total_mae += weighted_mae\n",
    "    \n",
    "    print(f\"Fold {len(reg_models)}, Weighted Mean Absolute Error: {weighted_mae}\")\n",
    "\n",
    "average_mae = total_mae / num_folds\n",
    "print(f\"Average Weighted Mean Absolute Error: {average_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_predict(x_values :pd.DataFrame, models) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function for predicting on multiple models and averaging the results\n",
    "    \"\"\"\n",
    "    results = models[0].predict(x_values)\n",
    "    for model in models[1:]:\n",
    "        prediction = model.predict(x_values)\n",
    "        results += prediction\n",
    "    \n",
    "    results = results / len(models)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reg_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred_val_obs_combined \u001b[38;5;241m=\u001b[39m multi_predict(x_whole_obs, \u001b[43mreg_models\u001b[49m)\n\u001b[1;32m      2\u001b[0m y_pred_val_est_combined \u001b[38;5;241m=\u001b[39m multi_predict(x_whole_est, reg_models)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Evaluate the model's performance using Mean Absolute Error (MAE) on the combined validation observed data\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reg_models' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred_val_obs_combined = multi_predict(x_whole_obs, reg_models)\n",
    "y_pred_val_est_combined = multi_predict(x_whole_est, reg_models)\n",
    "\n",
    "# Evaluate the model's performance using Mean Absolute Error (MAE) on the combined validation observed data\n",
    "mae_obs_combined = mean_absolute_error(y_whole_obs, y_pred_val_obs_combined)\n",
    "mae_est_combined = mean_absolute_error(y_whole_est, y_pred_val_est_combined)\n",
    "print('MAE on validation observed data: ', mae_obs_combined)\n",
    "print('MAE on validation estimated data: ', mae_est_combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_prediction = multi_predict(x_whole, reg_models)\n",
    "\n",
    "test_prediction = multi_predict(X_val_est_combined, reg_models)\n",
    "# Observed Data\n",
    "# Set up the plotting area\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Line plot of Actual values\n",
    "plt.plot(y_whole.reset_index(drop=True), label='Actual', linestyle='-', marker='o', markersize=5, alpha=0.7, color='blue')\n",
    "# Line plot of Predicted values\n",
    "plt.plot(train_prediction, label='Predicted', linestyle='--', marker='x', markersize=5, alpha=0.7, color='orange')\n",
    "# Titles and labels\n",
    "plt.title('Actual vs Predicted - Observed Data', fontsize=16)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualise the monthly predictions\n",
    "# Observed Data\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Line plot of Actual values\n",
    "plt.plot(y_whole.reset_index(drop=True)[:24*7*4], label='Actual', linestyle='-', marker='o', markersize=5, alpha=0.7, color='blue')\n",
    "# Line plot of Predicted values\n",
    "plt.plot(train_prediction[:24*7*4], label='Predicted', linestyle='--', marker='x', markersize=5, alpha=0.7, color='orange')\n",
    "# Titles and labels\n",
    "plt.title('Actual vs Predicted - Observed Data', fontsize=16)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estimated Data\n",
    "# Set up the plotting area\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Line plot of Actual values\n",
    "plt.plot(y_val_est_combined.reset_index(drop=True), label='Actual', linestyle='-', marker='o', markersize=5, alpha=0.7, color='blue')\n",
    "# Line plot of Predicted values\n",
    "plt.plot(test_prediction, label='Predicted', linestyle='--', marker='x', markersize=5, alpha=0.7, color='orange')\n",
    "# Titles and labels\n",
    "plt.title('Actual vs Predicted - Estimated Data', fontsize=16)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Visualise the monthly predictions\n",
    "# Estimated Data\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Line plot of Actual values\n",
    "plt.plot(y_val_est_combined.reset_index(drop=True)[:24*7*4], label='Actual', linestyle='-', marker='o', markersize=5, alpha=0.7, color='blue')\n",
    "# Line plot of Predicted values\n",
    "plt.plot(test_prediction[:24*7*4], label='Predicted', linestyle='--', marker='x', markersize=5, alpha=0.7, color='orange')\n",
    "plt.title('Actual vs Predicted - Estimated Data', fontsize=16)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"catboost_models.pkl\", \"wb\") as file:\n",
    "    pickle.dump(reg_models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'catboost_models.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcatboost_models.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      2\u001b[0m     loaded_reg_models \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:308\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m     )\n\u001b[0;32m--> 308\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'catboost_models.pkl'"
     ]
    }
   ],
   "source": [
    "with open(\"catboost_models.pkl\", \"rb\") as file:\n",
    "    loaded_reg_models = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = multi_predict(x_test_whole, reg_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post process\n",
    "\n",
    "from src.features.postprocess_data import postprocess_data\n",
    "\n",
    "processed_y_pred = postprocess_data(x_test_whole, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  prediction\n",
      "0   0    0.000000\n",
      "1   1    0.000000\n",
      "2   2    0.093490\n",
      "3   3   53.153196\n",
      "4   4  308.907390\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "from src.models.saving import save_predictions\n",
    "\n",
    "save_predictions(processed_y_pred, 'catboost')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
