{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking of models into two layers\n",
    "1. First layer: train models on the whole training set\n",
    "2. Second layer: train a model on the first layer's predictions and the rest of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\bruker\\onedrive\\ntnu semester 05\\tdt4173 maskinlæring\\ml_power_predictor\\venv\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\bruker\\onedrive\\ntnu semester 05\\tdt4173 maskinlæring\\ml_power_predictor\\venv\\lib\\site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\bruker\\onedrive\\ntnu semester 05\\tdt4173 maskinlæring\\ml_power_predictor\\venv\\lib\\site-packages (from xgboost) (1.9.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\bruker\\onedrive\\ntnu semester 05\\tdt4173 maskinlæring\\ml_power_predictor\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\bruker\\onedrive\\ntnu semester 05\\tdt4173 maskinlæring\\ml_power_predictor\\venv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "\n",
    "from src.features.preprocess_data import get_preprocessed_test_data, fetch_preprocessed_data\n",
    "pd.set_option('display.max_columns', 200)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_xgb: bool = False\n",
    "load_lgb: bool = False\n",
    "load_cat: bool = False\n",
    "load_rf: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_estimated_a.shape = (2880, 47), X_test_estimated_b.shape = (2880, 47), X_test_estimated_c.shape = (2880, 47)\n",
      "After temporal alignment\n",
      "X_test_estimated_a.shape = (720, 47), X_test_estimated_b.shape = (720, 47), X_test_estimated_c.shape = (720, 47)\n",
      "X_test_estimated_a_processed.shape = (720, 46), X_test_estimated_b_processed.shape = (720, 46), X_test_estimated_c_processed.shape = (720, 46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>cloud_base_agl:m</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad:W</th>\n",
       "      <th>direct_rad_1h:J</th>\n",
       "      <th>effective_cloud_cover:p</th>\n",
       "      <th>is_day:idx</th>\n",
       "      <th>is_in_shadow:idx</th>\n",
       "      <th>precip_5min:mm</th>\n",
       "      <th>precip_type_5min:idx</th>\n",
       "      <th>pressure_50m:hPa</th>\n",
       "      <th>prob_rime:p</th>\n",
       "      <th>rain_water:kgm2</th>\n",
       "      <th>relative_humidity_1000hPa:p</th>\n",
       "      <th>sun_azimuth:d</th>\n",
       "      <th>super_cooled_liquid_water:kgm2</th>\n",
       "      <th>t_1000hPa:K</th>\n",
       "      <th>total_cloud_cover:p</th>\n",
       "      <th>visibility:m</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>wind_speed_u_10m:ms</th>\n",
       "      <th>wind_speed_v_10m:ms</th>\n",
       "      <th>wind_speed_w_1000hPa:ms</th>\n",
       "      <th>location_a</th>\n",
       "      <th>location_b</th>\n",
       "      <th>location_c</th>\n",
       "      <th>sin_day_of_year</th>\n",
       "      <th>cos_day_of_year</th>\n",
       "      <th>sin_hour</th>\n",
       "      <th>cos_hour</th>\n",
       "      <th>sun_product</th>\n",
       "      <th>modified_solar_elevation</th>\n",
       "      <th>effective_radiation</th>\n",
       "      <th>time_since_prediction</th>\n",
       "      <th>cloud_ratio</th>\n",
       "      <th>cloud_cover_over_30%</th>\n",
       "      <th>sun_addition</th>\n",
       "      <th>is_freezing</th>\n",
       "      <th>is_snow</th>\n",
       "      <th>is_rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.2</td>\n",
       "      <td>1.18175</td>\n",
       "      <td>1.351672e+06</td>\n",
       "      <td>440.600006</td>\n",
       "      <td>7231.174805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>291.250000</td>\n",
       "      <td>95.500000</td>\n",
       "      <td>294605.53125</td>\n",
       "      <td>271.225006</td>\n",
       "      <td>872357.56250</td>\n",
       "      <td>54.224998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1007.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.375000</td>\n",
       "      <td>92.172501</td>\n",
       "      <td>0.00</td>\n",
       "      <td>294.625000</td>\n",
       "      <td>98.925003</td>\n",
       "      <td>48152.375000</td>\n",
       "      <td>2.125</td>\n",
       "      <td>-2.000</td>\n",
       "      <td>-0.750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027950</td>\n",
       "      <td>-0.999609</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>25901.988281</td>\n",
       "      <td>0.455669</td>\n",
       "      <td>0.645392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.548142</td>\n",
       "      <td>1</td>\n",
       "      <td>366.725006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.7</td>\n",
       "      <td>1.19250</td>\n",
       "      <td>2.456032e+06</td>\n",
       "      <td>637.599976</td>\n",
       "      <td>1410.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.399994</td>\n",
       "      <td>145.525009</td>\n",
       "      <td>447652.68750</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>11749.87500</td>\n",
       "      <td>99.675003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1001.400024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>80.699997</td>\n",
       "      <td>236.257751</td>\n",
       "      <td>0.10</td>\n",
       "      <td>292.100006</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>5903.875000</td>\n",
       "      <td>1.350</td>\n",
       "      <td>-1.225</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.310857</td>\n",
       "      <td>-0.950457</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>844.045105</td>\n",
       "      <td>0.611489</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>1</td>\n",
       "      <td>151.325012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.5</td>\n",
       "      <td>1.20150</td>\n",
       "      <td>2.172293e+05</td>\n",
       "      <td>107.400002</td>\n",
       "      <td>2315.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>285.299988</td>\n",
       "      <td>42.200001</td>\n",
       "      <td>100314.65625</td>\n",
       "      <td>65.099998</td>\n",
       "      <td>135992.90625</td>\n",
       "      <td>23.299999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1006.849976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.049999</td>\n",
       "      <td>85.390503</td>\n",
       "      <td>0.00</td>\n",
       "      <td>291.700012</td>\n",
       "      <td>43.549999</td>\n",
       "      <td>49974.699219</td>\n",
       "      <td>3.375</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>3.350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.804826</td>\n",
       "      <td>-0.593511</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>2747.219971</td>\n",
       "      <td>0.164161</td>\n",
       "      <td>0.626034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.535017</td>\n",
       "      <td>0</td>\n",
       "      <td>107.300003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.3</td>\n",
       "      <td>1.24800</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>131.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.100006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>99.574997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>992.949951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.650002</td>\n",
       "      <td>127.701752</td>\n",
       "      <td>0.35</td>\n",
       "      <td>278.100006</td>\n",
       "      <td>99.974998</td>\n",
       "      <td>3399.375000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>5.950</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.141444</td>\n",
       "      <td>0.989946</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995999</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.3</td>\n",
       "      <td>1.27175</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8580.474609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>49.400002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1012.200012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.649994</td>\n",
       "      <td>346.724243</td>\n",
       "      <td>0.00</td>\n",
       "      <td>278.600006</td>\n",
       "      <td>98.824997</td>\n",
       "      <td>27873.150391</td>\n",
       "      <td>1.450</td>\n",
       "      <td>1.450</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.931210</td>\n",
       "      <td>-0.364483</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499874</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolute_humidity_2m:gm3  air_density_2m:kgm3  clear_sky_energy_1h:J  \\\n",
       "0                      15.2              1.18175           1.351672e+06   \n",
       "1                      13.7              1.19250           2.456032e+06   \n",
       "2                      10.5              1.20150           2.172293e+05   \n",
       "3                       6.3              1.24800           0.000000e+00   \n",
       "4                       6.3              1.27175           0.000000e+00   \n",
       "\n",
       "   clear_sky_rad:W  cloud_base_agl:m  dew_or_rime:idx  dew_point_2m:K  \\\n",
       "0       440.600006       7231.174805              0.0      291.250000   \n",
       "1       637.599976       1410.500000              0.0      289.399994   \n",
       "2       107.400002       2315.000000              0.0      285.299988   \n",
       "3         0.000000        131.375000              0.0      277.100006   \n",
       "4         0.000000       8580.474609              0.0      277.000000   \n",
       "\n",
       "   diffuse_rad:W  diffuse_rad_1h:J  direct_rad:W  direct_rad_1h:J  \\\n",
       "0      95.500000      294605.53125    271.225006     872357.56250   \n",
       "1     145.525009      447652.68750      5.800000      11749.87500   \n",
       "2      42.200001      100314.65625     65.099998     135992.90625   \n",
       "3       0.000000           0.00000      0.000000          0.00000   \n",
       "4       0.000000           0.00000      0.000000          0.00000   \n",
       "\n",
       "   effective_cloud_cover:p  is_day:idx  is_in_shadow:idx  precip_5min:mm  \\\n",
       "0                54.224998         1.0               0.0             0.0   \n",
       "1                99.675003         1.0               0.0             0.0   \n",
       "2                23.299999         1.0               0.0             0.0   \n",
       "3                99.574997         0.0               1.0             0.0   \n",
       "4                49.400002         0.0               1.0             0.0   \n",
       "\n",
       "   precip_type_5min:idx  pressure_50m:hPa  prob_rime:p  rain_water:kgm2  \\\n",
       "0                   0.0       1007.500000          0.0              0.0   \n",
       "1                   0.0       1001.400024          0.0              0.1   \n",
       "2                   0.0       1006.849976          0.0              0.0   \n",
       "3                   0.0        992.949951          0.0              0.0   \n",
       "4                   0.0       1012.200012          0.0              0.0   \n",
       "\n",
       "   relative_humidity_1000hPa:p  sun_azimuth:d  super_cooled_liquid_water:kgm2  \\\n",
       "0                    72.375000      92.172501                            0.00   \n",
       "1                    80.699997     236.257751                            0.10   \n",
       "2                    59.049999      85.390503                            0.00   \n",
       "3                    93.650002     127.701752                            0.35   \n",
       "4                    81.649994     346.724243                            0.00   \n",
       "\n",
       "   t_1000hPa:K  total_cloud_cover:p  visibility:m  wind_speed_10m:ms  \\\n",
       "0   294.625000            98.925003  48152.375000              2.125   \n",
       "1   292.100006           100.000000   5903.875000              1.350   \n",
       "2   291.700012            43.549999  49974.699219              3.375   \n",
       "3   278.100006            99.974998   3399.375000              6.000   \n",
       "4   278.600006            98.824997  27873.150391              1.450   \n",
       "\n",
       "   wind_speed_u_10m:ms  wind_speed_v_10m:ms  wind_speed_w_1000hPa:ms  \\\n",
       "0               -2.000               -0.750                      0.0   \n",
       "1               -1.225                0.525                      0.0   \n",
       "2               -0.400                3.350                      0.0   \n",
       "3                5.950               -0.500                      0.0   \n",
       "4                1.450               -0.275                      0.0   \n",
       "\n",
       "   location_a  location_b  location_c  sin_day_of_year  cos_day_of_year  \\\n",
       "0           1           0           0         0.027950        -0.999609   \n",
       "1           0           1           0        -0.310857        -0.950457   \n",
       "2           1           0           0        -0.804826        -0.593511   \n",
       "3           1           0           0        -0.141444         0.989946   \n",
       "4           1           0           0         0.931210        -0.364483   \n",
       "\n",
       "   sin_hour      cos_hour   sun_product  modified_solar_elevation  \\\n",
       "0  1.000000  6.123234e-17  25901.988281                  0.455669   \n",
       "1 -0.500000 -8.660254e-01    844.045105                  0.611489   \n",
       "2  0.965926  2.588190e-01   2747.219971                  0.164161   \n",
       "3  0.965926 -2.588190e-01      0.000000                  0.000000   \n",
       "4 -0.500000  8.660254e-01      0.000000                  0.000000   \n",
       "\n",
       "   effective_radiation  time_since_prediction  cloud_ratio  \\\n",
       "0             0.645392                    0.0     0.548142   \n",
       "1             0.004784                    0.0     0.996750   \n",
       "2             0.626034                    0.0     0.535017   \n",
       "3             0.000000                    0.0     0.995999   \n",
       "4             0.000000                    0.0     0.499874   \n",
       "\n",
       "   cloud_cover_over_30%  sun_addition  is_freezing  is_snow  is_rain  \n",
       "0                     1    366.725006            0        0        0  \n",
       "1                     1    151.325012            0        0        0  \n",
       "2                     0    107.300003            0        0        0  \n",
       "3                     1      0.000000            0        0        0  \n",
       "4                     1      0.000000            0        0        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_obs_combined, X_val_obs_combined, y_train_obs_combined, y_val_obs_combined, X_train_est_combined, X_val_est_combined, y_train_est_combined, y_val_est_combined = fetch_preprocessed_data()\n",
    "x_test_whole = get_preprocessed_test_data()\n",
    "\n",
    "x_whole = pd.concat([X_train_obs_combined, X_val_obs_combined, X_train_est_combined, X_val_est_combined])\n",
    "y_whole = pd.concat([y_train_obs_combined, y_val_obs_combined, y_train_est_combined, y_val_est_combined])\n",
    "x_whole.reset_index(drop=True, inplace=True)\n",
    "y_whole.reset_index(drop=True, inplace=True)\n",
    "\n",
    "x_whole.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split for the base layer and meta layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['absolute_humidity_2m:gm3', 'air_density_2m:kgm3',\n",
       "       'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'cloud_base_agl:m',\n",
       "       'dew_or_rime:idx', 'dew_point_2m:K', 'diffuse_rad:W',\n",
       "       'diffuse_rad_1h:J', 'direct_rad:W', 'direct_rad_1h:J',\n",
       "       'effective_cloud_cover:p', 'is_day:idx', 'is_in_shadow:idx',\n",
       "       'precip_5min:mm', 'precip_type_5min:idx', 'pressure_50m:hPa',\n",
       "       'prob_rime:p', 'rain_water:kgm2', 'relative_humidity_1000hPa:p',\n",
       "       'sun_azimuth:d', 'super_cooled_liquid_water:kgm2', 't_1000hPa:K',\n",
       "       'total_cloud_cover:p', 'visibility:m', 'wind_speed_10m:ms',\n",
       "       'wind_speed_u_10m:ms', 'wind_speed_v_10m:ms', 'wind_speed_w_1000hPa:ms',\n",
       "       'location_a', 'location_b', 'location_c', 'sin_day_of_year',\n",
       "       'cos_day_of_year', 'sin_hour', 'cos_hour', 'sun_product',\n",
       "       'modified_solar_elevation', 'effective_radiation',\n",
       "       'time_since_prediction', 'cloud_ratio', 'cloud_cover_over_30%',\n",
       "       'sun_addition', 'is_freezing', 'is_snow', 'is_rain'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The base layer gets 80% of the data\n",
    "# The meta layer gets 20% of the data\n",
    "base_to_meta_layer_split = 0.8\n",
    "\n",
    "base_x_train = x_whole.sample(frac=base_to_meta_layer_split)\n",
    "meta_x_train = x_whole.sample(frac=1-base_to_meta_layer_split)\n",
    "\n",
    "# Get the corresponding y values\n",
    "base_y_train = y_whole[base_x_train.index]\n",
    "meta_y_train = y_whole[meta_x_train.index]\n",
    "base_x_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Base level models\n",
    "It is important to use a variety of models to get a diverse set of predictions.\n",
    "\n",
    "I want a model to check if there is a linear relationship between the location features and the target. I will use a linear regression model for this.\n",
    "I want to check if the different irradiation values are correlated with the target. I will use xgboost for this.\n",
    "I want to check if the different temperature values are correlated with the target. I will use \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "The XGBoost model is a gradient boosting model. It is a tree based model that uses the gradient descent algorithm to minimize the loss function. The loss function is a combination of the training loss and a regularization term. The regularization term is used to prevent overfitting. The model is trained on the training set and the validation set is used to check if the model is overfitting. The model is then trained on the whole training set and the test set is used to check the model's performance.\n",
    "\n",
    "Utilizing k-fold cross validation to train the model on different subsets of the training set and validate on the rest of the training set. This is done to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mae:412.32484\n",
      "[100]\tvalidation_0-mae:375.22244\n",
      "[200]\tvalidation_0-mae:342.19067\n",
      "[300]\tvalidation_0-mae:312.83357\n",
      "[400]\tvalidation_0-mae:286.83419\n",
      "[500]\tvalidation_0-mae:263.70416\n",
      "[600]\tvalidation_0-mae:243.17075\n",
      "[700]\tvalidation_0-mae:225.06641\n",
      "[800]\tvalidation_0-mae:209.03974\n",
      "[900]\tvalidation_0-mae:194.79980\n",
      "[1000]\tvalidation_0-mae:182.08172\n",
      "[1100]\tvalidation_0-mae:170.78507\n",
      "[1200]\tvalidation_0-mae:160.68980\n",
      "[1300]\tvalidation_0-mae:151.74598\n",
      "[1400]\tvalidation_0-mae:143.81539\n",
      "[1500]\tvalidation_0-mae:136.74424\n",
      "[1600]\tvalidation_0-mae:130.44119\n",
      "[1700]\tvalidation_0-mae:124.83099\n",
      "[1800]\tvalidation_0-mae:119.84163\n",
      "[1900]\tvalidation_0-mae:115.41088\n",
      "[2000]\tvalidation_0-mae:111.42565\n",
      "[2100]\tvalidation_0-mae:107.86877\n",
      "[2200]\tvalidation_0-mae:104.68681\n",
      "[2300]\tvalidation_0-mae:101.82690\n",
      "[2400]\tvalidation_0-mae:99.26959\n",
      "[2500]\tvalidation_0-mae:96.94830\n",
      "[2600]\tvalidation_0-mae:94.88799\n",
      "[2700]\tvalidation_0-mae:93.04642\n",
      "[2800]\tvalidation_0-mae:91.39761\n",
      "[2900]\tvalidation_0-mae:89.93346\n",
      "[3000]\tvalidation_0-mae:88.59221\n",
      "[3100]\tvalidation_0-mae:87.34952\n",
      "[3200]\tvalidation_0-mae:86.23122\n",
      "[3300]\tvalidation_0-mae:85.24218\n",
      "[3400]\tvalidation_0-mae:84.34521\n",
      "[3500]\tvalidation_0-mae:83.57262\n",
      "[3600]\tvalidation_0-mae:82.84804\n",
      "[3700]\tvalidation_0-mae:82.17974\n",
      "[3800]\tvalidation_0-mae:81.60402\n",
      "[3900]\tvalidation_0-mae:81.07821\n",
      "[4000]\tvalidation_0-mae:80.62859\n",
      "[4100]\tvalidation_0-mae:80.24508\n",
      "[4200]\tvalidation_0-mae:79.87766\n",
      "[4300]\tvalidation_0-mae:79.51384\n",
      "[4400]\tvalidation_0-mae:79.21248\n",
      "[4500]\tvalidation_0-mae:78.93530\n",
      "[4600]\tvalidation_0-mae:78.67973\n",
      "[4700]\tvalidation_0-mae:78.44421\n",
      "[4800]\tvalidation_0-mae:78.23322\n",
      "[4900]\tvalidation_0-mae:78.03770\n",
      "[5000]\tvalidation_0-mae:77.84867\n",
      "[5100]\tvalidation_0-mae:77.66877\n",
      "[5200]\tvalidation_0-mae:77.47035\n",
      "[5300]\tvalidation_0-mae:77.31348\n",
      "[5400]\tvalidation_0-mae:77.17073\n",
      "[5500]\tvalidation_0-mae:77.04778\n",
      "[5600]\tvalidation_0-mae:76.91579\n",
      "[5700]\tvalidation_0-mae:76.79450\n",
      "[5800]\tvalidation_0-mae:76.72141\n",
      "[5900]\tvalidation_0-mae:76.64102\n",
      "[6000]\tvalidation_0-mae:76.56053\n",
      "[6100]\tvalidation_0-mae:76.48863\n",
      "[6200]\tvalidation_0-mae:76.42641\n",
      "[6300]\tvalidation_0-mae:76.35365\n",
      "[6400]\tvalidation_0-mae:76.26185\n",
      "[6500]\tvalidation_0-mae:76.15984\n",
      "[6600]\tvalidation_0-mae:76.05766\n",
      "[6700]\tvalidation_0-mae:75.96480\n",
      "[6800]\tvalidation_0-mae:75.88062\n",
      "[6900]\tvalidation_0-mae:75.81563\n",
      "[7000]\tvalidation_0-mae:75.73503\n",
      "[7100]\tvalidation_0-mae:75.65972\n",
      "[7200]\tvalidation_0-mae:75.58447\n",
      "[7300]\tvalidation_0-mae:75.51790\n",
      "[7400]\tvalidation_0-mae:75.45090\n",
      "[7500]\tvalidation_0-mae:75.38895\n",
      "[7600]\tvalidation_0-mae:75.33416\n",
      "[7700]\tvalidation_0-mae:75.27721\n",
      "[7800]\tvalidation_0-mae:75.21554\n",
      "[7900]\tvalidation_0-mae:75.16235\n",
      "[8000]\tvalidation_0-mae:75.10876\n",
      "[8100]\tvalidation_0-mae:75.04881\n",
      "[8200]\tvalidation_0-mae:74.98390\n",
      "[8300]\tvalidation_0-mae:74.91926\n",
      "[8400]\tvalidation_0-mae:74.85750\n",
      "[8500]\tvalidation_0-mae:74.78940\n",
      "[8600]\tvalidation_0-mae:74.72805\n",
      "[8700]\tvalidation_0-mae:74.67859\n",
      "[8800]\tvalidation_0-mae:74.63583\n",
      "[8900]\tvalidation_0-mae:74.58262\n",
      "[9000]\tvalidation_0-mae:74.54121\n",
      "[9100]\tvalidation_0-mae:74.49018\n",
      "[9200]\tvalidation_0-mae:74.44583\n",
      "[9300]\tvalidation_0-mae:74.38902\n",
      "[9400]\tvalidation_0-mae:74.32351\n",
      "[9500]\tvalidation_0-mae:74.25904\n",
      "[9600]\tvalidation_0-mae:74.20819\n",
      "[9700]\tvalidation_0-mae:74.15734\n",
      "[9800]\tvalidation_0-mae:74.13029\n",
      "[9900]\tvalidation_0-mae:74.11190\n",
      "[10000]\tvalidation_0-mae:74.08833\n",
      "[10100]\tvalidation_0-mae:74.06399\n",
      "[10200]\tvalidation_0-mae:74.03452\n",
      "[10300]\tvalidation_0-mae:74.01162\n",
      "[10400]\tvalidation_0-mae:73.98852\n",
      "[10500]\tvalidation_0-mae:73.95991\n",
      "[10600]\tvalidation_0-mae:73.93790\n",
      "[10700]\tvalidation_0-mae:73.91623\n",
      "[10800]\tvalidation_0-mae:73.88008\n",
      "[10900]\tvalidation_0-mae:73.84947\n",
      "[11000]\tvalidation_0-mae:73.82094\n",
      "[11100]\tvalidation_0-mae:73.78932\n",
      "[11200]\tvalidation_0-mae:73.76631\n",
      "[11300]\tvalidation_0-mae:73.73387\n",
      "[11400]\tvalidation_0-mae:73.69946\n",
      "[11500]\tvalidation_0-mae:73.66715\n",
      "[11600]\tvalidation_0-mae:73.62963\n",
      "[11700]\tvalidation_0-mae:73.61404\n",
      "[11800]\tvalidation_0-mae:73.60004\n",
      "[11900]\tvalidation_0-mae:73.59047\n",
      "[12000]\tvalidation_0-mae:73.57415\n",
      "[12100]\tvalidation_0-mae:73.54767\n",
      "[12200]\tvalidation_0-mae:73.52263\n",
      "[12300]\tvalidation_0-mae:73.49617\n",
      "[12400]\tvalidation_0-mae:73.47533\n",
      "[12500]\tvalidation_0-mae:73.45249\n",
      "[12600]\tvalidation_0-mae:73.42619\n",
      "[12700]\tvalidation_0-mae:73.40085\n",
      "[12800]\tvalidation_0-mae:73.37011\n",
      "[12900]\tvalidation_0-mae:73.34390\n",
      "[13000]\tvalidation_0-mae:73.31841\n",
      "[13100]\tvalidation_0-mae:73.28930\n",
      "[13200]\tvalidation_0-mae:73.26114\n",
      "[13300]\tvalidation_0-mae:73.23807\n",
      "[13400]\tvalidation_0-mae:73.21040\n",
      "[13500]\tvalidation_0-mae:73.17431\n",
      "[13600]\tvalidation_0-mae:73.14557\n",
      "[13700]\tvalidation_0-mae:73.12009\n",
      "[13800]\tvalidation_0-mae:73.08820\n",
      "[13900]\tvalidation_0-mae:73.04644\n",
      "[14000]\tvalidation_0-mae:73.01885\n",
      "[14100]\tvalidation_0-mae:72.99084\n",
      "[14200]\tvalidation_0-mae:72.97114\n",
      "[14300]\tvalidation_0-mae:72.95412\n",
      "[14400]\tvalidation_0-mae:72.93743\n",
      "[14500]\tvalidation_0-mae:72.92132\n",
      "[14600]\tvalidation_0-mae:72.90072\n",
      "[14700]\tvalidation_0-mae:72.87647\n",
      "[14800]\tvalidation_0-mae:72.85004\n",
      "[14900]\tvalidation_0-mae:72.82434\n",
      "[15000]\tvalidation_0-mae:72.80517\n",
      "[15100]\tvalidation_0-mae:72.78278\n",
      "[15200]\tvalidation_0-mae:72.76444\n",
      "[15300]\tvalidation_0-mae:72.74958\n",
      "[15400]\tvalidation_0-mae:72.73126\n",
      "[15500]\tvalidation_0-mae:72.71554\n",
      "[15600]\tvalidation_0-mae:72.69847\n",
      "[15700]\tvalidation_0-mae:72.67886\n",
      "[15800]\tvalidation_0-mae:72.66235\n",
      "[15900]\tvalidation_0-mae:72.64233\n",
      "[16000]\tvalidation_0-mae:72.62720\n",
      "[16100]\tvalidation_0-mae:72.61362\n",
      "[16200]\tvalidation_0-mae:72.59951\n",
      "[16300]\tvalidation_0-mae:72.58435\n",
      "[16400]\tvalidation_0-mae:72.56743\n",
      "[16500]\tvalidation_0-mae:72.54760\n",
      "[16600]\tvalidation_0-mae:72.53130\n",
      "[16700]\tvalidation_0-mae:72.51473\n",
      "[16800]\tvalidation_0-mae:72.49739\n",
      "[16900]\tvalidation_0-mae:72.48180\n",
      "[17000]\tvalidation_0-mae:72.46538\n",
      "[17100]\tvalidation_0-mae:72.45340\n",
      "[17200]\tvalidation_0-mae:72.44619\n",
      "[17300]\tvalidation_0-mae:72.43789\n",
      "[17400]\tvalidation_0-mae:72.43203\n",
      "[17451]\tvalidation_0-mae:72.43250\n",
      "Fold 72.43189210091779, Mean Absolute Error: 72.43189210091779\n",
      "[0]\tvalidation_0-mae:421.41197\n",
      "[100]\tvalidation_0-mae:383.36539\n",
      "[200]\tvalidation_0-mae:349.60212\n",
      "[300]\tvalidation_0-mae:319.64482\n",
      "[400]\tvalidation_0-mae:293.16023\n",
      "[500]\tvalidation_0-mae:269.80172\n",
      "[600]\tvalidation_0-mae:249.03916\n",
      "[700]\tvalidation_0-mae:230.64424\n",
      "[800]\tvalidation_0-mae:214.30947\n",
      "[900]\tvalidation_0-mae:199.86589\n",
      "[1000]\tvalidation_0-mae:187.15589\n",
      "[1100]\tvalidation_0-mae:175.84691\n",
      "[1200]\tvalidation_0-mae:165.75312\n",
      "[1300]\tvalidation_0-mae:156.73009\n",
      "[1400]\tvalidation_0-mae:148.75844\n",
      "[1500]\tvalidation_0-mae:141.62657\n",
      "[1600]\tvalidation_0-mae:135.25325\n",
      "[1700]\tvalidation_0-mae:129.52144\n",
      "[1800]\tvalidation_0-mae:124.35724\n",
      "[1900]\tvalidation_0-mae:119.72178\n",
      "[2000]\tvalidation_0-mae:115.59625\n",
      "[2100]\tvalidation_0-mae:111.92491\n",
      "[2200]\tvalidation_0-mae:108.66198\n",
      "[2300]\tvalidation_0-mae:105.70077\n",
      "[2400]\tvalidation_0-mae:103.03973\n",
      "[2500]\tvalidation_0-mae:100.69772\n",
      "[2600]\tvalidation_0-mae:98.58235\n",
      "[2700]\tvalidation_0-mae:96.67588\n",
      "[2800]\tvalidation_0-mae:95.00529\n",
      "[2900]\tvalidation_0-mae:93.48847\n",
      "[3000]\tvalidation_0-mae:92.13313\n",
      "[3100]\tvalidation_0-mae:90.89156\n",
      "[3200]\tvalidation_0-mae:89.75237\n",
      "[3300]\tvalidation_0-mae:88.71078\n",
      "[3400]\tvalidation_0-mae:87.76946\n",
      "[3500]\tvalidation_0-mae:86.91352\n",
      "[3600]\tvalidation_0-mae:86.13375\n",
      "[3700]\tvalidation_0-mae:85.45269\n",
      "[3800]\tvalidation_0-mae:84.85181\n",
      "[3900]\tvalidation_0-mae:84.33934\n",
      "[4000]\tvalidation_0-mae:83.86822\n",
      "[4100]\tvalidation_0-mae:83.43865\n",
      "[4200]\tvalidation_0-mae:83.05722\n",
      "[4300]\tvalidation_0-mae:82.69061\n",
      "[4400]\tvalidation_0-mae:82.36760\n",
      "[4500]\tvalidation_0-mae:82.07443\n",
      "[4600]\tvalidation_0-mae:81.81556\n",
      "[4700]\tvalidation_0-mae:81.59067\n",
      "[4800]\tvalidation_0-mae:81.37833\n",
      "[4900]\tvalidation_0-mae:81.17358\n",
      "[5000]\tvalidation_0-mae:80.99408\n",
      "[5100]\tvalidation_0-mae:80.84253\n",
      "[5200]\tvalidation_0-mae:80.71699\n",
      "[5300]\tvalidation_0-mae:80.58656\n",
      "[5400]\tvalidation_0-mae:80.46813\n",
      "[5500]\tvalidation_0-mae:80.35020\n",
      "[5600]\tvalidation_0-mae:80.22074\n",
      "[5700]\tvalidation_0-mae:80.11805\n",
      "[5800]\tvalidation_0-mae:80.02610\n",
      "[5900]\tvalidation_0-mae:79.94405\n",
      "[6000]\tvalidation_0-mae:79.84248\n",
      "[6100]\tvalidation_0-mae:79.75345\n",
      "[6200]\tvalidation_0-mae:79.62889\n",
      "[6300]\tvalidation_0-mae:79.51053\n",
      "[6400]\tvalidation_0-mae:79.38416\n",
      "[6500]\tvalidation_0-mae:79.29903\n",
      "[6600]\tvalidation_0-mae:79.22518\n",
      "[6700]\tvalidation_0-mae:79.12696\n",
      "[6800]\tvalidation_0-mae:79.02785\n",
      "[6900]\tvalidation_0-mae:78.95332\n",
      "[7000]\tvalidation_0-mae:78.88417\n",
      "[7100]\tvalidation_0-mae:78.81420\n",
      "[7200]\tvalidation_0-mae:78.75157\n",
      "[7300]\tvalidation_0-mae:78.67364\n",
      "[7400]\tvalidation_0-mae:78.59662\n",
      "[7500]\tvalidation_0-mae:78.53449\n",
      "[7600]\tvalidation_0-mae:78.45793\n",
      "[7700]\tvalidation_0-mae:78.38419\n",
      "[7800]\tvalidation_0-mae:78.32640\n",
      "[7900]\tvalidation_0-mae:78.26230\n",
      "[8000]\tvalidation_0-mae:78.19034\n",
      "[8100]\tvalidation_0-mae:78.11559\n",
      "[8200]\tvalidation_0-mae:78.04324\n",
      "[8300]\tvalidation_0-mae:77.97099\n",
      "[8400]\tvalidation_0-mae:77.90558\n",
      "[8500]\tvalidation_0-mae:77.84828\n",
      "[8600]\tvalidation_0-mae:77.80128\n",
      "[8700]\tvalidation_0-mae:77.75064\n",
      "[8800]\tvalidation_0-mae:77.70869\n",
      "[8900]\tvalidation_0-mae:77.66396\n",
      "[9000]\tvalidation_0-mae:77.62068\n",
      "[9100]\tvalidation_0-mae:77.56676\n",
      "[9200]\tvalidation_0-mae:77.52675\n",
      "[9300]\tvalidation_0-mae:77.49166\n",
      "[9400]\tvalidation_0-mae:77.44968\n",
      "[9500]\tvalidation_0-mae:77.40533\n",
      "[9600]\tvalidation_0-mae:77.36175\n",
      "[9700]\tvalidation_0-mae:77.31912\n",
      "[9800]\tvalidation_0-mae:77.28088\n",
      "[9900]\tvalidation_0-mae:77.24746\n",
      "[10000]\tvalidation_0-mae:77.21487\n",
      "[10100]\tvalidation_0-mae:77.18196\n",
      "[10200]\tvalidation_0-mae:77.14789\n",
      "[10300]\tvalidation_0-mae:77.11651\n",
      "[10400]\tvalidation_0-mae:77.07950\n",
      "[10500]\tvalidation_0-mae:77.05266\n",
      "[10600]\tvalidation_0-mae:77.02816\n",
      "[10700]\tvalidation_0-mae:77.00145\n",
      "[10800]\tvalidation_0-mae:76.97218\n",
      "[10900]\tvalidation_0-mae:76.94025\n",
      "[11000]\tvalidation_0-mae:76.90344\n",
      "[11100]\tvalidation_0-mae:76.86222\n",
      "[11200]\tvalidation_0-mae:76.82636\n",
      "[11300]\tvalidation_0-mae:76.80464\n",
      "[11400]\tvalidation_0-mae:76.78642\n",
      "[11500]\tvalidation_0-mae:76.76454\n",
      "[11600]\tvalidation_0-mae:76.73576\n",
      "[11700]\tvalidation_0-mae:76.70339\n",
      "[11800]\tvalidation_0-mae:76.66924\n",
      "[11900]\tvalidation_0-mae:76.63649\n",
      "[12000]\tvalidation_0-mae:76.60701\n",
      "[12100]\tvalidation_0-mae:76.58160\n",
      "[12200]\tvalidation_0-mae:76.55375\n",
      "[12300]\tvalidation_0-mae:76.52335\n",
      "[12400]\tvalidation_0-mae:76.49351\n",
      "[12500]\tvalidation_0-mae:76.46197\n",
      "[12600]\tvalidation_0-mae:76.42785\n",
      "[12700]\tvalidation_0-mae:76.39349\n",
      "[12800]\tvalidation_0-mae:76.36633\n",
      "[12900]\tvalidation_0-mae:76.34319\n",
      "[13000]\tvalidation_0-mae:76.32237\n",
      "[13100]\tvalidation_0-mae:76.30534\n",
      "[13200]\tvalidation_0-mae:76.28237\n",
      "[13300]\tvalidation_0-mae:76.25291\n",
      "[13400]\tvalidation_0-mae:76.22039\n",
      "[13500]\tvalidation_0-mae:76.19577\n",
      "[13600]\tvalidation_0-mae:76.16826\n",
      "[13700]\tvalidation_0-mae:76.14459\n",
      "[13800]\tvalidation_0-mae:76.11705\n",
      "[13900]\tvalidation_0-mae:76.08945\n",
      "[14000]\tvalidation_0-mae:76.06611\n",
      "[14100]\tvalidation_0-mae:76.03674\n",
      "[14200]\tvalidation_0-mae:76.01064\n",
      "[14300]\tvalidation_0-mae:75.98258\n",
      "[14400]\tvalidation_0-mae:75.95753\n",
      "[14500]\tvalidation_0-mae:75.93698\n",
      "[14600]\tvalidation_0-mae:75.91814\n",
      "[14700]\tvalidation_0-mae:75.90020\n",
      "[14800]\tvalidation_0-mae:75.87934\n",
      "[14900]\tvalidation_0-mae:75.86342\n",
      "[15000]\tvalidation_0-mae:75.84673\n",
      "[15100]\tvalidation_0-mae:75.83024\n",
      "[15200]\tvalidation_0-mae:75.81338\n",
      "[15300]\tvalidation_0-mae:75.80331\n",
      "[15400]\tvalidation_0-mae:75.78971\n",
      "[15500]\tvalidation_0-mae:75.77074\n",
      "[15600]\tvalidation_0-mae:75.75150\n",
      "[15700]\tvalidation_0-mae:75.73660\n",
      "[15800]\tvalidation_0-mae:75.71892\n",
      "[15900]\tvalidation_0-mae:75.70086\n",
      "[16000]\tvalidation_0-mae:75.69282\n",
      "[16100]\tvalidation_0-mae:75.68229\n",
      "[16200]\tvalidation_0-mae:75.67019\n",
      "[16300]\tvalidation_0-mae:75.66239\n",
      "[16400]\tvalidation_0-mae:75.65337\n",
      "[16500]\tvalidation_0-mae:75.64351\n",
      "[16600]\tvalidation_0-mae:75.63483\n",
      "[16700]\tvalidation_0-mae:75.62711\n",
      "[16800]\tvalidation_0-mae:75.61897\n",
      "[16900]\tvalidation_0-mae:75.60858\n",
      "[17000]\tvalidation_0-mae:75.60092\n",
      "[17100]\tvalidation_0-mae:75.58605\n",
      "[17200]\tvalidation_0-mae:75.57289\n",
      "[17300]\tvalidation_0-mae:75.56389\n",
      "[17400]\tvalidation_0-mae:75.55603\n",
      "[17500]\tvalidation_0-mae:75.54470\n",
      "[17600]\tvalidation_0-mae:75.53454\n",
      "[17700]\tvalidation_0-mae:75.52140\n",
      "[17800]\tvalidation_0-mae:75.50725\n",
      "[17900]\tvalidation_0-mae:75.49943\n",
      "[18000]\tvalidation_0-mae:75.49002\n",
      "[18100]\tvalidation_0-mae:75.48155\n",
      "[18200]\tvalidation_0-mae:75.47416\n",
      "[18300]\tvalidation_0-mae:75.46781\n",
      "[18400]\tvalidation_0-mae:75.45860\n",
      "[18500]\tvalidation_0-mae:75.44346\n",
      "[18600]\tvalidation_0-mae:75.43207\n",
      "[18700]\tvalidation_0-mae:75.41903\n",
      "[18800]\tvalidation_0-mae:75.40436\n",
      "[18900]\tvalidation_0-mae:75.39426\n",
      "[19000]\tvalidation_0-mae:75.38114\n",
      "[19100]\tvalidation_0-mae:75.36702\n",
      "[19200]\tvalidation_0-mae:75.35294\n",
      "[19300]\tvalidation_0-mae:75.34093\n",
      "[19400]\tvalidation_0-mae:75.33030\n",
      "[19500]\tvalidation_0-mae:75.31973\n",
      "[19600]\tvalidation_0-mae:75.30717\n",
      "[19700]\tvalidation_0-mae:75.29791\n",
      "[19800]\tvalidation_0-mae:75.28824\n",
      "[19900]\tvalidation_0-mae:75.28434\n",
      "[20000]\tvalidation_0-mae:75.27596\n",
      "[20100]\tvalidation_0-mae:75.26502\n",
      "[20200]\tvalidation_0-mae:75.25498\n",
      "[20300]\tvalidation_0-mae:75.24495\n",
      "[20400]\tvalidation_0-mae:75.23417\n",
      "[20500]\tvalidation_0-mae:75.22285\n",
      "[20600]\tvalidation_0-mae:75.21814\n",
      "[20700]\tvalidation_0-mae:75.21620\n",
      "[20800]\tvalidation_0-mae:75.20989\n",
      "[20900]\tvalidation_0-mae:75.20473\n",
      "[21000]\tvalidation_0-mae:75.19739\n",
      "[21078]\tvalidation_0-mae:75.19677\n",
      "Fold 147.62821828466906, Mean Absolute Error: 75.19632618375125\n",
      "[0]\tvalidation_0-mae:420.32178\n",
      "[100]\tvalidation_0-mae:383.35546\n",
      "[200]\tvalidation_0-mae:350.16621\n",
      "[300]\tvalidation_0-mae:320.39650\n",
      "[400]\tvalidation_0-mae:293.91548\n",
      "[500]\tvalidation_0-mae:270.47592\n",
      "[600]\tvalidation_0-mae:249.71267\n",
      "[700]\tvalidation_0-mae:231.32293\n",
      "[800]\tvalidation_0-mae:215.03266\n",
      "[900]\tvalidation_0-mae:200.49931\n",
      "[1000]\tvalidation_0-mae:187.59125\n",
      "[1100]\tvalidation_0-mae:176.14744\n",
      "[1200]\tvalidation_0-mae:165.95318\n",
      "[1300]\tvalidation_0-mae:156.88331\n",
      "[1400]\tvalidation_0-mae:148.78692\n",
      "[1500]\tvalidation_0-mae:141.55094\n",
      "[1600]\tvalidation_0-mae:135.08866\n",
      "[1700]\tvalidation_0-mae:129.34798\n",
      "[1800]\tvalidation_0-mae:124.21406\n",
      "[1900]\tvalidation_0-mae:119.62047\n",
      "[2000]\tvalidation_0-mae:115.51905\n",
      "[2100]\tvalidation_0-mae:111.87389\n",
      "[2200]\tvalidation_0-mae:108.57035\n",
      "[2300]\tvalidation_0-mae:105.59916\n",
      "[2400]\tvalidation_0-mae:102.93681\n",
      "[2500]\tvalidation_0-mae:100.53947\n",
      "[2600]\tvalidation_0-mae:98.40959\n",
      "[2700]\tvalidation_0-mae:96.49017\n",
      "[2800]\tvalidation_0-mae:94.73875\n",
      "[2900]\tvalidation_0-mae:93.14982\n",
      "[3000]\tvalidation_0-mae:91.77962\n",
      "[3100]\tvalidation_0-mae:90.53442\n",
      "[3200]\tvalidation_0-mae:89.42154\n",
      "[3300]\tvalidation_0-mae:88.41305\n",
      "[3400]\tvalidation_0-mae:87.48508\n",
      "[3500]\tvalidation_0-mae:86.64877\n",
      "[3600]\tvalidation_0-mae:85.91213\n",
      "[3700]\tvalidation_0-mae:85.19907\n",
      "[3800]\tvalidation_0-mae:84.56282\n",
      "[3900]\tvalidation_0-mae:84.01576\n",
      "[4000]\tvalidation_0-mae:83.49922\n",
      "[4100]\tvalidation_0-mae:83.05841\n",
      "[4200]\tvalidation_0-mae:82.66695\n",
      "[4300]\tvalidation_0-mae:82.31700\n",
      "[4400]\tvalidation_0-mae:81.97547\n",
      "[4500]\tvalidation_0-mae:81.65679\n",
      "[4600]\tvalidation_0-mae:81.37142\n",
      "[4700]\tvalidation_0-mae:81.09491\n",
      "[4800]\tvalidation_0-mae:80.85519\n",
      "[4900]\tvalidation_0-mae:80.63927\n",
      "[5000]\tvalidation_0-mae:80.45264\n",
      "[5100]\tvalidation_0-mae:80.26023\n",
      "[5200]\tvalidation_0-mae:80.07096\n",
      "[5300]\tvalidation_0-mae:79.89489\n",
      "[5400]\tvalidation_0-mae:79.75781\n",
      "[5500]\tvalidation_0-mae:79.63070\n",
      "[5600]\tvalidation_0-mae:79.46369\n",
      "[5700]\tvalidation_0-mae:79.32167\n",
      "[5800]\tvalidation_0-mae:79.18795\n",
      "[5900]\tvalidation_0-mae:79.07247\n",
      "[6000]\tvalidation_0-mae:78.99064\n",
      "[6100]\tvalidation_0-mae:78.90025\n",
      "[6200]\tvalidation_0-mae:78.78747\n",
      "[6300]\tvalidation_0-mae:78.65861\n",
      "[6400]\tvalidation_0-mae:78.54978\n",
      "[6500]\tvalidation_0-mae:78.46319\n",
      "[6600]\tvalidation_0-mae:78.38390\n",
      "[6700]\tvalidation_0-mae:78.30622\n",
      "[6800]\tvalidation_0-mae:78.23764\n",
      "[6900]\tvalidation_0-mae:78.17654\n",
      "[7000]\tvalidation_0-mae:78.10197\n",
      "[7100]\tvalidation_0-mae:78.02298\n",
      "[7200]\tvalidation_0-mae:77.95267\n",
      "[7300]\tvalidation_0-mae:77.88513\n",
      "[7400]\tvalidation_0-mae:77.81444\n",
      "[7500]\tvalidation_0-mae:77.74728\n",
      "[7600]\tvalidation_0-mae:77.66573\n",
      "[7700]\tvalidation_0-mae:77.58207\n",
      "[7800]\tvalidation_0-mae:77.51726\n",
      "[7900]\tvalidation_0-mae:77.46143\n",
      "[8000]\tvalidation_0-mae:77.40463\n",
      "[8100]\tvalidation_0-mae:77.35302\n",
      "[8200]\tvalidation_0-mae:77.30364\n",
      "[8300]\tvalidation_0-mae:77.24386\n",
      "[8400]\tvalidation_0-mae:77.19377\n",
      "[8500]\tvalidation_0-mae:77.14253\n",
      "[8600]\tvalidation_0-mae:77.07907\n",
      "[8700]\tvalidation_0-mae:77.03962\n",
      "[8800]\tvalidation_0-mae:77.00120\n",
      "[8900]\tvalidation_0-mae:76.95291\n",
      "[9000]\tvalidation_0-mae:76.90094\n",
      "[9100]\tvalidation_0-mae:76.85525\n",
      "[9200]\tvalidation_0-mae:76.81636\n",
      "[9300]\tvalidation_0-mae:76.77824\n",
      "[9400]\tvalidation_0-mae:76.71996\n",
      "[9500]\tvalidation_0-mae:76.67492\n",
      "[9600]\tvalidation_0-mae:76.63611\n",
      "[9700]\tvalidation_0-mae:76.59706\n",
      "[9800]\tvalidation_0-mae:76.55854\n",
      "[9900]\tvalidation_0-mae:76.51219\n",
      "[10000]\tvalidation_0-mae:76.47479\n",
      "[10100]\tvalidation_0-mae:76.44688\n",
      "[10200]\tvalidation_0-mae:76.40746\n",
      "[10300]\tvalidation_0-mae:76.38004\n",
      "[10400]\tvalidation_0-mae:76.34645\n",
      "[10500]\tvalidation_0-mae:76.31137\n",
      "[10600]\tvalidation_0-mae:76.27966\n",
      "[10700]\tvalidation_0-mae:76.26878\n",
      "[10800]\tvalidation_0-mae:76.25442\n",
      "[10900]\tvalidation_0-mae:76.24034\n",
      "[11000]\tvalidation_0-mae:76.21523\n",
      "[11100]\tvalidation_0-mae:76.18268\n",
      "[11200]\tvalidation_0-mae:76.15090\n",
      "[11300]\tvalidation_0-mae:76.11924\n",
      "[11400]\tvalidation_0-mae:76.09319\n",
      "[11500]\tvalidation_0-mae:76.06543\n",
      "[11600]\tvalidation_0-mae:76.04395\n",
      "[11700]\tvalidation_0-mae:76.03034\n",
      "[11800]\tvalidation_0-mae:76.01096\n",
      "[11900]\tvalidation_0-mae:75.98830\n",
      "[12000]\tvalidation_0-mae:75.95995\n",
      "[12100]\tvalidation_0-mae:75.93694\n",
      "[12200]\tvalidation_0-mae:75.90877\n",
      "[12300]\tvalidation_0-mae:75.87880\n",
      "[12400]\tvalidation_0-mae:75.85387\n",
      "[12500]\tvalidation_0-mae:75.83367\n",
      "[12600]\tvalidation_0-mae:75.80851\n",
      "[12700]\tvalidation_0-mae:75.78907\n",
      "[12800]\tvalidation_0-mae:75.77546\n",
      "[12900]\tvalidation_0-mae:75.75876\n",
      "[13000]\tvalidation_0-mae:75.73971\n",
      "[13100]\tvalidation_0-mae:75.72508\n",
      "[13200]\tvalidation_0-mae:75.70866\n",
      "[13300]\tvalidation_0-mae:75.69060\n",
      "[13400]\tvalidation_0-mae:75.67622\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Bruker\\OneDrive\\NTNU semester 05\\TDT4173 Maskinlæring\\ml_power_predictor\\stacking.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/stacking.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m# Create sample weights for testing data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/stacking.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m sample_weight_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(X_test[\u001b[39m'\u001b[39m\u001b[39mtime_since_prediction\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/stacking.ipynb#X11sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m reg\u001b[39m.\u001b[39;49mfit(X_train, y_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/stacking.ipynb#X11sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         eval_set\u001b[39m=\u001b[39;49m[(X_test, y_test)],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/stacking.ipynb#X11sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/stacking.ipynb#X11sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         sample_weight_eval_set\u001b[39m=\u001b[39;49m[sample_weight_test],  \u001b[39m# Here's how you pass the eval weights\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/stacking.ipynb#X11sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/stacking.ipynb#X11sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m xgboost_models\u001b[39m.\u001b[39mappend(reg)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/stacking.ipynb#X11sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m predictions \u001b[39m=\u001b[39m reg\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\OneDrive\\NTNU semester 05\\TDT4173 Maskinlæring\\ml_power_predictor\\venv\\lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\OneDrive\\NTNU semester 05\\TDT4173 Maskinlæring\\ml_power_predictor\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1086\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1075\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1077\u001b[0m (\n\u001b[0;32m   1078\u001b[0m     model,\n\u001b[0;32m   1079\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1084\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1085\u001b[0m )\n\u001b[1;32m-> 1086\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[0;32m   1087\u001b[0m     params,\n\u001b[0;32m   1088\u001b[0m     train_dmatrix,\n\u001b[0;32m   1089\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[0;32m   1090\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[0;32m   1091\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[0;32m   1092\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[0;32m   1093\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1094\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[0;32m   1095\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m   1096\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1097\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1098\u001b[0m )\n\u001b[0;32m   1100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1101\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\OneDrive\\NTNU semester 05\\TDT4173 Maskinlæring\\ml_power_predictor\\venv\\lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\OneDrive\\NTNU semester 05\\TDT4173 Maskinlæring\\ml_power_predictor\\venv\\lib\\site-packages\\xgboost\\training.py:182\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     bst\u001b[39m.\u001b[39mupdate(dtrain, i, obj)\n\u001b[1;32m--> 182\u001b[0m     \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39;49mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    185\u001b[0m bst \u001b[39m=\u001b[39m cb_container\u001b[39m.\u001b[39mafter_training(bst)\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\OneDrive\\NTNU semester 05\\TDT4173 Maskinlæring\\ml_power_predictor\\venv\\lib\\site-packages\\xgboost\\callback.py:238\u001b[0m, in \u001b[0;36mCallbackContainer.after_iteration\u001b[1;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39mfor\u001b[39;00m _, name \u001b[39min\u001b[39;00m evals:\n\u001b[0;32m    237\u001b[0m     \u001b[39massert\u001b[39;00m name\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDataset name should not contain `-`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 238\u001b[0m score: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49meval_set(evals, epoch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetric, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_output_margin)\n\u001b[0;32m    239\u001b[0m metric_score \u001b[39m=\u001b[39m _parse_eval_str(score)\n\u001b[0;32m    240\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_history(metric_score, epoch)\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\OneDrive\\NTNU semester 05\\TDT4173 Maskinlæring\\ml_power_predictor\\venv\\lib\\site-packages\\xgboost\\core.py:2125\u001b[0m, in \u001b[0;36mBooster.eval_set\u001b[1;34m(self, evals, iteration, feval, output_margin)\u001b[0m\n\u001b[0;32m   2122\u001b[0m evnames \u001b[39m=\u001b[39m c_array(ctypes\u001b[39m.\u001b[39mc_char_p, [c_str(d[\u001b[39m1\u001b[39m]) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m evals])\n\u001b[0;32m   2123\u001b[0m msg \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_char_p()\n\u001b[0;32m   2124\u001b[0m _check_call(\n\u001b[1;32m-> 2125\u001b[0m     _LIB\u001b[39m.\u001b[39;49mXGBoosterEvalOneIter(\n\u001b[0;32m   2126\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m   2127\u001b[0m         ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[0;32m   2128\u001b[0m         dmats,\n\u001b[0;32m   2129\u001b[0m         evnames,\n\u001b[0;32m   2130\u001b[0m         c_bst_ulong(\u001b[39mlen\u001b[39;49m(evals)),\n\u001b[0;32m   2131\u001b[0m         ctypes\u001b[39m.\u001b[39;49mbyref(msg),\n\u001b[0;32m   2132\u001b[0m     )\n\u001b[0;32m   2133\u001b[0m )\n\u001b[0;32m   2134\u001b[0m \u001b[39massert\u001b[39;00m msg\u001b[39m.\u001b[39mvalue \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2135\u001b[0m res \u001b[39m=\u001b[39m msg\u001b[39m.\u001b[39mvalue\u001b[39m.\u001b[39mdecode()  \u001b[39m# pylint: disable=no-member\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# K-fold cross validation\n",
    "if not load_xgb:\n",
    "    num_folds = 5\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    total_mae = 0\n",
    "\n",
    "    xgboost_models = []\n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(base_x_train):\n",
    "        reg = xgb.XGBRegressor(n_estimators=10000000,\n",
    "                        early_stopping_rounds=50,\n",
    "                        learning_rate= 0.001,\n",
    "                        objective=\"reg:linear\",\n",
    "                        eval_metric=\"mae\",\n",
    "                        sub_sample = 0.9,\n",
    "                        colsample_bytree = 1.0,\n",
    "                        gamma = 0,\n",
    "                        min_child_weight=0,\n",
    "                        max_depth=9)\n",
    "\n",
    "        X_train, X_test = base_x_train.iloc[train_index], base_x_train.iloc[test_index]\n",
    "        y_train, y_test = base_y_train.iloc[train_index], base_y_train.iloc[test_index]\n",
    "        \n",
    "        # Create sample weights for training data\n",
    "        sample_weight_train = np.where(X_train['time_since_prediction'] == 0, 1, 2)\n",
    "        # Create sample weights for testing data\n",
    "        sample_weight_test = np.where(X_test['time_since_prediction'] == 0, 1, 2)\n",
    "        \n",
    "        reg.fit(X_train, y_train,\n",
    "                eval_set=[(X_test, y_test)],\n",
    "                sample_weight=sample_weight_train,\n",
    "                sample_weight_eval_set=[sample_weight_test],  # Here's how you pass the eval weights\n",
    "                verbose=100)\n",
    "        \n",
    "        xgboost_models.append(reg)\n",
    "        predictions = reg.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, predictions, sample_weight=sample_weight_test)\n",
    "        total_mae += mae\n",
    "        \n",
    "        print(f\"Fold {total_mae}, Mean Absolute Error: {mae}\")\n",
    "\n",
    "    average_mse = total_mae / num_folds\n",
    "    print(f\"Average Mean Squared Error: {average_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not load_cat:\n",
    "    num_folds = 5\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    total_mae = 0\n",
    "    catboost_models = []\n",
    "\n",
    "    def compute_sample_weight(data):\n",
    "        # Assign weight of 2 for estimated data and 1 for observed data\n",
    "        return np.where(data['time_since_prediction'] > 0, 2, 1)\n",
    "\n",
    "    for train_index, test_index in kf.split(base_x_train):\n",
    "        reg = CatBoostRegressor(\n",
    "            iterations=10000000,\n",
    "            depth=8,\n",
    "            learning_rate=0.001,\n",
    "            loss_function='MAE',\n",
    "            verbose=200\n",
    "        )\n",
    "        \n",
    "        X_train, X_test = base_x_train.iloc[train_index], base_x_train.iloc[test_index]\n",
    "        y_train, y_test = base_y_train.iloc[train_index], base_y_train.iloc[test_index]\n",
    "        \n",
    "        # Compute sample weights for training and testing data\n",
    "        train_weight = compute_sample_weight(X_train)\n",
    "        test_weight = compute_sample_weight(X_test)\n",
    "\n",
    "        # Create Pool for training and testing\n",
    "        train_pool = Pool(data=X_train, label=y_train, weight=train_weight)\n",
    "        test_pool = Pool(data=X_test, label=y_test, weight=test_weight)\n",
    "\n",
    "        # Fit the model using the sample weights\n",
    "        reg.fit(train_pool, eval_set=test_pool, early_stopping_rounds=100)\n",
    "\n",
    "        catboost_models.append(reg)\n",
    "        predictions = reg.predict(test_pool)\n",
    "        \n",
    "        # Compute weighted MAE manually\n",
    "        weighted_mae = np.sum(test_weight * np.abs(y_test - predictions)) / np.sum(test_weight)\n",
    "        total_mae += weighted_mae\n",
    "        \n",
    "        print(f\"Fold {len(catboost_models)}, Weighted Mean Absolute Error: {weighted_mae}\")\n",
    "\n",
    "    average_mae = total_mae / num_folds\n",
    "    print(f\"Average Weighted Mean Absolute Error: {average_mae}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not load_lgb:\n",
    "    num_folds = 5\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    total_mae = 0\n",
    "\n",
    "    lightgbm_models = []\n",
    "\n",
    "    params = {\n",
    "        'objective': 'regression_l1',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'max_depth': 8,\n",
    "        'metric': 'mae',\n",
    "        'num_leaves': 256,\n",
    "        'learning_rate': 0.001,\n",
    "        'feature_fraction': 1.0,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 5,\n",
    "        'min_data_in_leaf': 20,\n",
    "        'early_stopping_rounds': 100,\n",
    "        'verbosity': 100,  # 0 for verbose, -1 for silent\n",
    "    }\n",
    "\n",
    "    num_round = 10000000 # number of training iterations\n",
    "\n",
    "    # Ensure column names are compatible with LightGBM\n",
    "    base_x_train.columns = base_x_train.columns.str.replace('[^A-Za-z0-9_]', '_', regex=True)\n",
    "\n",
    "    for train_index, test_index in kf.split(base_x_train):\n",
    "        X_train, X_test = base_x_train.iloc[train_index], base_x_train.iloc[test_index]\n",
    "        y_train, y_test = base_y_train.iloc[train_index], base_y_train.iloc[test_index]\n",
    "\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        valid_data = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "        reg = lgb.train(params, train_data, num_round, valid_sets=[valid_data])\n",
    "        lightgbm_models.append(reg)\n",
    "        predictions = reg.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        total_mae += mae\n",
    "        \n",
    "        print(f\"Fold {total_mae}, Mean Absolute Error: {mae}\")\n",
    "\n",
    "    average_mse = total_mae / num_folds\n",
    "    print(f\"Average Mean Squared Error: {average_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not load_rf:\n",
    "    # K-fold cross validation\n",
    "    num_folds = 5\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    total_mae = 0\n",
    "\n",
    "    random_forest_models = []\n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(base_x_train):\n",
    "\n",
    "        rf_model = RandomForestRegressor(n_estimators=1, random_state=42)\n",
    "\n",
    "        X_train, X_test = base_x_train.iloc[train_index], base_x_train.iloc[test_index]\n",
    "        y_train, y_test = base_y_train.iloc[train_index], base_y_train.iloc[test_index]\n",
    "\n",
    "        # Train the Random Forest model on the cleaned training data\n",
    "        \n",
    "        reg.fit(X_train, y_train,\n",
    "                eval_set=[(X_val_est_combined, y_val_est_combined)],\n",
    "                verbose=100)\n",
    "        \n",
    "        random_forest_models.append(reg)\n",
    "        predictions = reg.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        total_mae += mae\n",
    "        \n",
    "        print(f\"Fold {total_mae}, Mean Absolute Error: {mae}\")\n",
    "\n",
    "    average_mse = total_mae / num_folds\n",
    "    print(f\"Average Mean Squared Error: {average_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the models and save the newly trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what models should be loaded\n",
    "# Load XGBoost models\n",
    "if load_xgb:\n",
    "    with open(\"xgboost_models.pkl\", \"rb\") as file:\n",
    "        xgboost_models = pickle.load(file)\n",
    "        print(f\"[LOADED] xgboost_models {len(xgboost_models)} has successfully been loaded\")\n",
    "else:\n",
    "    with open(\"xgboost_models.pkl\", \"wb\") as file:\n",
    "        pickle.dump(xgboost_models, file)\n",
    "        print(f\"[SAVED] xgboost_models has successfully been saved.\")\n",
    "\n",
    "# Load CatBoost models\n",
    "if load_cat:\n",
    "    with open(\"catboost_models.pkl\", \"rb\") as file:\n",
    "        catboost_models = pickle.load(file)\n",
    "        print(f\"[LOADED] catboost_models {len(catboost_models)} has successfully been loaded\")\n",
    "else:\n",
    "    with open(\"catboost_models.pkl\", \"wb\") as file:\n",
    "        pickle.dump(catboost_models, file)\n",
    "        print(f\"[SAVED] catboost_models has successfully been saved.\")\n",
    "\n",
    "# Load lightGBM models\n",
    "if load_lgb:\n",
    "    with open(\"lightgbm_models.pkl\", \"rb\") as file:\n",
    "        lightgbm_models = pickle.load(file)\n",
    "        print(f\"[LOADED] lightgbm_models {len(lightgbm_models)} has successfully been loaded\")\n",
    "else:\n",
    "    with open(\"lightgbm_models.pkl\", \"wb\") as file:\n",
    "        pickle.dump(lightgbm_models, file)\n",
    "        print(f\"[SAVED] lightgbm_models has successfully been saved.\")\n",
    "\n",
    "# Load random forest models\n",
    "if load_rf:\n",
    "    with open(\"random_forest_models.pkl\", \"rb\") as file:\n",
    "        random_forest_models = pickle.load(file)\n",
    "        print(f\"[LOADED] random_forest_models {len(random_forest_models)} has successfully been loaded\")\n",
    "else:\n",
    "    with open(\"random_forest_models.pkl\", \"wb\") as file:\n",
    "        pickle.dump(random_forest_models, file)\n",
    "        print(f\"[SAVED] random_forest_models has successfully been saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_prediction(x_values :pd.DataFrame, models) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function for predicting on multiple models and averaging the results\n",
    "    \"\"\"\n",
    "    results = models[0].predict(x_values)\n",
    "    for model in models[1:]:\n",
    "        model: xgb.XGBRegressor\n",
    "        prediction = model.predict(x_values)\n",
    "        results += prediction\n",
    "    \n",
    "    results = results / len(models)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train meta learner model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset for meta learner model by using models to predict on the meta layer training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the base layer on meta_x_train\n",
    "base_xgboost_predictions  = average_prediction(meta_x_train, xgboost_models)\n",
    "base_catboost_predictions = average_prediction(meta_x_train, catboost_models)\n",
    "base_lightgbm_predictions = average_prediction(meta_x_train, lightgbm_models)\n",
    "base_random_forest_predictions = average_prediction(meta_x_train, random_forest_models)\n",
    "\n",
    "# Add the predictions to the meta_x_train\n",
    "meta_base_x_train = pd.DataFrame()\n",
    "meta_base_x_train[\"xgboost\"] = base_xgboost_predictions\n",
    "meta_base_x_train[\"catboost\"] = base_catboost_predictions\n",
    "meta_base_x_train[\"lightgbm\"] = base_lightgbm_predictions\n",
    "meta_base_x_train[\"random_forest\"] = base_random_forest_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train meta learner model on new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-fold cross validation\n",
    "\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "total_mae = 0\n",
    "\n",
    "meta_models = []\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(meta_base_x_train):\n",
    "\n",
    "    reg = xgb.XGBRegressor(n_estimators=100000,\n",
    "                       early_stopping_rounds=50,\n",
    "                       learning_rate= 0.01,\n",
    "                       objective=\"reg:linear\",\n",
    "                       eval_metric=\"mae\",\n",
    "                       sub_sample = 0.9,\n",
    "                       colsample_bytree = 0.8,\n",
    "                       gamma = 0,\n",
    "                       alpha = 0.001,\n",
    "                       min_child_weight=0,\n",
    "                       max_depth=4)\n",
    "\n",
    "    X_train, X_test = meta_base_x_train.iloc[train_index], meta_base_x_train.iloc[test_index]\n",
    "    y_train, y_test = meta_y_train.iloc[train_index], meta_y_train.iloc[test_index]\n",
    "\n",
    "    reg.fit(X_train, y_train,\n",
    "            eval_set=[(X_test, y_test)],\n",
    "            verbose=100)\n",
    "    \n",
    "    meta_models.append(reg)\n",
    "    predictions = reg.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    total_mae += mae\n",
    "    \n",
    "    print(f\"Fold {total_mae}, Mean Absolute Error: {mae}\")\n",
    "\n",
    "average_mse = total_mae / num_folds\n",
    "print(f\"Average Mean Squared Error: {average_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame(data=reg.feature_importances_,\n",
    "             index=reg.feature_names_in_,\n",
    "             columns=[\"importance\"])\n",
    "\n",
    "plt.figure(figsize=(100,100))\n",
    "plt.tight_layout()\n",
    "fi.sort_values(\"importance\").plot(kind=\"barh\", title=\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val_obs_combined = average_prediction(X_val_obs_combined, meta_models)\n",
    "y_pred_val_est_combined = average_prediction(X_val_est_combined, meta_models)\n",
    "\n",
    "# Evaluate the model's performance using Mean Absolute Error (MAE) on the combined validation observed data\n",
    "mae_obs_combined = mean_absolute_error(y_val_obs_combined, y_pred_val_obs_combined)\n",
    "mae_est_combined = mean_absolute_error(y_val_est_combined, y_pred_val_est_combined)\n",
    "print('MAE on validation observed data: ', mae_obs_combined)\n",
    "print('MAE on validation estimated data: ', mae_est_combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions for meta learner model test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the cleaned validation set\n",
    "from src.features.preprocess_data import get_final_prediction\n",
    "\n",
    "y_predictions = average_prediction(x_test_whole, meta_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.saving import save_predictions\n",
    "\n",
    "\n",
    "save_predictions(y_predictions, 'stacking with possible data leakage')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
