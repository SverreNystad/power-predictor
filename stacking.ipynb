{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking of models into two layers\n",
    "1. First layer: train models on the whole training set\n",
    "2. Second layer: train a model on the first layer's predictions and the rest of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\bruker\\onedrive\\ntnu semester 05\\tdt4173 maskinlæring\\ml_power_predictor\\venv\\lib\\site-packages (2.0.1)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\bruker\\onedrive\\ntnu semester 05\\tdt4173 maskinlæring\\ml_power_predictor\\venv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\bruker\\onedrive\\ntnu semester 05\\tdt4173 maskinlæring\\ml_power_predictor\\venv\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\bruker\\onedrive\\ntnu semester 05\\tdt4173 maskinlæring\\ml_power_predictor\\venv\\lib\\site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\bruker\\onedrive\\ntnu semester 05\\tdt4173 maskinlæring\\ml_power_predictor\\venv\\lib\\site-packages (from xgboost) (1.9.3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "\n",
    "from src.features.preprocess_data import get_preprocessed_test_data, fetch_preprocessed_data\n",
    "pd.set_option('display.max_columns', 200)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_xgb: bool = False\n",
    "load_lgb: bool = False\n",
    "load_cat: bool = False\n",
    "load_rf: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absolute_humidity_2m:gm3</th>\n",
       "      <th>air_density_2m:kgm3</th>\n",
       "      <th>clear_sky_energy_1h:J</th>\n",
       "      <th>clear_sky_rad:W</th>\n",
       "      <th>cloud_base_agl:m</th>\n",
       "      <th>dew_or_rime:idx</th>\n",
       "      <th>dew_point_2m:K</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>diffuse_rad_1h:J</th>\n",
       "      <th>direct_rad:W</th>\n",
       "      <th>direct_rad_1h:J</th>\n",
       "      <th>effective_cloud_cover:p</th>\n",
       "      <th>is_day:idx</th>\n",
       "      <th>is_in_shadow:idx</th>\n",
       "      <th>precip_5min:mm</th>\n",
       "      <th>precip_type_5min:idx</th>\n",
       "      <th>pressure_50m:hPa</th>\n",
       "      <th>prob_rime:p</th>\n",
       "      <th>rain_water:kgm2</th>\n",
       "      <th>relative_humidity_1000hPa:p</th>\n",
       "      <th>sun_azimuth:d</th>\n",
       "      <th>super_cooled_liquid_water:kgm2</th>\n",
       "      <th>t_1000hPa:K</th>\n",
       "      <th>total_cloud_cover:p</th>\n",
       "      <th>visibility:m</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>wind_speed_u_10m:ms</th>\n",
       "      <th>wind_speed_v_10m:ms</th>\n",
       "      <th>wind_speed_w_1000hPa:ms</th>\n",
       "      <th>location_a</th>\n",
       "      <th>location_b</th>\n",
       "      <th>location_c</th>\n",
       "      <th>sin_day_of_year</th>\n",
       "      <th>cos_day_of_year</th>\n",
       "      <th>sin_hour</th>\n",
       "      <th>cos_hour</th>\n",
       "      <th>sun_product</th>\n",
       "      <th>modified_solar_elevation</th>\n",
       "      <th>effective_radiation</th>\n",
       "      <th>time_since_prediction</th>\n",
       "      <th>cloud_ratio</th>\n",
       "      <th>cloud_cover_over_30%</th>\n",
       "      <th>sun_addition</th>\n",
       "      <th>is_freezing</th>\n",
       "      <th>is_snow</th>\n",
       "      <th>is_rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.450</td>\n",
       "      <td>1.25900</td>\n",
       "      <td>902436.125</td>\n",
       "      <td>194.449997</td>\n",
       "      <td>2426.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.625000</td>\n",
       "      <td>88.175003</td>\n",
       "      <td>348536.406250</td>\n",
       "      <td>70.375000</td>\n",
       "      <td>271995.531250</td>\n",
       "      <td>62.900002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1018.400024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.174999</td>\n",
       "      <td>242.404755</td>\n",
       "      <td>0.000</td>\n",
       "      <td>281.774994</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>43816.324219</td>\n",
       "      <td>0.725</td>\n",
       "      <td>-0.250</td>\n",
       "      <td>-0.700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.984306</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>6205.315918</td>\n",
       "      <td>0.242142</td>\n",
       "      <td>0.301401</td>\n",
       "      <td>0</td>\n",
       "      <td>0.629000</td>\n",
       "      <td>1</td>\n",
       "      <td>158.550003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.925</td>\n",
       "      <td>1.27550</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>971.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>273.600006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.425003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1010.150024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.949997</td>\n",
       "      <td>309.972748</td>\n",
       "      <td>0.100</td>\n",
       "      <td>276.625000</td>\n",
       "      <td>99.425003</td>\n",
       "      <td>33486.976562</td>\n",
       "      <td>2.825</td>\n",
       "      <td>1.125</td>\n",
       "      <td>2.600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.702148</td>\n",
       "      <td>0.712031</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.975</td>\n",
       "      <td>1.20350</td>\n",
       "      <td>797556.125</td>\n",
       "      <td>175.350006</td>\n",
       "      <td>3255.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.075012</td>\n",
       "      <td>50.824997</td>\n",
       "      <td>206314.859375</td>\n",
       "      <td>120.599998</td>\n",
       "      <td>537617.250000</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>995.099976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.700001</td>\n",
       "      <td>230.077255</td>\n",
       "      <td>0.000</td>\n",
       "      <td>289.299988</td>\n",
       "      <td>6.050000</td>\n",
       "      <td>57556.351562</td>\n",
       "      <td>4.925</td>\n",
       "      <td>-0.275</td>\n",
       "      <td>4.925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.999371</td>\n",
       "      <td>0.035473</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>6129.494629</td>\n",
       "      <td>0.226685</td>\n",
       "      <td>0.674081</td>\n",
       "      <td>0</td>\n",
       "      <td>0.867769</td>\n",
       "      <td>0</td>\n",
       "      <td>171.424988</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.675</td>\n",
       "      <td>1.23925</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2067.925049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>272.924988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.949997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>981.574951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.949997</td>\n",
       "      <td>252.160492</td>\n",
       "      <td>0.000</td>\n",
       "      <td>279.774994</td>\n",
       "      <td>98.974998</td>\n",
       "      <td>45661.750000</td>\n",
       "      <td>3.800</td>\n",
       "      <td>1.100</td>\n",
       "      <td>3.625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.638384</td>\n",
       "      <td>0.769718</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.929022</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.450</td>\n",
       "      <td>1.22500</td>\n",
       "      <td>2240127.750</td>\n",
       "      <td>591.500000</td>\n",
       "      <td>115.849998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>283.324982</td>\n",
       "      <td>138.100006</td>\n",
       "      <td>454697.093750</td>\n",
       "      <td>66.150002</td>\n",
       "      <td>185963.796875</td>\n",
       "      <td>96.349998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1001.400024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.900002</td>\n",
       "      <td>216.283997</td>\n",
       "      <td>0.275</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>98.199997</td>\n",
       "      <td>5958.750000</td>\n",
       "      <td>4.525</td>\n",
       "      <td>4.100</td>\n",
       "      <td>-1.950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.739392</td>\n",
       "      <td>-0.673275</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>9135.315430</td>\n",
       "      <td>0.571108</td>\n",
       "      <td>0.083015</td>\n",
       "      <td>0</td>\n",
       "      <td>0.981161</td>\n",
       "      <td>1</td>\n",
       "      <td>204.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   absolute_humidity_2m:gm3  air_density_2m:kgm3  clear_sky_energy_1h:J  \\\n",
       "0                     6.450              1.25900             902436.125   \n",
       "1                     4.925              1.27550                  0.000   \n",
       "2                     6.975              1.20350             797556.125   \n",
       "3                     4.675              1.23925                  0.000   \n",
       "4                     9.450              1.22500            2240127.750   \n",
       "\n",
       "   clear_sky_rad:W  cloud_base_agl:m  dew_or_rime:idx  dew_point_2m:K  \\\n",
       "0       194.449997       2426.750000              0.0      277.625000   \n",
       "1         0.000000        971.250000              0.0      273.600006   \n",
       "2       175.350006       3255.375000              0.0      279.075012   \n",
       "3         0.000000       2067.925049              0.0      272.924988   \n",
       "4       591.500000        115.849998              0.0      283.324982   \n",
       "\n",
       "   diffuse_rad:W  diffuse_rad_1h:J  direct_rad:W  direct_rad_1h:J  \\\n",
       "0      88.175003     348536.406250     70.375000    271995.531250   \n",
       "1       0.000000          0.000000      0.000000         0.000000   \n",
       "2      50.824997     206314.859375    120.599998    537617.250000   \n",
       "3       0.000000          0.000000      0.000000         0.000000   \n",
       "4     138.100006     454697.093750     66.150002    185963.796875   \n",
       "\n",
       "   effective_cloud_cover:p  is_day:idx  is_in_shadow:idx  precip_5min:mm  \\\n",
       "0                62.900002         1.0               0.0          0.0000   \n",
       "1                99.425003         0.0               1.0          0.0000   \n",
       "2                 5.250000         1.0               0.0          0.0000   \n",
       "3                91.949997         0.0               1.0          0.0000   \n",
       "4                96.349998         1.0               0.0          0.0125   \n",
       "\n",
       "   precip_type_5min:idx  pressure_50m:hPa  prob_rime:p  rain_water:kgm2  \\\n",
       "0                  0.00       1018.400024          0.0              0.0   \n",
       "1                  0.00       1010.150024          0.0              0.0   \n",
       "2                  0.00        995.099976          0.0              0.0   \n",
       "3                  0.00        981.574951          0.0              0.0   \n",
       "4                  0.25       1001.400024          0.0              0.0   \n",
       "\n",
       "   relative_humidity_1000hPa:p  sun_azimuth:d  super_cooled_liquid_water:kgm2  \\\n",
       "0                    58.174999     242.404755                           0.000   \n",
       "1                    73.949997     309.972748                           0.100   \n",
       "2                    45.700001     230.077255                           0.000   \n",
       "3                    65.949997     252.160492                           0.000   \n",
       "4                    88.900002     216.283997                           0.275   \n",
       "\n",
       "   t_1000hPa:K  total_cloud_cover:p  visibility:m  wind_speed_10m:ms  \\\n",
       "0   281.774994           100.000000  43816.324219              0.725   \n",
       "1   276.625000            99.425003  33486.976562              2.825   \n",
       "2   289.299988             6.050000  57556.351562              4.925   \n",
       "3   279.774994            98.974998  45661.750000              3.800   \n",
       "4   284.000000            98.199997   5958.750000              4.525   \n",
       "\n",
       "   wind_speed_u_10m:ms  wind_speed_v_10m:ms  wind_speed_w_1000hPa:ms  \\\n",
       "0               -0.250               -0.700                      0.0   \n",
       "1                1.125                2.600                      0.0   \n",
       "2               -0.275                4.925                      0.0   \n",
       "3                1.100                3.625                      0.0   \n",
       "4                4.100               -1.950                      0.0   \n",
       "\n",
       "   location_a  location_b  location_c  sin_day_of_year  cos_day_of_year  \\\n",
       "0           1           0           0         0.984306         0.176471   \n",
       "1           1           0           0        -0.702148         0.712031   \n",
       "2           0           1           0        -0.999371         0.035473   \n",
       "3           1           0           0        -0.638384         0.769718   \n",
       "4           0           0           1        -0.739392        -0.673275   \n",
       "\n",
       "   sin_hour  cos_hour  sun_product  modified_solar_elevation  \\\n",
       "0 -0.707107 -0.707107  6205.315918                  0.242142   \n",
       "1 -0.866025  0.500000     0.000000                  0.000000   \n",
       "2 -0.500000 -0.866025  6129.494629                  0.226685   \n",
       "3 -0.866025 -0.500000     0.000000                  0.000000   \n",
       "4 -0.258819 -0.965926  9135.315430                  0.571108   \n",
       "\n",
       "   effective_radiation  time_since_prediction  cloud_ratio  \\\n",
       "0             0.301401                      0     0.629000   \n",
       "1             0.000000                      0     1.000000   \n",
       "2             0.674081                      0     0.867769   \n",
       "3             0.000000                      0     0.929022   \n",
       "4             0.083015                      0     0.981161   \n",
       "\n",
       "   cloud_cover_over_30%  sun_addition  is_freezing  is_snow  is_rain  \n",
       "0                     1    158.550003            0        0        0  \n",
       "1                     1      0.000000            0        0        0  \n",
       "2                     0    171.424988            0        0        0  \n",
       "3                     1      0.000000            0        0        0  \n",
       "4                     1    204.250000            0        0        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_obs_combined, X_val_obs_combined, y_train_obs_combined, y_val_obs_combined, X_train_est_combined, X_val_est_combined, y_train_est_combined, y_val_est_combined = fetch_preprocessed_data()\n",
    "x_test_whole = get_preprocessed_test_data()\n",
    "\n",
    "x_whole = pd.concat([X_train_obs_combined, X_val_obs_combined])\n",
    "y_whole = pd.concat([y_train_obs_combined, y_val_obs_combined])\n",
    "x_whole.reset_index(drop=True, inplace=True)\n",
    "y_whole.reset_index(drop=True, inplace=True)\n",
    "\n",
    "x_whole.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split for the base layer and meta layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['absolute_humidity_2m:gm3', 'air_density_2m:kgm3',\n",
       "       'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'cloud_base_agl:m',\n",
       "       'dew_or_rime:idx', 'dew_point_2m:K', 'diffuse_rad:W',\n",
       "       'diffuse_rad_1h:J', 'direct_rad:W', 'direct_rad_1h:J',\n",
       "       'effective_cloud_cover:p', 'is_day:idx', 'is_in_shadow:idx',\n",
       "       'precip_5min:mm', 'precip_type_5min:idx', 'pressure_50m:hPa',\n",
       "       'prob_rime:p', 'rain_water:kgm2', 'relative_humidity_1000hPa:p',\n",
       "       'sun_azimuth:d', 'super_cooled_liquid_water:kgm2', 't_1000hPa:K',\n",
       "       'total_cloud_cover:p', 'visibility:m', 'wind_speed_10m:ms',\n",
       "       'wind_speed_u_10m:ms', 'wind_speed_v_10m:ms', 'wind_speed_w_1000hPa:ms',\n",
       "       'location_a', 'location_b', 'location_c', 'sin_day_of_year',\n",
       "       'cos_day_of_year', 'sin_hour', 'cos_hour', 'sun_product',\n",
       "       'modified_solar_elevation', 'effective_radiation',\n",
       "       'time_since_prediction', 'cloud_ratio', 'cloud_cover_over_30%',\n",
       "       'sun_addition', 'is_freezing', 'is_snow', 'is_rain'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The base layer gets 80% of the data\n",
    "# The meta layer gets 20% of the data\n",
    "base_to_meta_layer_split = 0.8\n",
    "\n",
    "base_x_train = x_whole.sample(frac=base_to_meta_layer_split)\n",
    "meta_x_train = x_whole.sample(frac=1-base_to_meta_layer_split)\n",
    "\n",
    "# Get the corresponding y values\n",
    "base_y_train = y_whole[base_x_train.index]\n",
    "meta_y_train = y_whole[meta_x_train.index]\n",
    "base_x_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Base level models\n",
    "It is important to use a variety of models to get a diverse set of predictions.\n",
    "\n",
    "I want a model to check if there is a linear relationship between the location features and the target. I will use a linear regression model for this.\n",
    "I want to check if the different irradiation values are correlated with the target. I will use xgboost for this.\n",
    "I want to check if the different temperature values are correlated with the target. I will use \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mae:457.34673\n",
      "[100]\tvalidation_0-mae:416.63755\n",
      "[200]\tvalidation_0-mae:380.11439\n",
      "[300]\tvalidation_0-mae:347.36942\n",
      "[400]\tvalidation_0-mae:318.34896\n",
      "[500]\tvalidation_0-mae:292.76028\n",
      "[600]\tvalidation_0-mae:270.15887\n",
      "[700]\tvalidation_0-mae:250.14122\n",
      "[800]\tvalidation_0-mae:232.39713\n",
      "[900]\tvalidation_0-mae:216.63806\n",
      "[1000]\tvalidation_0-mae:202.63497\n",
      "[1100]\tvalidation_0-mae:190.22722\n",
      "[1200]\tvalidation_0-mae:179.29625\n",
      "[1300]\tvalidation_0-mae:169.63634\n",
      "[1400]\tvalidation_0-mae:161.10339\n",
      "[1500]\tvalidation_0-mae:153.56411\n",
      "[1600]\tvalidation_0-mae:146.86240\n",
      "[1700]\tvalidation_0-mae:140.93383\n",
      "[1800]\tvalidation_0-mae:135.65059\n",
      "[1900]\tvalidation_0-mae:130.93691\n",
      "[2000]\tvalidation_0-mae:126.66437\n",
      "[2100]\tvalidation_0-mae:122.82734\n",
      "[2200]\tvalidation_0-mae:119.36699\n",
      "[2300]\tvalidation_0-mae:116.23622\n",
      "[2400]\tvalidation_0-mae:113.45280\n",
      "[2500]\tvalidation_0-mae:111.00579\n",
      "[2600]\tvalidation_0-mae:108.78737\n",
      "[2700]\tvalidation_0-mae:106.79485\n",
      "[2800]\tvalidation_0-mae:104.95425\n",
      "[2900]\tvalidation_0-mae:103.41284\n",
      "[3000]\tvalidation_0-mae:102.00687\n",
      "[3100]\tvalidation_0-mae:100.75586\n",
      "[3200]\tvalidation_0-mae:99.56439\n",
      "[3300]\tvalidation_0-mae:98.41026\n",
      "[3400]\tvalidation_0-mae:97.38922\n",
      "[3500]\tvalidation_0-mae:96.51747\n",
      "[3600]\tvalidation_0-mae:95.72604\n",
      "[3700]\tvalidation_0-mae:95.01167\n",
      "[3800]\tvalidation_0-mae:94.36666\n",
      "[3900]\tvalidation_0-mae:93.81904\n",
      "[4000]\tvalidation_0-mae:93.38026\n",
      "[4100]\tvalidation_0-mae:92.94577\n",
      "[4200]\tvalidation_0-mae:92.57288\n",
      "[4300]\tvalidation_0-mae:92.20443\n",
      "[4400]\tvalidation_0-mae:91.85243\n",
      "[4500]\tvalidation_0-mae:91.55671\n",
      "[4600]\tvalidation_0-mae:91.29845\n",
      "[4700]\tvalidation_0-mae:91.04091\n",
      "[4800]\tvalidation_0-mae:90.83174\n",
      "[4900]\tvalidation_0-mae:90.66362\n",
      "[5000]\tvalidation_0-mae:90.50078\n",
      "[5100]\tvalidation_0-mae:90.34470\n",
      "[5200]\tvalidation_0-mae:90.19721\n",
      "[5300]\tvalidation_0-mae:90.04710\n",
      "[5400]\tvalidation_0-mae:89.91447\n",
      "[5500]\tvalidation_0-mae:89.73694\n",
      "[5600]\tvalidation_0-mae:89.60349\n",
      "[5700]\tvalidation_0-mae:89.48382\n",
      "[5800]\tvalidation_0-mae:89.36144\n",
      "[5900]\tvalidation_0-mae:89.26607\n",
      "[6000]\tvalidation_0-mae:89.18314\n",
      "[6100]\tvalidation_0-mae:89.06451\n",
      "[6200]\tvalidation_0-mae:88.95799\n",
      "[6300]\tvalidation_0-mae:88.85668\n",
      "[6400]\tvalidation_0-mae:88.76924\n",
      "[6500]\tvalidation_0-mae:88.68434\n",
      "[6600]\tvalidation_0-mae:88.61983\n",
      "[6700]\tvalidation_0-mae:88.55703\n",
      "[6800]\tvalidation_0-mae:88.48587\n",
      "[6900]\tvalidation_0-mae:88.42206\n",
      "[7000]\tvalidation_0-mae:88.35437\n",
      "[7100]\tvalidation_0-mae:88.26216\n",
      "[7200]\tvalidation_0-mae:88.16482\n",
      "[7300]\tvalidation_0-mae:88.09092\n",
      "[7400]\tvalidation_0-mae:88.02506\n",
      "[7500]\tvalidation_0-mae:87.94866\n",
      "[7600]\tvalidation_0-mae:87.87211\n",
      "[7700]\tvalidation_0-mae:87.79723\n",
      "[7800]\tvalidation_0-mae:87.73953\n",
      "[7900]\tvalidation_0-mae:87.69113\n",
      "[8000]\tvalidation_0-mae:87.63264\n",
      "[8100]\tvalidation_0-mae:87.57426\n",
      "[8200]\tvalidation_0-mae:87.53440\n",
      "[8300]\tvalidation_0-mae:87.49371\n",
      "[8400]\tvalidation_0-mae:87.46039\n",
      "[8500]\tvalidation_0-mae:87.43232\n",
      "[8600]\tvalidation_0-mae:87.39217\n",
      "[8700]\tvalidation_0-mae:87.35763\n",
      "[8800]\tvalidation_0-mae:87.32366\n",
      "[8900]\tvalidation_0-mae:87.28582\n",
      "[9000]\tvalidation_0-mae:87.23834\n",
      "[9100]\tvalidation_0-mae:87.19096\n",
      "[9200]\tvalidation_0-mae:87.14418\n",
      "[9300]\tvalidation_0-mae:87.10550\n",
      "[9400]\tvalidation_0-mae:87.06664\n",
      "[9500]\tvalidation_0-mae:87.02828\n",
      "[9600]\tvalidation_0-mae:86.99117\n",
      "[9700]\tvalidation_0-mae:86.94710\n",
      "[9800]\tvalidation_0-mae:86.90432\n",
      "[9900]\tvalidation_0-mae:86.85833\n",
      "[10000]\tvalidation_0-mae:86.82512\n",
      "[10100]\tvalidation_0-mae:86.79233\n",
      "[10200]\tvalidation_0-mae:86.75454\n",
      "[10300]\tvalidation_0-mae:86.72040\n",
      "[10400]\tvalidation_0-mae:86.67655\n",
      "[10500]\tvalidation_0-mae:86.64264\n",
      "[10600]\tvalidation_0-mae:86.60939\n",
      "[10700]\tvalidation_0-mae:86.57441\n",
      "[10800]\tvalidation_0-mae:86.53853\n",
      "[10900]\tvalidation_0-mae:86.50404\n",
      "[11000]\tvalidation_0-mae:86.46623\n",
      "[11100]\tvalidation_0-mae:86.40931\n",
      "[11200]\tvalidation_0-mae:86.37013\n",
      "[11300]\tvalidation_0-mae:86.33653\n",
      "[11400]\tvalidation_0-mae:86.30267\n",
      "[11500]\tvalidation_0-mae:86.27715\n",
      "[11600]\tvalidation_0-mae:86.24337\n",
      "[11700]\tvalidation_0-mae:86.21595\n",
      "[11800]\tvalidation_0-mae:86.18193\n",
      "[11900]\tvalidation_0-mae:86.15104\n",
      "[12000]\tvalidation_0-mae:86.12128\n",
      "[12100]\tvalidation_0-mae:86.09028\n",
      "[12200]\tvalidation_0-mae:86.06379\n",
      "[12300]\tvalidation_0-mae:86.03695\n",
      "[12400]\tvalidation_0-mae:86.01011\n",
      "[12500]\tvalidation_0-mae:85.98481\n",
      "[12600]\tvalidation_0-mae:85.95419\n",
      "[12700]\tvalidation_0-mae:85.92569\n",
      "[12800]\tvalidation_0-mae:85.88665\n",
      "[12900]\tvalidation_0-mae:85.85665\n",
      "[13000]\tvalidation_0-mae:85.82289\n",
      "[13100]\tvalidation_0-mae:85.79015\n",
      "[13200]\tvalidation_0-mae:85.74838\n",
      "[13300]\tvalidation_0-mae:85.71760\n",
      "[13400]\tvalidation_0-mae:85.68579\n",
      "[13500]\tvalidation_0-mae:85.66259\n",
      "[13600]\tvalidation_0-mae:85.63727\n",
      "[13700]\tvalidation_0-mae:85.61624\n",
      "[13800]\tvalidation_0-mae:85.59248\n",
      "[13900]\tvalidation_0-mae:85.56964\n",
      "[14000]\tvalidation_0-mae:85.55030\n",
      "[14100]\tvalidation_0-mae:85.53056\n",
      "[14200]\tvalidation_0-mae:85.50744\n",
      "[14300]\tvalidation_0-mae:85.48244\n",
      "[14400]\tvalidation_0-mae:85.45387\n",
      "[14500]\tvalidation_0-mae:85.42724\n",
      "[14600]\tvalidation_0-mae:85.39880\n",
      "[14700]\tvalidation_0-mae:85.36887\n",
      "[14800]\tvalidation_0-mae:85.34170\n",
      "[14900]\tvalidation_0-mae:85.32243\n",
      "[15000]\tvalidation_0-mae:85.30480\n",
      "[15100]\tvalidation_0-mae:85.28958\n",
      "[15200]\tvalidation_0-mae:85.26711\n",
      "[15300]\tvalidation_0-mae:85.23849\n",
      "[15400]\tvalidation_0-mae:85.20621\n",
      "[15500]\tvalidation_0-mae:85.18118\n",
      "[15600]\tvalidation_0-mae:85.16400\n",
      "[15700]\tvalidation_0-mae:85.14844\n",
      "[15800]\tvalidation_0-mae:85.12918\n",
      "[15900]\tvalidation_0-mae:85.10528\n",
      "[16000]\tvalidation_0-mae:85.07894\n",
      "[16100]\tvalidation_0-mae:85.05876\n",
      "[16200]\tvalidation_0-mae:85.03807\n",
      "[16300]\tvalidation_0-mae:85.01985\n",
      "[16400]\tvalidation_0-mae:85.00396\n",
      "[16500]\tvalidation_0-mae:84.98589\n",
      "[16600]\tvalidation_0-mae:84.95937\n",
      "[16700]\tvalidation_0-mae:84.93361\n",
      "[16800]\tvalidation_0-mae:84.91107\n",
      "[16900]\tvalidation_0-mae:84.89117\n",
      "[17000]\tvalidation_0-mae:84.86975\n",
      "[17100]\tvalidation_0-mae:84.85267\n",
      "[17200]\tvalidation_0-mae:84.84148\n",
      "[17300]\tvalidation_0-mae:84.82861\n",
      "[17400]\tvalidation_0-mae:84.81174\n",
      "[17500]\tvalidation_0-mae:84.80027\n",
      "[17600]\tvalidation_0-mae:84.78323\n",
      "[17700]\tvalidation_0-mae:84.77033\n",
      "[17800]\tvalidation_0-mae:84.75878\n",
      "[17900]\tvalidation_0-mae:84.74514\n",
      "[18000]\tvalidation_0-mae:84.73329\n",
      "[18100]\tvalidation_0-mae:84.72423\n",
      "[18200]\tvalidation_0-mae:84.71814\n",
      "[18300]\tvalidation_0-mae:84.71173\n",
      "[18400]\tvalidation_0-mae:84.70149\n",
      "[18500]\tvalidation_0-mae:84.69101\n",
      "[18600]\tvalidation_0-mae:84.68053\n",
      "[18700]\tvalidation_0-mae:84.66654\n",
      "[18800]\tvalidation_0-mae:84.65378\n",
      "[18900]\tvalidation_0-mae:84.64464\n",
      "[19000]\tvalidation_0-mae:84.63590\n",
      "[19100]\tvalidation_0-mae:84.62790\n",
      "[19200]\tvalidation_0-mae:84.62037\n",
      "[19300]\tvalidation_0-mae:84.61131\n",
      "[19400]\tvalidation_0-mae:84.60222\n",
      "[19500]\tvalidation_0-mae:84.58701\n",
      "[19600]\tvalidation_0-mae:84.57067\n",
      "[19700]\tvalidation_0-mae:84.55389\n",
      "[19800]\tvalidation_0-mae:84.53407\n",
      "[19900]\tvalidation_0-mae:84.51545\n",
      "[20000]\tvalidation_0-mae:84.49616\n",
      "[20100]\tvalidation_0-mae:84.48629\n",
      "[20200]\tvalidation_0-mae:84.47890\n",
      "[20300]\tvalidation_0-mae:84.46585\n",
      "[20400]\tvalidation_0-mae:84.45131\n",
      "[20500]\tvalidation_0-mae:84.44651\n",
      "[20600]\tvalidation_0-mae:84.43579\n",
      "[20700]\tvalidation_0-mae:84.42455\n",
      "[20800]\tvalidation_0-mae:84.41332\n",
      "[20900]\tvalidation_0-mae:84.40286\n",
      "[21000]\tvalidation_0-mae:84.38985\n",
      "[21100]\tvalidation_0-mae:84.38230\n",
      "[21200]\tvalidation_0-mae:84.37309\n",
      "[21300]\tvalidation_0-mae:84.36273\n",
      "[21400]\tvalidation_0-mae:84.35141\n",
      "[21500]\tvalidation_0-mae:84.34370\n",
      "[21600]\tvalidation_0-mae:84.33468\n",
      "[21700]\tvalidation_0-mae:84.31914\n",
      "[21800]\tvalidation_0-mae:84.31099\n",
      "[21900]\tvalidation_0-mae:84.30536\n",
      "[22000]\tvalidation_0-mae:84.29333\n",
      "[22100]\tvalidation_0-mae:84.27908\n",
      "[22200]\tvalidation_0-mae:84.26178\n",
      "[22300]\tvalidation_0-mae:84.24926\n",
      "[22400]\tvalidation_0-mae:84.23966\n",
      "[22500]\tvalidation_0-mae:84.22867\n",
      "[22600]\tvalidation_0-mae:84.22056\n",
      "[22700]\tvalidation_0-mae:84.21129\n",
      "[22800]\tvalidation_0-mae:84.20119\n",
      "[22900]\tvalidation_0-mae:84.18990\n",
      "[23000]\tvalidation_0-mae:84.17864\n",
      "[23100]\tvalidation_0-mae:84.16559\n",
      "[23200]\tvalidation_0-mae:84.15203\n",
      "[23300]\tvalidation_0-mae:84.14045\n",
      "[23400]\tvalidation_0-mae:84.12570\n",
      "[23500]\tvalidation_0-mae:84.10466\n",
      "[23600]\tvalidation_0-mae:84.08540\n",
      "[23700]\tvalidation_0-mae:84.07095\n",
      "[23800]\tvalidation_0-mae:84.05979\n",
      "[23900]\tvalidation_0-mae:84.04885\n",
      "[24000]\tvalidation_0-mae:84.04153\n",
      "[24100]\tvalidation_0-mae:84.03229\n",
      "[24200]\tvalidation_0-mae:84.01898\n",
      "[24300]\tvalidation_0-mae:84.00805\n",
      "[24400]\tvalidation_0-mae:83.99991\n",
      "[24500]\tvalidation_0-mae:83.99305\n",
      "[24600]\tvalidation_0-mae:83.98901\n",
      "[24700]\tvalidation_0-mae:83.98400\n",
      "[24800]\tvalidation_0-mae:83.98012\n",
      "[24900]\tvalidation_0-mae:83.97489\n",
      "[25000]\tvalidation_0-mae:83.96924\n",
      "[25100]\tvalidation_0-mae:83.96424\n",
      "[25200]\tvalidation_0-mae:83.95853\n",
      "[25300]\tvalidation_0-mae:83.95467\n",
      "[25400]\tvalidation_0-mae:83.94989\n",
      "[25500]\tvalidation_0-mae:83.94265\n",
      "[25600]\tvalidation_0-mae:83.93486\n",
      "[25700]\tvalidation_0-mae:83.92481\n",
      "[25800]\tvalidation_0-mae:83.91141\n",
      "[25900]\tvalidation_0-mae:83.90247\n",
      "[26000]\tvalidation_0-mae:83.89442\n",
      "[26100]\tvalidation_0-mae:83.88797\n",
      "[26200]\tvalidation_0-mae:83.87978\n",
      "[26300]\tvalidation_0-mae:83.86951\n",
      "[26400]\tvalidation_0-mae:83.86064\n",
      "[26500]\tvalidation_0-mae:83.85707\n",
      "[26549]\tvalidation_0-mae:83.85709\n",
      "Fold 83.85706708921643, Mean Absolute Error: 83.85706708921643\n",
      "[0]\tvalidation_0-mae:442.87100\n",
      "[100]\tvalidation_0-mae:403.25549\n",
      "[200]\tvalidation_0-mae:367.83440\n",
      "[300]\tvalidation_0-mae:336.33092\n",
      "[400]\tvalidation_0-mae:308.44577\n",
      "[500]\tvalidation_0-mae:283.88252\n",
      "[600]\tvalidation_0-mae:262.18660\n",
      "[700]\tvalidation_0-mae:243.04582\n",
      "[800]\tvalidation_0-mae:225.98963\n",
      "[900]\tvalidation_0-mae:210.98811\n",
      "[1000]\tvalidation_0-mae:197.68043\n",
      "[1100]\tvalidation_0-mae:185.86512\n",
      "[1200]\tvalidation_0-mae:175.32610\n",
      "[1300]\tvalidation_0-mae:165.90039\n",
      "[1400]\tvalidation_0-mae:157.55290\n",
      "[1500]\tvalidation_0-mae:150.15763\n",
      "[1600]\tvalidation_0-mae:143.60941\n",
      "[1700]\tvalidation_0-mae:137.73425\n",
      "[1800]\tvalidation_0-mae:132.50000\n",
      "[1900]\tvalidation_0-mae:127.80029\n",
      "[2000]\tvalidation_0-mae:123.55541\n",
      "[2100]\tvalidation_0-mae:119.75844\n",
      "[2200]\tvalidation_0-mae:116.35945\n",
      "[2300]\tvalidation_0-mae:113.27212\n",
      "[2400]\tvalidation_0-mae:110.51877\n",
      "[2500]\tvalidation_0-mae:108.01400\n",
      "[2600]\tvalidation_0-mae:105.85007\n",
      "[2700]\tvalidation_0-mae:103.87022\n",
      "[2800]\tvalidation_0-mae:102.11433\n",
      "[2900]\tvalidation_0-mae:100.53384\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross validation\n",
    "if load_xgb:\n",
    "    num_folds = 5\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    total_mae = 0\n",
    "\n",
    "    xgboost_models = []\n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(base_x_train):\n",
    "        reg = xgb.XGBRegressor(n_estimators=10000000,\n",
    "                        early_stopping_rounds=50,\n",
    "                        learning_rate= 0.001,\n",
    "                        objective=\"reg:linear\",\n",
    "                        eval_metric=\"mae\",\n",
    "                        sub_sample = 0.9,\n",
    "                        colsample_bytree = 1.0,\n",
    "                        gamma = 0,\n",
    "                        min_child_weight=0,\n",
    "                        max_depth=9)\n",
    "\n",
    "        X_train, X_test = base_x_train.iloc[train_index], base_x_train.iloc[test_index]\n",
    "        y_train, y_test = base_y_train.iloc[train_index], base_y_train.iloc[test_index]\n",
    "        \n",
    "        # Create sample weights for training data\n",
    "        sample_weight_train = np.where(X_train['time_since_prediction'] == 0, 1, 2)\n",
    "        # Create sample weights for testing data\n",
    "        sample_weight_test = np.where(X_test['time_since_prediction'] == 0, 1, 2)\n",
    "        \n",
    "        reg.fit(X_train, y_train,\n",
    "                eval_set=[(X_test, y_test)],\n",
    "                sample_weight=sample_weight_train,\n",
    "                sample_weight_eval_set=[sample_weight_test],  # Here's how you pass the eval weights\n",
    "                verbose=100)\n",
    "        \n",
    "        xgboost_models.append(reg)\n",
    "        predictions = reg.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, predictions, sample_weight=sample_weight_test)\n",
    "        total_mae += mae\n",
    "        \n",
    "        print(f\"Fold {total_mae}, Mean Absolute Error: {mae}\")\n",
    "\n",
    "    average_mse = total_mae / num_folds\n",
    "    print(f\"Average Mean Squared Error: {average_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 319.2688617\ttest: 321.1561406\tbest: 321.1561406 (0)\ttotal: 215ms\tremaining: 24d 22h 21m 36s\n",
      "200:\tlearn: 281.2586358\ttest: 283.0927042\tbest: 283.0927042 (200)\ttotal: 7.5s\tremaining: 4d 7h 41m 23s\n",
      "400:\tlearn: 244.6701513\ttest: 246.4584006\tbest: 246.4584006 (400)\ttotal: 14.4s\tremaining: 4d 3h 51m 13s\n",
      "600:\tlearn: 212.8658236\ttest: 214.8102130\tbest: 214.8102130 (600)\ttotal: 21.7s\tremaining: 4d 4h 16m 22s\n",
      "800:\tlearn: 188.1097963\ttest: 190.2060282\tbest: 190.2060282 (800)\ttotal: 28.3s\tremaining: 4d 1h 58m 36s\n",
      "1000:\tlearn: 168.8386292\ttest: 171.0407055\tbest: 171.0407055 (1000)\ttotal: 35.3s\tremaining: 4d 1h 59m 56s\n",
      "1200:\tlearn: 154.1245236\ttest: 156.1806167\tbest: 156.1806167 (1200)\ttotal: 42.7s\tremaining: 4d 2h 49m 53s\n",
      "1400:\tlearn: 142.5459343\ttest: 144.5358448\tbest: 144.5358448 (1400)\ttotal: 49.6s\tremaining: 4d 2h 22m 56s\n",
      "1600:\tlearn: 133.2908509\ttest: 135.3052315\tbest: 135.3052315 (1600)\ttotal: 56.9s\tremaining: 4d 2h 41m 56s\n",
      "1800:\tlearn: 125.5303259\ttest: 127.5529840\tbest: 127.5529840 (1800)\ttotal: 1m 4s\tremaining: 4d 3h 27m 17s\n",
      "2000:\tlearn: 119.4843965\ttest: 121.5923819\tbest: 121.5923819 (2000)\ttotal: 1m 11s\tremaining: 4d 3h 15m 22s\n",
      "2200:\tlearn: 114.8753802\ttest: 117.0837992\tbest: 117.0837992 (2200)\ttotal: 1m 18s\tremaining: 4d 3h 34m 4s\n"
     ]
    }
   ],
   "source": [
    "if not load_cat:\n",
    "    num_folds = 5\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    total_mae = 0\n",
    "    catboost_models = []\n",
    "\n",
    "    def compute_sample_weight(data):\n",
    "        # Assign weight of 2 for estimated data and 1 for observed data\n",
    "        return np.where(data['time_since_prediction'] > 0, 2, 1)\n",
    "\n",
    "    for train_index, test_index in kf.split(base_x_train):\n",
    "        reg = CatBoostRegressor(\n",
    "            iterations=10000000,\n",
    "            depth=8,\n",
    "            learning_rate=0.001,\n",
    "            loss_function='MAE',\n",
    "            verbose=200\n",
    "        )\n",
    "        \n",
    "        X_train, X_test = base_x_train.iloc[train_index], base_x_train.iloc[test_index]\n",
    "        y_train, y_test = base_y_train.iloc[train_index], base_y_train.iloc[test_index]\n",
    "        \n",
    "        # Compute sample weights for training and testing data\n",
    "        train_weight = compute_sample_weight(X_train)\n",
    "        test_weight = compute_sample_weight(X_test)\n",
    "\n",
    "        # Create Pool for training and testing\n",
    "        train_pool = Pool(data=X_train, label=y_train, weight=train_weight)\n",
    "        test_pool = Pool(data=X_test, label=y_test, weight=test_weight)\n",
    "\n",
    "        # Fit the model using the sample weights\n",
    "        reg.fit(train_pool, eval_set=test_pool, early_stopping_rounds=100)\n",
    "\n",
    "        catboost_models.append(reg)\n",
    "        predictions = reg.predict(test_pool)\n",
    "        \n",
    "        # Compute weighted MAE manually\n",
    "        weighted_mae = np.sum(test_weight * np.abs(y_test - predictions)) / np.sum(test_weight)\n",
    "        total_mae += weighted_mae\n",
    "        \n",
    "        print(f\"Fold {len(catboost_models)}, Weighted Mean Absolute Error: {weighted_mae}\")\n",
    "\n",
    "    average_mae = total_mae / num_folds\n",
    "    print(f\"Average Weighted Mean Absolute Error: {average_mae}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.883147\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.368057\n",
      "[LightGBM] [Debug] init for col-wise cost 0.003511 seconds, init for row-wise cost 0.011434 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 7461\n",
      "[LightGBM] [Info] Number of data points in the train set: 49320, number of used features: 45\n",
      "[LightGBM] [Debug] Use subset for bagging\n",
      "[LightGBM] [Debug] Re-bagging, using 44391 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 114 and depth = 8\n",
      "[1]\tvalid_0's l1: 320.904\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's l1: 320.904\n",
      "Fold 320.90351299573996, Mean Absolute Error: 320.90351299573996\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.882696\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.367611\n",
      "[LightGBM] [Debug] init for col-wise cost 0.002227 seconds, init for row-wise cost 0.019224 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7464\n",
      "[LightGBM] [Info] Number of data points in the train set: 49320, number of used features: 45\n",
      "[LightGBM] [Debug] Use subset for bagging\n",
      "[LightGBM] [Debug] Re-bagging, using 44391 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 106 and depth = 8\n",
      "[1]\tvalid_0's l1: 312.58\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's l1: 312.58\n",
      "Fold 633.4833144635862, Mean Absolute Error: 312.57980146784627\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.883038\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.367805\n",
      "[LightGBM] [Debug] init for col-wise cost 0.003605 seconds, init for row-wise cost 0.010866 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7458\n",
      "[LightGBM] [Info] Number of data points in the train set: 49320, number of used features: 45\n",
      "[LightGBM] [Debug] Use subset for bagging\n",
      "[LightGBM] [Debug] Re-bagging, using 44391 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 113 and depth = 8\n",
      "[1]\tvalid_0's l1: 316.706\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's l1: 316.706\n",
      "Fold 950.1896915701207, Mean Absolute Error: 316.70637710653443\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.882473\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.367710\n",
      "[LightGBM] [Debug] init for col-wise cost 0.002354 seconds, init for row-wise cost 0.012584 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7460\n",
      "[LightGBM] [Info] Number of data points in the train set: 49320, number of used features: 45\n",
      "[LightGBM] [Debug] Use subset for bagging\n",
      "[LightGBM] [Debug] Re-bagging, using 44391 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 109 and depth = 8\n",
      "[1]\tvalid_0's l1: 319.256\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's l1: 319.256\n",
      "Fold 1269.445361408627, Mean Absolute Error: 319.2556698385063\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.882795\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.367963\n",
      "[LightGBM] [Debug] init for col-wise cost 0.003157 seconds, init for row-wise cost 0.010521 seconds\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Debug] Using Sparse Multi-Val Bin\n",
      "[LightGBM] [Info] Total Bins 7465\n",
      "[LightGBM] [Info] Number of data points in the train set: 49320, number of used features: 45\n",
      "[LightGBM] [Debug] Use subset for bagging\n",
      "[LightGBM] [Debug] Re-bagging, using 44391 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 104 and depth = 8\n",
      "[1]\tvalid_0's l1: 322.759\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1]\tvalid_0's l1: 322.759\n",
      "Fold 1592.204196501921, Mean Absolute Error: 322.75883509329407\n",
      "Average Mean Squared Error: 318.4408393003842\n"
     ]
    }
   ],
   "source": [
    "if not load_lgb:\n",
    "    num_folds = 5\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "    total_mae = 0\n",
    "\n",
    "    lightgbm_models = []\n",
    "\n",
    "    params = {\n",
    "        'objective': 'regression_l1',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'max_depth': 8,\n",
    "        'metric': 'mae',\n",
    "        'num_leaves': 256,\n",
    "        'learning_rate': 0.001,\n",
    "        'feature_fraction': 1.0,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 5,\n",
    "        'min_data_in_leaf': 20,\n",
    "        'early_stopping_rounds': 100,\n",
    "        'verbosity': 100,  # 0 for verbose, -1 for silent\n",
    "    }\n",
    "\n",
    "    num_round = 10000000 # number of training iterations\n",
    "\n",
    "    # Ensure column names are compatible with LightGBM\n",
    "    base_x_train.columns = base_x_train.columns.str.replace('[^A-Za-z0-9_]', '_', regex=True)\n",
    "\n",
    "    for train_index, test_index in kf.split(base_x_train):\n",
    "        X_train, X_test = base_x_train.iloc[train_index], base_x_train.iloc[test_index]\n",
    "        y_train, y_test = base_y_train.iloc[train_index], base_y_train.iloc[test_index]\n",
    "\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        valid_data = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "        reg = lgb.train(params, train_data, num_round, valid_sets=[valid_data])\n",
    "        lightgbm_models.append(reg)\n",
    "        predictions = reg.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        total_mae += mae\n",
    "        \n",
    "        print(f\"Fold {total_mae}, Mean Absolute Error: {mae}\")\n",
    "\n",
    "    average_mse = total_mae / num_folds\n",
    "    print(f\"Average Mean Squared Error: {average_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not load_rf:\n",
    "    # K-fold cross validation\n",
    "    num_folds = 5\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    total_mae = 0\n",
    "\n",
    "    random_forest_models = []\n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(base_x_train):\n",
    "\n",
    "        rf_model = RandomForestRegressor(n_estimators=1, random_state=42)\n",
    "\n",
    "        X_train, X_test = base_x_train.iloc[train_index], base_x_train.iloc[test_index]\n",
    "        y_train, y_test = base_y_train.iloc[train_index], base_y_train.iloc[test_index]\n",
    "\n",
    "        # Train the Random Forest model on the cleaned training data\n",
    "        \n",
    "        reg.fit(X_train, y_train,\n",
    "                eval_set=[(X_val_est_combined, y_val_est_combined)],\n",
    "                verbose=100)\n",
    "        \n",
    "        random_forest_models.append(reg)\n",
    "        predictions = reg.predict(X_test)\n",
    "        \n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        total_mae += mae\n",
    "        \n",
    "        print(f\"Fold {total_mae}, Mean Absolute Error: {mae}\")\n",
    "\n",
    "    average_mse = total_mae / num_folds\n",
    "    print(f\"Average Mean Squared Error: {average_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what models should be loaded\n",
    "# Load XGBoost models\n",
    "if load_xgb:\n",
    "    with open(\"xgboost_models.pkl\", \"rb\") as file:\n",
    "        xgboost_models = pickle.load(file)\n",
    "\n",
    "# Load CatBoost models\n",
    "if load_cat:\n",
    "    with open(\"catboost_models.pkl\", \"rb\") as file:\n",
    "        catboost_models = pickle.load(file)\n",
    "# Load lightGBM models\n",
    "if load_lgb:\n",
    "    with open(\"lightgbm_models.pkl\", \"rb\") as file:\n",
    "        lightgbm_models = pickle.load(file)\n",
    "# Load random forest models\n",
    "if load_rf:\n",
    "    with open(\"random_forest_models.pkl\", \"rb\") as file:\n",
    "        random_forest_models = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_prediction(x_values :pd.DataFrame, models) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function for predicting on multiple models and averaging the results\n",
    "    \"\"\"\n",
    "    results = models[0].predict(x_values)\n",
    "    for model in models[1:]:\n",
    "        model: xgb.XGBRegressor\n",
    "        prediction = model.predict(x_values)\n",
    "        results += prediction\n",
    "    \n",
    "    results = results / len(models)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train meta learner model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset for meta learner model by using models to predict on the meta layer training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the base layer on meta_x_train\n",
    "base_xgboost_predictions  = average_prediction(meta_x_train, xgboost_models)\n",
    "base_catboost_predictions = average_prediction(meta_x_train, catboost_models)\n",
    "base_lightgbm_predictions = average_prediction(meta_x_train, lightgbm_models)\n",
    "base_random_forest_predictions = average_prediction(meta_x_train, random_forest_models)\n",
    "\n",
    "# Add the predictions to the meta_x_train\n",
    "meta_base_x_train = pd.DataFrame()\n",
    "meta_base_x_train[\"xgboost\"] = base_xgboost_predictions\n",
    "meta_base_x_train[\"catboost\"] = base_catboost_predictions\n",
    "meta_base_x_train[\"lightgbm\"] = base_lightgbm_predictions\n",
    "meta_x_train[\"random_forest\"] = base_random_forest_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train meta learner model on new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mae:437.81923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 437.81923520276587, Mean Absolute Error: 437.81923520276587\n",
      "[0]\tvalidation_0-mae:469.82864\n",
      "Fold 907.6478779289748, Mean Absolute Error: 469.828642726209\n",
      "[0]\tvalidation_0-mae:442.07283\n",
      "Fold 1349.7207061602815, Mean Absolute Error: 442.0728282313066\n",
      "[0]\tvalidation_0-mae:462.35442\n",
      "Fold 1812.075125533751, Mean Absolute Error: 462.35441937346957\n",
      "[0]\tvalidation_0-mae:442.78670\n",
      "Fold 2254.8618256781283, Mean Absolute Error: 442.7867001443772\n",
      "Average Mean Squared Error: 450.97236513562564\n"
     ]
    }
   ],
   "source": [
    "# K-fold cross validation\n",
    "\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "total_mae = 0\n",
    "\n",
    "meta_models = []\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(meta_base_x_train):\n",
    "\n",
    "    reg = xgb.XGBRegressor(n_estimators=100000,\n",
    "                       early_stopping_rounds=50,\n",
    "                       learning_rate= 0.01,\n",
    "                       objective=\"reg:linear\",\n",
    "                       eval_metric=\"mae\",\n",
    "                       sub_sample = 0.9,\n",
    "                       colsample_bytree = 0.8,\n",
    "                       gamma = 0,\n",
    "                       alpha = 0.001,\n",
    "                       min_child_weight=0,\n",
    "                       max_depth=4)\n",
    "\n",
    "    X_train, X_test = meta_base_x_train.iloc[train_index], meta_base_x_train.iloc[test_index]\n",
    "    y_train, y_test = meta_y_train.iloc[train_index], meta_y_train.iloc[test_index]\n",
    "\n",
    "    reg.fit(X_train, y_train,\n",
    "            eval_set=[(X_test, y_test)],\n",
    "            verbose=100)\n",
    "    \n",
    "    meta_models.append(reg)\n",
    "    predictions = reg.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    total_mae += mae\n",
    "    \n",
    "    print(f\"Fold {total_mae}, Mean Absolute Error: {mae}\")\n",
    "\n",
    "average_mse = total_mae / num_folds\n",
    "print(f\"Average Mean Squared Error: {average_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 10000x10000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fi = pd.DataFrame(data=reg.feature_importances_,\n",
    "             index=reg.feature_names_in_,\n",
    "             columns=[\"importance\"])\n",
    "\n",
    "plt.figure(figsize=(100,100))\n",
    "plt.tight_layout()\n",
    "fi.sort_values(\"importance\").plot(kind=\"barh\", title=\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['xgboost', 'catboost', 'lightgbm'] ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'cloud_base_agl:m', 'dew_or_rime:idx', 'dew_point_2m:K', 'diffuse_rad:W', 'diffuse_rad_1h:J', 'direct_rad:W', 'direct_rad_1h:J', 'effective_cloud_cover:p', 'is_day:idx', 'is_in_shadow:idx', 'precip_5min:mm', 'precip_type_5min:idx', 'pressure_50m:hPa', 'prob_rime:p', 'rain_water:kgm2', 'relative_humidity_1000hPa:p', 'sun_azimuth:d', 'super_cooled_liquid_water:kgm2', 't_1000hPa:K', 'total_cloud_cover:p', 'visibility:m', 'wind_speed_10m:ms', 'wind_speed_u_10m:ms', 'wind_speed_v_10m:ms', 'wind_speed_w_1000hPa:ms', 'location_a', 'location_b', 'location_c', 'sin_day_of_year', 'cos_day_of_year', 'sin_hour', 'cos_hour', 'sun_product', 'modified_solar_elevation', 'effective_radiation', 'time_since_prediction', 'cloud_ratio', 'cloud_cover_over_30%', 'sun_addition', 'is_freezing', 'is_snow', 'is_rain']\nexpected catboost, xgboost, lightgbm in input data\ntraining data did not have the following fields: effective_radiation, precip_type_5min:idx, sin_day_of_year, diffuse_rad_1h:J, location_b, location_c, cos_hour, cloud_cover_over_30%, is_rain, rain_water:kgm2, clear_sky_rad:W, wind_speed_10m:ms, air_density_2m:kgm3, t_1000hPa:K, absolute_humidity_2m:gm3, diffuse_rad:W, sun_product, relative_humidity_1000hPa:p, prob_rime:p, wind_speed_u_10m:ms, precip_5min:mm, effective_cloud_cover:p, sin_hour, cloud_base_agl:m, direct_rad:W, direct_rad_1h:J, dew_point_2m:K, wind_speed_w_1000hPa:ms, pressure_50m:hPa, cloud_ratio, wind_speed_v_10m:ms, dew_or_rime:idx, is_freezing, is_day:idx, location_a, is_snow, visibility:m, cos_day_of_year, is_in_shadow:idx, total_cloud_cover:p, time_since_prediction, sun_addition, clear_sky_energy_1h:J, modified_solar_elevation, super_cooled_liquid_water:kgm2, sun_azimuth:d",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Bruker\\OneDrive\\NTNU semester 05\\TDT4173 Maskinlæring\\ml_power_predictor\\stacking.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/stacking.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m y_pred_val_obs_combined \u001b[39m=\u001b[39m average_prediction(X_val_obs_combined, meta_models)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/stacking.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y_pred_val_est_combined \u001b[39m=\u001b[39m average_prediction(X_val_est_combined, meta_models)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/stacking.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Evaluate the model's performance using Mean Absolute Error (MAE) on the combined validation observed data\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\Bruker\\OneDrive\\NTNU semester 05\\TDT4173 Maskinlæring\\ml_power_predictor\\stacking.ipynb Cell 22\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/stacking.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maverage_prediction\u001b[39m(x_values :pd\u001b[39m.\u001b[39mDataFrame, models) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/stacking.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/stacking.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m    Function for predicting on multiple models and averaging the results\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/stacking.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/stacking.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     results \u001b[39m=\u001b[39m models[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mpredict(x_values)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/stacking.ipynb#X30sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models[\u001b[39m1\u001b[39m:]:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Bruker/OneDrive/NTNU%20semester%2005/TDT4173%20Maskinl%C3%A6ring/ml_power_predictor/stacking.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         model: xgb\u001b[39m.\u001b[39mXGBRegressor\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\OneDrive\\NTNU semester 05\\TDT4173 Maskinlæring\\ml_power_predictor\\venv\\lib\\site-packages\\xgboost\\sklearn.py:1164\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1163\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1164\u001b[0m         predts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_booster()\u001b[39m.\u001b[39;49minplace_predict(\n\u001b[0;32m   1165\u001b[0m             data\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m   1166\u001b[0m             iteration_range\u001b[39m=\u001b[39;49miteration_range,\n\u001b[0;32m   1167\u001b[0m             predict_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmargin\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m output_margin \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1168\u001b[0m             missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[0;32m   1169\u001b[0m             base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[0;32m   1170\u001b[0m             validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[0;32m   1171\u001b[0m         )\n\u001b[0;32m   1172\u001b[0m         \u001b[39mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[0;32m   1173\u001b[0m             \u001b[39mimport\u001b[39;00m \u001b[39mcupy\u001b[39;00m  \u001b[39m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\OneDrive\\NTNU semester 05\\TDT4173 Maskinlæring\\ml_power_predictor\\venv\\lib\\site-packages\\xgboost\\core.py:2417\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2415\u001b[0m     data, fns, _ \u001b[39m=\u001b[39m _transform_pandas_df(data, enable_categorical)\n\u001b[0;32m   2416\u001b[0m     \u001b[39mif\u001b[39;00m validate_features:\n\u001b[1;32m-> 2417\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_features(fns)\n\u001b[0;32m   2418\u001b[0m \u001b[39mif\u001b[39;00m _is_list(data) \u001b[39mor\u001b[39;00m _is_tuple(data):\n\u001b[0;32m   2419\u001b[0m     data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(data)\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\OneDrive\\NTNU semester 05\\TDT4173 Maskinlæring\\ml_power_predictor\\venv\\lib\\site-packages\\xgboost\\core.py:2969\u001b[0m, in \u001b[0;36mBooster._validate_features\u001b[1;34m(self, feature_names)\u001b[0m\n\u001b[0;32m   2963\u001b[0m \u001b[39mif\u001b[39;00m my_missing:\n\u001b[0;32m   2964\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m   2965\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mtraining data did not have the following fields: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2966\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m my_missing)\n\u001b[0;32m   2967\u001b[0m     )\n\u001b[1;32m-> 2969\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names, feature_names))\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['xgboost', 'catboost', 'lightgbm'] ['absolute_humidity_2m:gm3', 'air_density_2m:kgm3', 'clear_sky_energy_1h:J', 'clear_sky_rad:W', 'cloud_base_agl:m', 'dew_or_rime:idx', 'dew_point_2m:K', 'diffuse_rad:W', 'diffuse_rad_1h:J', 'direct_rad:W', 'direct_rad_1h:J', 'effective_cloud_cover:p', 'is_day:idx', 'is_in_shadow:idx', 'precip_5min:mm', 'precip_type_5min:idx', 'pressure_50m:hPa', 'prob_rime:p', 'rain_water:kgm2', 'relative_humidity_1000hPa:p', 'sun_azimuth:d', 'super_cooled_liquid_water:kgm2', 't_1000hPa:K', 'total_cloud_cover:p', 'visibility:m', 'wind_speed_10m:ms', 'wind_speed_u_10m:ms', 'wind_speed_v_10m:ms', 'wind_speed_w_1000hPa:ms', 'location_a', 'location_b', 'location_c', 'sin_day_of_year', 'cos_day_of_year', 'sin_hour', 'cos_hour', 'sun_product', 'modified_solar_elevation', 'effective_radiation', 'time_since_prediction', 'cloud_ratio', 'cloud_cover_over_30%', 'sun_addition', 'is_freezing', 'is_snow', 'is_rain']\nexpected catboost, xgboost, lightgbm in input data\ntraining data did not have the following fields: effective_radiation, precip_type_5min:idx, sin_day_of_year, diffuse_rad_1h:J, location_b, location_c, cos_hour, cloud_cover_over_30%, is_rain, rain_water:kgm2, clear_sky_rad:W, wind_speed_10m:ms, air_density_2m:kgm3, t_1000hPa:K, absolute_humidity_2m:gm3, diffuse_rad:W, sun_product, relative_humidity_1000hPa:p, prob_rime:p, wind_speed_u_10m:ms, precip_5min:mm, effective_cloud_cover:p, sin_hour, cloud_base_agl:m, direct_rad:W, direct_rad_1h:J, dew_point_2m:K, wind_speed_w_1000hPa:ms, pressure_50m:hPa, cloud_ratio, wind_speed_v_10m:ms, dew_or_rime:idx, is_freezing, is_day:idx, location_a, is_snow, visibility:m, cos_day_of_year, is_in_shadow:idx, total_cloud_cover:p, time_since_prediction, sun_addition, clear_sky_energy_1h:J, modified_solar_elevation, super_cooled_liquid_water:kgm2, sun_azimuth:d"
     ]
    }
   ],
   "source": [
    "y_pred_val_obs_combined = average_prediction(X_val_obs_combined, meta_models)\n",
    "y_pred_val_est_combined = average_prediction(X_val_est_combined, meta_models)\n",
    "\n",
    "# Evaluate the model's performance using Mean Absolute Error (MAE) on the combined validation observed data\n",
    "mae_obs_combined = mean_absolute_error(y_val_obs_combined, y_pred_val_obs_combined)\n",
    "mae_est_combined = mean_absolute_error(y_val_est_combined, y_pred_val_est_combined)\n",
    "print('MAE on validation observed data: ', mae_obs_combined)\n",
    "print('MAE on validation estimated data: ', mae_est_combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get predictions for meta learner model test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the cleaned validation set\n",
    "from src.features.preprocess_data import get_final_prediction\n",
    "\n",
    "y_predictions = average_prediction(x_test_whole, meta_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.saving import save_predictions\n",
    "\n",
    "\n",
    "save_predictions(y_predictions, 'stacking with possible data leakage')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
